{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tmva_logo.gif\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "# TMVA Classification Example Using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    " // for using Keras\n",
    "gSystem->Setenv(\"KERAS_BACKEND\",\"tensorflow\"); \n",
    "TMVA::PyMethodBase::PyInitialize();\n",
    "\n",
    "\n",
    "\n",
    "auto outputFile = TFile::Open(\"CNN_ClassificationOutput.root\", \"RECREATE\");\n",
    "\n",
    "TMVA::Factory factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" ); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables \n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "In this case the input data consists of an image of 16x16 pixels. Each single pixel is a branch in a ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::DataLoader * loader = new TMVA::DataLoader(\"dataset\");\n",
    "\n",
    "int imgSize = 8 * 8; \n",
    "for(auto i = 0; i < imgSize; i++)\n",
    " {\n",
    "     loader->AddVariable(Form(\"var%d\",i),'F');\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "TString inputFileName = \"images_data.root\";\n",
    "\n",
    "//TString inputFileName = \"tmva_class_example.root\";\n",
    "\n",
    "auto inputFile = TFile::Open( inputFileName );\n",
    "\n",
    "// --- Register the training and test trees\n",
    "\n",
    "TTree *signalTree     = (TTree*)inputFile->Get(\"sig_tree\");\n",
    "TTree *backgroundTree = (TTree*)inputFile->Get(\"bkg_tree\");\n",
    "\n",
    "// global event weights per tree (see below for setting event-wise weights)\n",
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "   \n",
    "// You can add an arbitrary number of signal or background trees\n",
    "loader->AddSignalTree    ( signalTree,     signalWeight     );\n",
    "loader->AddBackgroundTree( backgroundTree, backgroundWeight );\n",
    "\n",
    "\n",
    "// Set individual event weights (the variables must exist in the original TTree)\n",
    "//    for signal    : factory->SetSignalWeightExpression    (\"weight1*weight2\");\n",
    "//    for background: factory->SetBackgroundWeightExpression(\"weight1*weight2\");\n",
    "//loader->SetBackgroundWeightExpression( \"weight\" );\n",
    "\n",
    "// Apply additional cuts on the signal and background samples (can be different)\n",
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "// Tell the factory how to use the training and testing events\n",
    "//\n",
    "// If no numbers of events are given, half of the events in the tree are used \n",
    "// for training, and the other half for testing:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "// To also specify the number of testing events, use:\n",
    "\n",
    "loader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                    \"nTrain_Signal=0:nTrain_Background=0:SplitMode=Random:NormMode=NumEvents:!V\" );\n",
    "\n",
    "\n",
    "\n",
    "//loader->PrepareTrainingAndTestTree(mycuts, mycutb,\n",
    "//                                   \"nTrain_Signal=5000:nTrain_Background=5000:nTest_Signal=5000:nTest_Background=5000:SplitMode=Random:NormMode=NumEvents:!V\" ); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Likelihood based on KDE, a Fischer discriminant and a BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 5000\n",
      "                         : Signal     -- testing events             : 5000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 5000\n",
      "                         : Background -- testing events             : 5000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                         :             var0    var1    var2    var3    var4    var5    var6    var7    var8    var9   var10   var11   var12   var13   var14   var15   var16   var17   var18   var19   var20   var21   var22   var23   var24   var25   var26   var27   var28   var29   var30   var31   var32   var33   var34   var35   var36   var37   var38   var39   var40   var41   var42   var43   var44   var45   var46   var47   var48   var49   var50   var51   var52   var53   var54   var55   var56   var57   var58   var59   var60   var61   var62   var63\n",
      "                         :    var0:  +1.000  +0.270  +0.261  +0.210  +0.091  -0.039  -0.087  -0.103  +0.279  +0.321  +0.296  +0.202  +0.085  -0.098  -0.151  -0.145  +0.308  +0.301  +0.313  +0.190  +0.010  -0.095  -0.191  -0.184  +0.287  +0.276  +0.252  +0.113  -0.070  -0.217  -0.250  -0.221  +0.227  +0.233  +0.188  +0.026  -0.167  -0.252  -0.301  -0.233  +0.177  +0.155  +0.078  -0.048  -0.203  -0.273  -0.293  -0.241  +0.110  +0.075  +0.018  -0.103  -0.219  -0.261  -0.255  -0.226  +0.059  +0.014  -0.029  -0.113  -0.197  -0.236  -0.220  -0.184\n",
      "                         :    var1:  +0.270  +1.000  +0.360  +0.290  +0.176  +0.029  -0.055  -0.073  +0.345  +0.395  +0.380  +0.288  +0.164  -0.016  -0.082  -0.147  +0.337  +0.370  +0.370  +0.274  +0.074  -0.097  -0.178  -0.174  +0.302  +0.325  +0.294  +0.182  -0.076  -0.204  -0.269  -0.239  +0.241  +0.229  +0.188  +0.023  -0.196  -0.292  -0.316  -0.270  +0.154  +0.141  +0.050  -0.135  -0.282  -0.348  -0.323  -0.294  +0.065  +0.037  -0.056  -0.181  -0.303  -0.325  -0.327  -0.266  +0.036  +0.000  -0.084  -0.205  -0.269  -0.302  -0.290  -0.233\n",
      "                         :    var2:  +0.261  +0.360  +1.000  +0.348  +0.251  +0.147  +0.027  +0.004  +0.303  +0.379  +0.395  +0.352  +0.248  +0.072  -0.010  -0.069  +0.279  +0.335  +0.375  +0.293  +0.154  +0.006  -0.074  -0.109  +0.252  +0.262  +0.228  +0.184  +0.006  -0.129  -0.193  -0.186  +0.152  +0.158  +0.122  -0.026  -0.199  -0.271  -0.259  -0.237  +0.070  +0.037  -0.033  -0.190  -0.284  -0.335  -0.297  -0.267  -0.002  -0.043  -0.136  -0.232  -0.344  -0.364  -0.308  -0.262  -0.054  -0.080  -0.163  -0.270  -0.307  -0.353  -0.303  -0.206\n",
      "                         :    var3:  +0.210  +0.290  +0.348  +1.000  +0.336  +0.248  +0.160  +0.080  +0.217  +0.299  +0.342  +0.364  +0.332  +0.211  +0.114  +0.058  +0.167  +0.216  +0.269  +0.298  +0.228  +0.147  +0.057  +0.003  +0.117  +0.136  +0.148  +0.122  +0.071  -0.001  -0.046  -0.053  +0.025  +0.014  -0.035  -0.076  -0.134  -0.153  -0.145  -0.124  -0.030  -0.103  -0.160  -0.238  -0.293  -0.259  -0.203  -0.187  -0.108  -0.170  -0.253  -0.329  -0.361  -0.323  -0.263  -0.224  -0.129  -0.213  -0.274  -0.333  -0.342  -0.308  -0.282  -0.186\n",
      "                         :    var4:  +0.091  +0.176  +0.251  +0.336  +1.000  +0.333  +0.279  +0.189  +0.088  +0.151  +0.215  +0.319  +0.362  +0.333  +0.283  +0.187  +0.033  +0.060  +0.131  +0.258  +0.270  +0.278  +0.207  +0.173  -0.025  -0.038  -0.004  +0.074  +0.123  +0.146  +0.124  +0.090  -0.114  -0.148  -0.161  -0.142  -0.084  -0.039  +0.003  +0.014  -0.165  -0.217  -0.256  -0.283  -0.247  -0.149  -0.093  -0.061  -0.222  -0.253  -0.329  -0.365  -0.315  -0.247  -0.155  -0.111  -0.194  -0.263  -0.321  -0.346  -0.331  -0.275  -0.179  -0.113\n",
      "                         :    var5:  -0.039  +0.029  +0.147  +0.248  +0.333  +1.000  +0.326  +0.283  -0.036  -0.006  +0.087  +0.242  +0.355  +0.386  +0.372  +0.277  -0.102  -0.085  +0.007  +0.162  +0.278  +0.356  +0.311  +0.284  -0.159  -0.172  -0.143  +0.001  +0.161  +0.258  +0.257  +0.218  -0.225  -0.268  -0.261  -0.180  +0.011  +0.109  +0.155  +0.153  -0.260  -0.309  -0.331  -0.273  -0.177  -0.027  +0.062  +0.079  -0.247  -0.316  -0.356  -0.323  -0.248  -0.122  -0.032  -0.011  -0.213  -0.295  -0.321  -0.317  -0.261  -0.162  -0.101  -0.042\n",
      "                         :    var6:  -0.087  -0.055  +0.027  +0.160  +0.279  +0.326  +1.000  +0.280  -0.126  -0.101  -0.015  +0.145  +0.285  +0.384  +0.377  +0.333  -0.170  -0.164  -0.098  +0.073  +0.255  +0.344  +0.372  +0.342  -0.233  -0.253  -0.204  -0.063  +0.151  +0.293  +0.315  +0.284  -0.281  -0.289  -0.304  -0.190  +0.026  +0.145  +0.230  +0.222  -0.268  -0.331  -0.342  -0.263  -0.102  +0.056  +0.152  +0.131  -0.274  -0.318  -0.331  -0.275  -0.140  -0.033  +0.065  +0.082  -0.211  -0.268  -0.308  -0.274  -0.174  -0.090  -0.001  +0.009\n",
      "                         :    var7:  -0.103  -0.073  +0.004  +0.080  +0.189  +0.283  +0.280  +1.000  -0.126  -0.118  -0.062  +0.085  +0.198  +0.295  +0.331  +0.264  -0.181  -0.158  -0.103  +0.021  +0.175  +0.298  +0.311  +0.277  -0.203  -0.222  -0.203  -0.092  +0.124  +0.256  +0.291  +0.252  -0.224  -0.284  -0.261  -0.158  +0.046  +0.166  +0.216  +0.219  -0.244  -0.269  -0.278  -0.208  -0.062  +0.081  +0.158  +0.153  -0.211  -0.265  -0.250  -0.207  -0.094  +0.003  +0.067  +0.095  -0.194  -0.202  -0.214  -0.198  -0.127  -0.034  +0.033  +0.036\n",
      "                         :    var8:  +0.279  +0.345  +0.303  +0.217  +0.088  -0.036  -0.126  -0.126  +1.000  +0.369  +0.340  +0.222  +0.051  -0.128  -0.185  -0.183  +0.364  +0.377  +0.357  +0.213  -0.020  -0.172  -0.240  -0.252  +0.342  +0.371  +0.321  +0.158  -0.105  -0.271  -0.314  -0.280  +0.283  +0.305  +0.227  +0.064  -0.190  -0.323  -0.355  -0.297  +0.227  +0.215  +0.139  -0.058  -0.217  -0.345  -0.351  -0.296  +0.175  +0.132  +0.044  -0.099  -0.258  -0.296  -0.320  -0.257  +0.099  +0.062  -0.001  -0.088  -0.221  -0.277  -0.278  -0.185\n",
      "                         :    var9:  +0.321  +0.395  +0.379  +0.299  +0.151  -0.006  -0.101  -0.118  +0.369  +1.000  +0.428  +0.311  +0.119  -0.077  -0.167  -0.181  +0.385  +0.432  +0.418  +0.271  +0.035  -0.159  -0.238  -0.245  +0.370  +0.385  +0.346  +0.197  -0.096  -0.261  -0.337  -0.306  +0.297  +0.329  +0.248  +0.055  -0.210  -0.354  -0.384  -0.347  +0.226  +0.221  +0.113  -0.079  -0.304  -0.397  -0.396  -0.354  +0.140  +0.092  +0.014  -0.149  -0.332  -0.379  -0.385  -0.313  +0.074  +0.041  -0.051  -0.183  -0.290  -0.345  -0.354  -0.264\n",
      "                         :   var10:  +0.296  +0.380  +0.395  +0.342  +0.215  +0.087  -0.015  -0.062  +0.340  +0.428  +1.000  +0.360  +0.212  +0.037  -0.061  -0.124  +0.325  +0.399  +0.406  +0.309  +0.112  -0.064  -0.172  -0.185  +0.311  +0.340  +0.313  +0.201  -0.027  -0.195  -0.261  -0.260  +0.221  +0.241  +0.169  +0.019  -0.199  -0.324  -0.340  -0.310  +0.158  +0.128  +0.016  -0.141  -0.327  -0.397  -0.376  -0.340  +0.069  +0.025  -0.065  -0.212  -0.344  -0.396  -0.388  -0.317  +0.002  -0.055  -0.125  -0.253  -0.326  -0.365  -0.345  -0.288\n",
      "                         :   var11:  +0.202  +0.288  +0.352  +0.364  +0.319  +0.242  +0.145  +0.085  +0.222  +0.311  +0.360  +1.000  +0.329  +0.186  +0.115  +0.036  +0.166  +0.234  +0.295  +0.299  +0.209  +0.117  +0.034  -0.003  +0.129  +0.148  +0.156  +0.150  +0.041  -0.017  -0.085  -0.095  +0.043  +0.052  +0.010  -0.050  -0.140  -0.193  -0.181  -0.167  +0.003  -0.050  -0.124  -0.222  -0.308  -0.282  -0.235  -0.223  -0.077  -0.140  -0.214  -0.312  -0.348  -0.340  -0.290  -0.230  -0.105  -0.172  -0.229  -0.315  -0.349  -0.343  -0.293  -0.217\n",
      "                         :   var12:  +0.085  +0.164  +0.248  +0.332  +0.362  +0.355  +0.285  +0.198  +0.051  +0.119  +0.212  +0.329  +1.000  +0.347  +0.295  +0.195  -0.009  +0.041  +0.133  +0.257  +0.311  +0.281  +0.237  +0.171  -0.057  -0.048  -0.023  +0.087  +0.142  +0.158  +0.141  +0.122  -0.147  -0.178  -0.180  -0.169  -0.056  -0.006  +0.034  +0.043  -0.190  -0.246  -0.293  -0.298  -0.254  -0.128  -0.054  -0.029  -0.237  -0.292  -0.331  -0.342  -0.295  -0.218  -0.131  -0.096  -0.239  -0.289  -0.338  -0.371  -0.313  -0.272  -0.188  -0.106\n",
      "                         :   var13:  -0.098  -0.016  +0.072  +0.211  +0.333  +0.386  +0.384  +0.295  -0.128  -0.077  +0.037  +0.186  +0.347  +1.000  +0.414  +0.324  -0.195  -0.167  -0.070  +0.135  +0.285  +0.402  +0.377  +0.347  -0.246  -0.239  -0.212  -0.042  +0.184  +0.320  +0.338  +0.282  -0.294  -0.340  -0.337  -0.202  +0.013  +0.175  +0.224  +0.219  -0.305  -0.367  -0.372  -0.304  -0.116  +0.042  +0.142  +0.154  -0.336  -0.362  -0.384  -0.325  -0.188  -0.065  +0.026  +0.051  -0.269  -0.326  -0.347  -0.326  -0.236  -0.124  -0.028  -0.019\n",
      "                         :   var14:  -0.151  -0.082  -0.010  +0.114  +0.283  +0.372  +0.377  +0.331  -0.185  -0.167  -0.061  +0.115  +0.295  +0.414  +1.000  +0.353  -0.241  -0.249  -0.143  +0.051  +0.268  +0.404  +0.418  +0.371  -0.299  -0.307  -0.276  -0.077  +0.185  +0.344  +0.390  +0.342  -0.332  -0.369  -0.353  -0.201  +0.073  +0.236  +0.290  +0.283  -0.324  -0.392  -0.377  -0.270  -0.062  +0.107  +0.212  +0.206  -0.308  -0.378  -0.361  -0.284  -0.115  +0.005  +0.126  +0.120  -0.253  -0.304  -0.320  -0.277  -0.164  -0.044  +0.044  +0.047\n",
      "                         :   var15:  -0.145  -0.147  -0.069  +0.058  +0.187  +0.277  +0.333  +0.264  -0.183  -0.181  -0.124  +0.036  +0.195  +0.324  +0.353  +1.000  -0.246  -0.256  -0.196  -0.029  +0.191  +0.349  +0.378  +0.367  -0.274  -0.311  -0.280  -0.128  +0.149  +0.319  +0.378  +0.345  -0.301  -0.349  -0.318  -0.185  +0.060  +0.256  +0.309  +0.297  -0.303  -0.343  -0.330  -0.221  -0.037  +0.163  +0.240  +0.248  -0.260  -0.312  -0.319  -0.217  -0.056  +0.053  +0.153  +0.164  -0.218  -0.249  -0.252  -0.182  -0.103  +0.026  +0.101  +0.103\n",
      "                         :   var16:  +0.308  +0.337  +0.279  +0.167  +0.033  -0.102  -0.170  -0.181  +0.364  +0.385  +0.325  +0.166  -0.009  -0.195  -0.241  -0.246  +1.000  +0.407  +0.381  +0.197  -0.064  -0.258  -0.323  -0.294  +0.389  +0.399  +0.350  +0.170  -0.131  -0.319  -0.374  -0.326  +0.364  +0.379  +0.292  +0.105  -0.193  -0.365  -0.408  -0.362  +0.306  +0.303  +0.207  +0.012  -0.211  -0.360  -0.377  -0.339  +0.233  +0.221  +0.111  -0.027  -0.222  -0.322  -0.340  -0.316  +0.165  +0.136  +0.048  -0.055  -0.188  -0.263  -0.289  -0.224\n",
      "                         :   var17:  +0.301  +0.370  +0.335  +0.216  +0.060  -0.085  -0.164  -0.158  +0.377  +0.432  +0.399  +0.234  +0.041  -0.167  -0.249  -0.256  +0.407  +1.000  +0.416  +0.217  -0.041  -0.254  -0.335  -0.325  +0.426  +0.440  +0.384  +0.200  -0.141  -0.327  -0.412  -0.361  +0.372  +0.413  +0.304  +0.090  -0.236  -0.391  -0.430  -0.402  +0.306  +0.301  +0.201  -0.012  -0.252  -0.401  -0.417  -0.405  +0.234  +0.222  +0.130  -0.064  -0.265  -0.361  -0.406  -0.337  +0.162  +0.104  +0.045  -0.077  -0.213  -0.333  -0.331  -0.281\n",
      "                         :   var18:  +0.313  +0.370  +0.375  +0.269  +0.131  +0.007  -0.098  -0.103  +0.357  +0.418  +0.406  +0.295  +0.133  -0.070  -0.143  -0.196  +0.381  +0.416  +1.000  +0.264  +0.060  -0.152  -0.242  -0.251  +0.378  +0.368  +0.358  +0.198  -0.058  -0.255  -0.337  -0.300  +0.297  +0.310  +0.258  +0.051  -0.201  -0.345  -0.384  -0.336  +0.227  +0.217  +0.113  -0.050  -0.293  -0.411  -0.393  -0.365  +0.135  +0.117  +0.013  -0.133  -0.323  -0.380  -0.386  -0.336  +0.074  +0.021  -0.033  -0.155  -0.286  -0.364  -0.347  -0.255\n",
      "                         :   var19:  +0.190  +0.274  +0.293  +0.298  +0.258  +0.162  +0.073  +0.021  +0.213  +0.271  +0.309  +0.299  +0.257  +0.135  +0.051  -0.029  +0.197  +0.217  +0.264  +1.000  +0.170  +0.062  -0.019  -0.078  +0.153  +0.173  +0.175  +0.132  +0.038  -0.054  -0.123  -0.121  +0.093  +0.083  +0.071  -0.020  -0.124  -0.191  -0.211  -0.170  +0.027  -0.007  -0.043  -0.168  -0.252  -0.286  -0.249  -0.228  -0.032  -0.064  -0.138  -0.226  -0.289  -0.304  -0.276  -0.240  -0.073  -0.106  -0.163  -0.261  -0.313  -0.308  -0.299  -0.209\n",
      "                         :   var20:  +0.010  +0.074  +0.154  +0.228  +0.270  +0.278  +0.255  +0.175  -0.020  +0.035  +0.112  +0.209  +0.311  +0.285  +0.268  +0.191  -0.064  -0.041  +0.060  +0.170  +1.000  +0.270  +0.220  +0.198  -0.130  -0.116  -0.071  +0.012  +0.125  +0.193  +0.168  +0.136  -0.172  -0.188  -0.191  -0.114  -0.016  +0.063  +0.079  +0.090  -0.215  -0.253  -0.255  -0.222  -0.138  -0.069  +0.018  +0.032  -0.225  -0.272  -0.309  -0.282  -0.222  -0.145  -0.067  -0.025  -0.205  -0.262  -0.268  -0.284  -0.227  -0.156  -0.108  -0.072\n",
      "                         :   var21:  -0.095  -0.097  +0.006  +0.147  +0.278  +0.356  +0.344  +0.298  -0.172  -0.159  -0.064  +0.117  +0.281  +0.402  +0.404  +0.349  -0.258  -0.254  -0.152  +0.062  +0.270  +1.000  +0.418  +0.372  -0.309  -0.321  -0.277  -0.090  +0.212  +0.362  +0.383  +0.329  -0.345  -0.388  -0.359  -0.197  +0.065  +0.246  +0.293  +0.296  -0.365  -0.411  -0.379  -0.263  -0.057  +0.136  +0.212  +0.220  -0.336  -0.386  -0.394  -0.287  -0.113  +0.022  +0.115  +0.160  -0.283  -0.338  -0.324  -0.260  -0.154  -0.015  +0.061  +0.069\n",
      "                         :   var22:  -0.191  -0.178  -0.074  +0.057  +0.207  +0.311  +0.372  +0.311  -0.240  -0.238  -0.172  +0.034  +0.237  +0.377  +0.418  +0.378  -0.323  -0.335  -0.242  -0.019  +0.220  +0.418  +1.000  +0.410  -0.357  -0.386  -0.347  -0.141  +0.184  +0.396  +0.449  +0.407  -0.397  -0.439  -0.410  -0.239  +0.118  +0.298  +0.385  +0.379  -0.378  -0.427  -0.395  -0.238  +0.017  +0.228  +0.308  +0.301  -0.338  -0.377  -0.370  -0.243  -0.039  +0.122  +0.233  +0.210  -0.288  -0.316  -0.302  -0.239  -0.097  +0.042  +0.142  +0.141\n",
      "                         :   var23:  -0.184  -0.174  -0.109  +0.003  +0.173  +0.284  +0.342  +0.277  -0.252  -0.245  -0.185  -0.003  +0.171  +0.347  +0.371  +0.367  -0.294  -0.325  -0.251  -0.078  +0.198  +0.372  +0.410  +1.000  -0.352  -0.367  -0.337  -0.132  +0.170  +0.338  +0.435  +0.389  -0.371  -0.410  -0.376  -0.208  +0.095  +0.299  +0.371  +0.357  -0.330  -0.393  -0.355  -0.220  +0.030  +0.239  +0.307  +0.312  -0.322  -0.343  -0.310  -0.207  -0.018  +0.131  +0.247  +0.241  -0.249  -0.289  -0.269  -0.177  -0.050  +0.089  +0.139  +0.154\n",
      "                         :   var24:  +0.287  +0.302  +0.252  +0.117  -0.025  -0.159  -0.233  -0.203  +0.342  +0.370  +0.311  +0.129  -0.057  -0.246  -0.299  -0.274  +0.389  +0.426  +0.378  +0.153  -0.130  -0.309  -0.357  -0.352  +1.000  +0.432  +0.375  +0.155  -0.158  -0.389  -0.431  -0.351  +0.393  +0.436  +0.360  +0.106  -0.212  -0.388  -0.425  -0.392  +0.354  +0.358  +0.275  +0.068  -0.203  -0.361  -0.392  -0.377  +0.278  +0.285  +0.215  +0.024  -0.188  -0.298  -0.348  -0.312  +0.214  +0.210  +0.138  +0.001  -0.132  -0.254  -0.276  -0.253\n",
      "                         :   var25:  +0.276  +0.325  +0.262  +0.136  -0.038  -0.172  -0.253  -0.222  +0.371  +0.385  +0.340  +0.148  -0.048  -0.239  -0.307  -0.311  +0.399  +0.440  +0.368  +0.173  -0.116  -0.321  -0.386  -0.367  +0.432  +1.000  +0.401  +0.178  -0.174  -0.394  -0.460  -0.388  +0.416  +0.447  +0.371  +0.145  -0.207  -0.405  -0.456  -0.422  +0.381  +0.365  +0.281  +0.070  -0.195  -0.398  -0.432  -0.384  +0.308  +0.289  +0.214  +0.046  -0.175  -0.318  -0.385  -0.341  +0.206  +0.207  +0.152  +0.027  -0.163  -0.270  -0.313  -0.257\n",
      "                         :   var26:  +0.252  +0.294  +0.228  +0.148  -0.004  -0.143  -0.204  -0.203  +0.321  +0.346  +0.313  +0.156  -0.023  -0.212  -0.276  -0.280  +0.350  +0.384  +0.358  +0.175  -0.071  -0.277  -0.347  -0.337  +0.375  +0.401  +1.000  +0.164  -0.140  -0.336  -0.408  -0.364  +0.340  +0.388  +0.332  +0.139  -0.186  -0.376  -0.423  -0.386  +0.312  +0.333  +0.246  +0.062  -0.185  -0.363  -0.387  -0.362  +0.239  +0.245  +0.183  +0.026  -0.179  -0.312  -0.353  -0.331  +0.176  +0.168  +0.121  -0.005  -0.153  -0.239  -0.286  -0.260\n",
      "                         :   var27:  +0.113  +0.182  +0.184  +0.122  +0.074  +0.001  -0.063  -0.092  +0.158  +0.197  +0.201  +0.150  +0.087  -0.042  -0.077  -0.128  +0.170  +0.200  +0.198  +0.132  +0.012  -0.090  -0.141  -0.132  +0.155  +0.178  +0.164  +1.000  -0.025  -0.129  -0.192  -0.179  +0.138  +0.150  +0.134  +0.030  -0.123  -0.175  -0.211  -0.220  +0.113  +0.097  +0.055  -0.003  -0.152  -0.206  -0.223  -0.211  +0.064  +0.048  -0.007  -0.070  -0.150  -0.201  -0.205  -0.190  +0.027  +0.037  -0.009  -0.077  -0.138  -0.176  -0.184  -0.157\n",
      "                         :   var28:  -0.070  -0.076  +0.006  +0.071  +0.123  +0.161  +0.151  +0.124  -0.105  -0.096  -0.027  +0.041  +0.142  +0.184  +0.185  +0.149  -0.131  -0.141  -0.058  +0.038  +0.125  +0.212  +0.184  +0.170  -0.158  -0.174  -0.140  -0.025  +1.000  +0.153  +0.183  +0.139  -0.191  -0.219  -0.167  -0.092  +0.042  +0.122  +0.143  +0.138  -0.183  -0.234  -0.211  -0.136  -0.001  +0.082  +0.120  +0.090  -0.192  -0.222  -0.193  -0.147  -0.031  +0.011  +0.088  +0.075  -0.185  -0.184  -0.165  -0.154  -0.079  -0.023  +0.044  +0.061\n",
      "                         :   var29:  -0.217  -0.204  -0.129  -0.001  +0.146  +0.258  +0.293  +0.256  -0.271  -0.261  -0.195  -0.017  +0.158  +0.320  +0.344  +0.319  -0.319  -0.327  -0.255  -0.054  +0.193  +0.362  +0.396  +0.338  -0.389  -0.394  -0.336  -0.129  +0.153  +1.000  +0.426  +0.369  -0.385  -0.429  -0.386  -0.199  +0.138  +0.319  +0.369  +0.355  -0.374  -0.397  -0.353  -0.160  +0.059  +0.260  +0.333  +0.307  -0.340  -0.352  -0.333  -0.178  +0.019  +0.166  +0.254  +0.243  -0.270  -0.273  -0.275  -0.159  -0.016  +0.107  +0.175  +0.172\n",
      "                         :   var30:  -0.250  -0.269  -0.193  -0.046  +0.124  +0.257  +0.315  +0.291  -0.314  -0.337  -0.261  -0.085  +0.141  +0.338  +0.390  +0.378  -0.374  -0.412  -0.337  -0.123  +0.168  +0.383  +0.449  +0.435  -0.431  -0.460  -0.408  -0.192  +0.183  +0.426  +1.000  +0.455  -0.436  -0.485  -0.450  -0.210  +0.156  +0.385  +0.474  +0.450  -0.419  -0.465  -0.390  -0.209  +0.099  +0.316  +0.401  +0.404  -0.349  -0.393  -0.341  -0.195  +0.066  +0.232  +0.327  +0.317  -0.281  -0.293  -0.262  -0.157  +0.017  +0.164  +0.242  +0.244\n",
      "                         :   var31:  -0.221  -0.239  -0.186  -0.053  +0.090  +0.218  +0.284  +0.252  -0.280  -0.306  -0.260  -0.095  +0.122  +0.282  +0.342  +0.345  -0.326  -0.361  -0.300  -0.121  +0.136  +0.329  +0.407  +0.389  -0.351  -0.388  -0.364  -0.179  +0.139  +0.369  +0.455  +1.000  -0.381  -0.419  -0.398  -0.196  +0.126  +0.329  +0.417  +0.390  -0.347  -0.400  -0.336  -0.164  +0.083  +0.300  +0.382  +0.358  -0.314  -0.333  -0.288  -0.155  +0.051  +0.222  +0.296  +0.290  -0.231  -0.258  -0.215  -0.138  +0.034  +0.154  +0.236  +0.203\n",
      "                         :   var32:  +0.227  +0.241  +0.152  +0.025  -0.114  -0.225  -0.281  -0.224  +0.283  +0.297  +0.221  +0.043  -0.147  -0.294  -0.332  -0.301  +0.364  +0.372  +0.297  +0.093  -0.172  -0.345  -0.397  -0.371  +0.393  +0.416  +0.340  +0.138  -0.191  -0.385  -0.436  -0.381  +1.000  +0.434  +0.371  +0.158  -0.183  -0.368  -0.413  -0.372  +0.382  +0.418  +0.356  +0.123  -0.130  -0.323  -0.381  -0.349  +0.347  +0.342  +0.274  +0.118  -0.110  -0.238  -0.306  -0.291  +0.272  +0.284  +0.206  +0.102  -0.065  -0.180  -0.243  -0.233\n",
      "                         :   var33:  +0.233  +0.229  +0.158  +0.014  -0.148  -0.268  -0.289  -0.284  +0.305  +0.329  +0.241  +0.052  -0.178  -0.340  -0.369  -0.349  +0.379  +0.413  +0.310  +0.083  -0.188  -0.388  -0.439  -0.410  +0.436  +0.447  +0.388  +0.150  -0.219  -0.429  -0.485  -0.419  +0.434  +1.000  +0.410  +0.182  -0.178  -0.389  -0.457  -0.415  +0.418  +0.451  +0.373  +0.174  -0.109  -0.355  -0.426  -0.364  +0.366  +0.379  +0.331  +0.166  -0.092  -0.258  -0.341  -0.298  +0.287  +0.299  +0.260  +0.126  -0.037  -0.181  -0.259  -0.238\n",
      "                         :   var34:  +0.188  +0.188  +0.122  -0.035  -0.161  -0.261  -0.304  -0.261  +0.227  +0.248  +0.169  +0.010  -0.180  -0.337  -0.353  -0.318  +0.292  +0.304  +0.258  +0.071  -0.191  -0.359  -0.410  -0.376  +0.360  +0.371  +0.332  +0.134  -0.167  -0.386  -0.450  -0.398  +0.371  +0.410  +1.000  +0.181  -0.133  -0.339  -0.404  -0.360  +0.388  +0.409  +0.357  +0.177  -0.075  -0.290  -0.339  -0.322  +0.309  +0.338  +0.314  +0.183  -0.049  -0.179  -0.261  -0.267  +0.249  +0.289  +0.252  +0.152  -0.001  -0.123  -0.201  -0.194\n",
      "                         :   var35:  +0.026  +0.023  -0.026  -0.076  -0.142  -0.180  -0.190  -0.158  +0.064  +0.055  +0.019  -0.050  -0.169  -0.202  -0.201  -0.185  +0.105  +0.090  +0.051  -0.020  -0.114  -0.197  -0.239  -0.208  +0.106  +0.145  +0.139  +0.030  -0.092  -0.199  -0.210  -0.196  +0.158  +0.182  +0.181  +1.000  -0.014  -0.148  -0.180  -0.184  +0.181  +0.196  +0.198  +0.135  +0.033  -0.089  -0.134  -0.123  +0.167  +0.200  +0.190  +0.145  +0.055  -0.043  -0.093  -0.094  +0.135  +0.160  +0.168  +0.141  +0.065  -0.001  -0.049  -0.049\n",
      "                         :   var36:  -0.167  -0.196  -0.199  -0.134  -0.084  +0.011  +0.026  +0.046  -0.190  -0.210  -0.199  -0.140  -0.056  +0.013  +0.073  +0.060  -0.193  -0.236  -0.201  -0.124  -0.016  +0.065  +0.118  +0.095  -0.212  -0.207  -0.186  -0.123  +0.042  +0.138  +0.156  +0.126  -0.183  -0.178  -0.133  -0.014  +1.000  +0.180  +0.184  +0.158  -0.167  -0.133  -0.087  +0.025  +0.140  +0.211  +0.190  +0.174  -0.103  -0.083  -0.022  +0.056  +0.158  +0.184  +0.196  +0.163  -0.083  -0.045  +0.001  +0.081  +0.139  +0.166  +0.171  +0.144\n",
      "                         :   var37:  -0.252  -0.292  -0.271  -0.153  -0.039  +0.109  +0.145  +0.166  -0.323  -0.354  -0.324  -0.193  -0.006  +0.175  +0.236  +0.256  -0.365  -0.391  -0.345  -0.191  +0.063  +0.246  +0.298  +0.299  -0.388  -0.405  -0.376  -0.175  +0.122  +0.319  +0.385  +0.329  -0.368  -0.389  -0.339  -0.148  +0.180  +1.000  +0.392  +0.375  -0.322  -0.329  -0.246  -0.042  +0.173  +0.374  +0.388  +0.363  -0.247  -0.259  -0.176  -0.007  +0.206  +0.317  +0.352  +0.328  -0.189  -0.194  -0.136  -0.003  +0.154  +0.268  +0.303  +0.254\n",
      "                         :   var38:  -0.301  -0.316  -0.259  -0.145  +0.003  +0.155  +0.230  +0.216  -0.355  -0.384  -0.340  -0.181  +0.034  +0.224  +0.290  +0.309  -0.408  -0.430  -0.384  -0.211  +0.079  +0.293  +0.385  +0.371  -0.425  -0.456  -0.423  -0.211  +0.143  +0.369  +0.474  +0.417  -0.413  -0.457  -0.404  -0.180  +0.184  +0.392  +1.000  +0.444  -0.391  -0.404  -0.318  -0.114  +0.175  +0.393  +0.458  +0.415  -0.322  -0.332  -0.247  -0.079  +0.195  +0.346  +0.410  +0.369  -0.235  -0.230  -0.177  -0.039  +0.137  +0.269  +0.344  +0.291\n",
      "                         :   var39:  -0.233  -0.270  -0.237  -0.124  +0.014  +0.153  +0.222  +0.219  -0.297  -0.347  -0.310  -0.167  +0.043  +0.219  +0.283  +0.297  -0.362  -0.402  -0.336  -0.170  +0.090  +0.296  +0.379  +0.357  -0.392  -0.422  -0.386  -0.220  +0.138  +0.355  +0.450  +0.390  -0.372  -0.415  -0.360  -0.184  +0.158  +0.375  +0.444  +1.000  -0.357  -0.383  -0.302  -0.124  +0.175  +0.345  +0.425  +0.393  -0.285  -0.322  -0.230  -0.092  +0.150  +0.286  +0.372  +0.341  -0.214  -0.234  -0.168  -0.040  +0.114  +0.245  +0.307  +0.262\n",
      "                         :   var40:  +0.177  +0.154  +0.070  -0.030  -0.165  -0.260  -0.268  -0.244  +0.227  +0.226  +0.158  +0.003  -0.190  -0.305  -0.324  -0.303  +0.306  +0.306  +0.227  +0.027  -0.215  -0.365  -0.378  -0.330  +0.354  +0.381  +0.312  +0.113  -0.183  -0.374  -0.419  -0.347  +0.382  +0.418  +0.388  +0.181  -0.167  -0.322  -0.391  -0.357  +1.000  +0.427  +0.371  +0.190  -0.082  -0.265  -0.345  -0.330  +0.363  +0.381  +0.327  +0.185  -0.052  -0.189  -0.277  -0.269  +0.278  +0.300  +0.279  +0.157  -0.010  -0.116  -0.220  -0.197\n",
      "                         :   var41:  +0.155  +0.141  +0.037  -0.103  -0.217  -0.309  -0.331  -0.269  +0.215  +0.221  +0.128  -0.050  -0.246  -0.367  -0.392  -0.343  +0.303  +0.301  +0.217  -0.007  -0.253  -0.411  -0.427  -0.393  +0.358  +0.365  +0.333  +0.097  -0.234  -0.397  -0.465  -0.400  +0.418  +0.451  +0.409  +0.196  -0.133  -0.329  -0.404  -0.383  +0.427  +1.000  +0.418  +0.243  -0.034  -0.263  -0.348  -0.337  +0.397  +0.439  +0.398  +0.263  +0.001  -0.165  -0.276  -0.264  +0.314  +0.354  +0.331  +0.233  +0.045  -0.102  -0.198  -0.192\n",
      "                         :   var42:  +0.078  +0.050  -0.033  -0.160  -0.256  -0.331  -0.342  -0.278  +0.139  +0.113  +0.016  -0.124  -0.293  -0.372  -0.377  -0.330  +0.207  +0.201  +0.113  -0.043  -0.255  -0.379  -0.395  -0.355  +0.275  +0.281  +0.246  +0.055  -0.211  -0.353  -0.390  -0.336  +0.356  +0.373  +0.357  +0.198  -0.087  -0.246  -0.318  -0.302  +0.371  +0.418  +1.000  +0.260  +0.044  -0.135  -0.258  -0.252  +0.355  +0.414  +0.399  +0.290  +0.092  -0.048  -0.175  -0.197  +0.315  +0.363  +0.348  +0.269  +0.133  -0.006  -0.087  -0.112\n",
      "                         :   var43:  -0.048  -0.135  -0.190  -0.238  -0.283  -0.273  -0.263  -0.208  -0.058  -0.079  -0.141  -0.222  -0.298  -0.304  -0.270  -0.221  +0.012  -0.012  -0.050  -0.168  -0.222  -0.263  -0.238  -0.220  +0.068  +0.070  +0.062  -0.003  -0.136  -0.160  -0.209  -0.164  +0.123  +0.174  +0.177  +0.135  +0.025  -0.042  -0.114  -0.124  +0.190  +0.243  +0.260  +1.000  +0.157  +0.042  -0.054  -0.072  +0.195  +0.269  +0.308  +0.292  +0.212  +0.135  +0.023  -0.018  +0.196  +0.251  +0.279  +0.316  +0.224  +0.152  +0.074  +0.029\n",
      "                         :   var44:  -0.203  -0.282  -0.284  -0.293  -0.247  -0.177  -0.102  -0.062  -0.217  -0.304  -0.327  -0.308  -0.254  -0.116  -0.062  -0.037  -0.211  -0.252  -0.293  -0.252  -0.138  -0.057  +0.017  +0.030  -0.203  -0.195  -0.185  -0.152  -0.001  +0.059  +0.099  +0.083  -0.130  -0.109  -0.075  +0.033  +0.140  +0.173  +0.175  +0.175  -0.082  -0.034  +0.044  +0.157  +1.000  +0.274  +0.232  +0.203  -0.028  +0.032  +0.110  +0.221  +0.316  +0.316  +0.260  +0.227  +0.037  +0.088  +0.135  +0.236  +0.300  +0.314  +0.267  +0.199\n",
      "                         :   var45:  -0.273  -0.348  -0.335  -0.259  -0.149  -0.027  +0.056  +0.081  -0.345  -0.397  -0.397  -0.282  -0.128  +0.042  +0.107  +0.163  -0.360  -0.401  -0.411  -0.286  -0.069  +0.136  +0.228  +0.239  -0.361  -0.398  -0.363  -0.206  +0.082  +0.260  +0.316  +0.300  -0.323  -0.355  -0.290  -0.089  +0.211  +0.374  +0.393  +0.345  -0.265  -0.263  -0.135  +0.042  +0.274  +1.000  +0.426  +0.373  -0.194  -0.174  -0.075  +0.093  +0.309  +0.397  +0.414  +0.369  -0.127  -0.088  -0.009  +0.126  +0.274  +0.362  +0.374  +0.305\n",
      "                         :   var46:  -0.293  -0.323  -0.297  -0.203  -0.093  +0.062  +0.152  +0.158  -0.351  -0.396  -0.376  -0.235  -0.054  +0.142  +0.212  +0.240  -0.377  -0.417  -0.393  -0.249  +0.018  +0.212  +0.308  +0.307  -0.392  -0.432  -0.387  -0.223  +0.120  +0.333  +0.401  +0.382  -0.381  -0.426  -0.339  -0.134  +0.190  +0.388  +0.458  +0.425  -0.345  -0.348  -0.258  -0.054  +0.232  +0.426  +1.000  +0.415  -0.264  -0.265  -0.160  +0.009  +0.250  +0.371  +0.423  +0.384  -0.179  -0.164  -0.100  +0.039  +0.218  +0.326  +0.366  +0.320\n",
      "                         :   var47:  -0.241  -0.294  -0.267  -0.187  -0.061  +0.079  +0.131  +0.153  -0.296  -0.354  -0.340  -0.223  -0.029  +0.154  +0.206  +0.248  -0.339  -0.405  -0.365  -0.228  +0.032  +0.220  +0.301  +0.312  -0.377  -0.384  -0.362  -0.211  +0.090  +0.307  +0.404  +0.358  -0.349  -0.364  -0.322  -0.123  +0.174  +0.363  +0.415  +0.393  -0.330  -0.337  -0.252  -0.072  +0.203  +0.373  +0.415  +1.000  -0.249  -0.252  -0.175  -0.011  +0.209  +0.316  +0.395  +0.351  -0.187  -0.171  -0.112  +0.008  +0.167  +0.292  +0.338  +0.286\n",
      "                         :   var48:  +0.110  +0.065  -0.002  -0.108  -0.222  -0.247  -0.274  -0.211  +0.175  +0.140  +0.069  -0.077  -0.237  -0.336  -0.308  -0.260  +0.233  +0.234  +0.135  -0.032  -0.225  -0.336  -0.338  -0.322  +0.278  +0.308  +0.239  +0.064  -0.192  -0.340  -0.349  -0.314  +0.347  +0.366  +0.309  +0.167  -0.103  -0.247  -0.322  -0.285  +0.363  +0.397  +0.355  +0.195  -0.028  -0.194  -0.264  -0.249  +1.000  +0.377  +0.353  +0.216  +0.023  -0.114  -0.191  -0.207  +0.291  +0.326  +0.299  +0.222  +0.074  -0.043  -0.122  -0.127\n",
      "                         :   var49:  +0.075  +0.037  -0.043  -0.170  -0.253  -0.316  -0.318  -0.265  +0.132  +0.092  +0.025  -0.140  -0.292  -0.362  -0.378  -0.312  +0.221  +0.222  +0.117  -0.064  -0.272  -0.386  -0.377  -0.343  +0.285  +0.289  +0.245  +0.048  -0.222  -0.352  -0.393  -0.333  +0.342  +0.379  +0.338  +0.200  -0.083  -0.259  -0.332  -0.322  +0.381  +0.439  +0.414  +0.269  +0.032  -0.174  -0.265  -0.252  +0.377  +1.000  +0.419  +0.276  +0.083  -0.064  -0.178  -0.189  +0.333  +0.376  +0.373  +0.285  +0.125  -0.006  -0.106  -0.128\n",
      "                         :   var50:  +0.018  -0.056  -0.136  -0.253  -0.329  -0.356  -0.331  -0.250  +0.044  +0.014  -0.065  -0.214  -0.331  -0.384  -0.361  -0.319  +0.111  +0.130  +0.013  -0.138  -0.309  -0.394  -0.370  -0.310  +0.215  +0.214  +0.183  -0.007  -0.193  -0.333  -0.341  -0.288  +0.274  +0.331  +0.314  +0.190  -0.022  -0.176  -0.247  -0.230  +0.327  +0.398  +0.399  +0.308  +0.110  -0.075  -0.160  -0.175  +0.353  +0.419  +1.000  +0.355  +0.190  +0.040  -0.072  -0.128  +0.306  +0.352  +0.411  +0.361  +0.233  +0.071  -0.012  -0.066\n",
      "                         :   var51:  -0.103  -0.181  -0.232  -0.329  -0.365  -0.323  -0.275  -0.207  -0.099  -0.149  -0.212  -0.312  -0.342  -0.325  -0.284  -0.217  -0.027  -0.064  -0.133  -0.226  -0.282  -0.287  -0.243  -0.207  +0.024  +0.046  +0.026  -0.070  -0.147  -0.178  -0.195  -0.155  +0.118  +0.166  +0.183  +0.145  +0.056  -0.007  -0.079  -0.092  +0.185  +0.263  +0.290  +0.292  +0.221  +0.093  +0.009  -0.011  +0.216  +0.276  +0.355  +1.000  +0.293  +0.193  +0.099  +0.063  +0.229  +0.302  +0.340  +0.383  +0.329  +0.222  +0.140  +0.070\n",
      "                         :   var52:  -0.219  -0.303  -0.344  -0.361  -0.315  -0.248  -0.140  -0.094  -0.258  -0.332  -0.344  -0.348  -0.295  -0.188  -0.115  -0.056  -0.222  -0.265  -0.323  -0.289  -0.222  -0.113  -0.039  -0.018  -0.188  -0.175  -0.179  -0.150  -0.031  +0.019  +0.066  +0.051  -0.110  -0.092  -0.049  +0.055  +0.158  +0.206  +0.195  +0.150  -0.052  +0.001  +0.092  +0.212  +0.316  +0.309  +0.250  +0.209  +0.023  +0.083  +0.190  +0.293  +1.000  +0.352  +0.288  +0.229  +0.075  +0.127  +0.217  +0.317  +0.362  +0.351  +0.320  +0.223\n",
      "                         :   var53:  -0.261  -0.325  -0.364  -0.323  -0.247  -0.122  -0.033  +0.003  -0.296  -0.379  -0.396  -0.340  -0.218  -0.065  +0.005  +0.053  -0.322  -0.361  -0.380  -0.304  -0.145  +0.022  +0.122  +0.131  -0.298  -0.318  -0.312  -0.201  +0.011  +0.166  +0.232  +0.222  -0.238  -0.258  -0.179  -0.043  +0.184  +0.317  +0.346  +0.286  -0.189  -0.165  -0.048  +0.135  +0.316  +0.397  +0.371  +0.316  -0.114  -0.064  +0.040  +0.193  +0.352  +1.000  +0.407  +0.333  -0.035  +0.010  +0.076  +0.223  +0.337  +0.388  +0.377  +0.276\n",
      "                         :   var54:  -0.255  -0.327  -0.308  -0.263  -0.155  -0.032  +0.065  +0.067  -0.320  -0.385  -0.388  -0.290  -0.131  +0.026  +0.126  +0.153  -0.340  -0.406  -0.386  -0.276  -0.067  +0.115  +0.233  +0.247  -0.348  -0.385  -0.353  -0.205  +0.088  +0.254  +0.327  +0.296  -0.306  -0.341  -0.261  -0.093  +0.196  +0.352  +0.410  +0.372  -0.277  -0.276  -0.175  +0.023  +0.260  +0.414  +0.423  +0.395  -0.191  -0.178  -0.072  +0.099  +0.288  +0.407  +1.000  +0.375  -0.117  -0.092  -0.024  +0.112  +0.275  +0.353  +0.377  +0.320\n",
      "                         :   var55:  -0.226  -0.266  -0.262  -0.224  -0.111  -0.011  +0.082  +0.095  -0.257  -0.313  -0.317  -0.230  -0.096  +0.051  +0.120  +0.164  -0.316  -0.337  -0.336  -0.240  -0.025  +0.160  +0.210  +0.241  -0.312  -0.341  -0.331  -0.190  +0.075  +0.243  +0.317  +0.290  -0.291  -0.298  -0.267  -0.094  +0.163  +0.328  +0.369  +0.341  -0.269  -0.264  -0.197  -0.018  +0.227  +0.369  +0.384  +0.351  -0.207  -0.189  -0.128  +0.063  +0.229  +0.333  +0.375  +1.000  -0.121  -0.115  -0.057  +0.070  +0.217  +0.309  +0.321  +0.278\n",
      "                         :   var56:  +0.059  +0.036  -0.054  -0.129  -0.194  -0.213  -0.211  -0.194  +0.099  +0.074  +0.002  -0.105  -0.239  -0.269  -0.253  -0.218  +0.165  +0.162  +0.074  -0.073  -0.205  -0.283  -0.288  -0.249  +0.214  +0.206  +0.176  +0.027  -0.185  -0.270  -0.281  -0.231  +0.272  +0.287  +0.249  +0.135  -0.083  -0.189  -0.235  -0.214  +0.278  +0.314  +0.315  +0.196  +0.037  -0.127  -0.179  -0.187  +0.291  +0.333  +0.306  +0.229  +0.075  -0.035  -0.117  -0.121  +1.000  +0.299  +0.272  +0.215  +0.107  -0.015  -0.080  -0.087\n",
      "                         :   var57:  +0.014  +0.000  -0.080  -0.213  -0.263  -0.295  -0.268  -0.202  +0.062  +0.041  -0.055  -0.172  -0.289  -0.326  -0.304  -0.249  +0.136  +0.104  +0.021  -0.106  -0.262  -0.338  -0.316  -0.289  +0.210  +0.207  +0.168  +0.037  -0.184  -0.273  -0.293  -0.258  +0.284  +0.299  +0.289  +0.160  -0.045  -0.194  -0.230  -0.234  +0.300  +0.354  +0.363  +0.251  +0.088  -0.088  -0.164  -0.171  +0.326  +0.376  +0.352  +0.302  +0.127  +0.010  -0.092  -0.115  +0.299  +1.000  +0.340  +0.287  +0.174  +0.046  -0.039  -0.075\n",
      "                         :   var58:  -0.029  -0.084  -0.163  -0.274  -0.321  -0.321  -0.308  -0.214  -0.001  -0.051  -0.125  -0.229  -0.338  -0.347  -0.320  -0.252  +0.048  +0.045  -0.033  -0.163  -0.268  -0.324  -0.302  -0.269  +0.138  +0.152  +0.121  -0.009  -0.165  -0.275  -0.262  -0.215  +0.206  +0.260  +0.252  +0.168  +0.001  -0.136  -0.177  -0.168  +0.279  +0.331  +0.348  +0.279  +0.135  -0.009  -0.100  -0.112  +0.299  +0.373  +0.411  +0.340  +0.217  +0.076  -0.024  -0.057  +0.272  +0.340  +1.000  +0.342  +0.244  +0.135  +0.042  -0.012\n",
      "                         :   var59:  -0.113  -0.205  -0.270  -0.333  -0.346  -0.317  -0.274  -0.198  -0.088  -0.183  -0.253  -0.315  -0.371  -0.326  -0.277  -0.182  -0.055  -0.077  -0.155  -0.261  -0.284  -0.260  -0.239  -0.177  +0.001  +0.027  -0.005  -0.077  -0.154  -0.159  -0.157  -0.138  +0.102  +0.126  +0.152  +0.141  +0.081  -0.003  -0.039  -0.040  +0.157  +0.233  +0.269  +0.316  +0.236  +0.126  +0.039  +0.008  +0.222  +0.285  +0.361  +0.383  +0.317  +0.223  +0.112  +0.070  +0.215  +0.287  +0.342  +1.000  +0.347  +0.265  +0.167  +0.083\n",
      "                         :   var60:  -0.197  -0.269  -0.307  -0.342  -0.331  -0.261  -0.174  -0.127  -0.221  -0.290  -0.326  -0.349  -0.313  -0.236  -0.164  -0.103  -0.188  -0.213  -0.286  -0.313  -0.227  -0.154  -0.097  -0.050  -0.132  -0.163  -0.153  -0.138  -0.079  -0.016  +0.017  +0.034  -0.065  -0.037  -0.001  +0.065  +0.139  +0.154  +0.137  +0.114  -0.010  +0.045  +0.133  +0.224  +0.300  +0.274  +0.218  +0.167  +0.074  +0.125  +0.233  +0.329  +0.362  +0.337  +0.275  +0.217  +0.107  +0.174  +0.244  +0.347  +1.000  +0.354  +0.288  +0.187\n",
      "                         :   var61:  -0.236  -0.302  -0.353  -0.308  -0.275  -0.162  -0.090  -0.034  -0.277  -0.345  -0.365  -0.343  -0.272  -0.124  -0.044  +0.026  -0.263  -0.333  -0.364  -0.308  -0.156  -0.015  +0.042  +0.089  -0.254  -0.270  -0.239  -0.176  -0.023  +0.107  +0.164  +0.154  -0.180  -0.181  -0.123  -0.001  +0.166  +0.268  +0.269  +0.245  -0.116  -0.102  -0.006  +0.152  +0.314  +0.362  +0.326  +0.292  -0.043  -0.006  +0.071  +0.222  +0.351  +0.388  +0.353  +0.309  -0.015  +0.046  +0.135  +0.265  +0.354  +1.000  +0.349  +0.282\n",
      "                         :   var62:  -0.220  -0.290  -0.303  -0.282  -0.179  -0.101  -0.001  +0.033  -0.278  -0.354  -0.345  -0.293  -0.188  -0.028  +0.044  +0.101  -0.289  -0.331  -0.347  -0.299  -0.108  +0.061  +0.142  +0.139  -0.276  -0.313  -0.286  -0.184  +0.044  +0.175  +0.242  +0.236  -0.243  -0.259  -0.201  -0.049  +0.171  +0.303  +0.344  +0.307  -0.220  -0.198  -0.087  +0.074  +0.267  +0.374  +0.366  +0.338  -0.122  -0.106  -0.012  +0.140  +0.320  +0.377  +0.377  +0.321  -0.080  -0.039  +0.042  +0.167  +0.288  +0.349  +1.000  +0.287\n",
      "                         :   var63:  -0.184  -0.233  -0.206  -0.186  -0.113  -0.042  +0.009  +0.036  -0.185  -0.264  -0.288  -0.217  -0.106  -0.019  +0.047  +0.103  -0.224  -0.281  -0.255  -0.209  -0.072  +0.069  +0.141  +0.154  -0.253  -0.257  -0.260  -0.157  +0.061  +0.172  +0.244  +0.203  -0.233  -0.238  -0.194  -0.049  +0.144  +0.254  +0.291  +0.262  -0.197  -0.192  -0.112  +0.029  +0.199  +0.305  +0.320  +0.286  -0.127  -0.128  -0.066  +0.070  +0.223  +0.276  +0.320  +0.278  -0.087  -0.075  -0.012  +0.083  +0.187  +0.282  +0.287  +1.000\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                         :             var0    var1    var2    var3    var4    var5    var6    var7    var8    var9   var10   var11   var12   var13   var14   var15   var16   var17   var18   var19   var20   var21   var22   var23   var24   var25   var26   var27   var28   var29   var30   var31   var32   var33   var34   var35   var36   var37   var38   var39   var40   var41   var42   var43   var44   var45   var46   var47   var48   var49   var50   var51   var52   var53   var54   var55   var56   var57   var58   var59   var60   var61   var62   var63\n",
      "                         :    var0:  +1.000  +0.279  +0.265  +0.252  +0.153  +0.067  +0.016  -0.014  +0.301  +0.315  +0.310  +0.259  +0.164  +0.044  -0.000  -0.080  +0.281  +0.302  +0.311  +0.223  +0.099  -0.038  -0.120  -0.112  +0.254  +0.256  +0.243  +0.126  -0.008  -0.129  -0.168  -0.184  +0.158  +0.138  +0.081  -0.024  -0.160  -0.222  -0.260  -0.223  +0.093  +0.040  -0.028  -0.120  -0.226  -0.277  -0.276  -0.231  +0.011  -0.016  -0.072  -0.181  -0.243  -0.265  -0.263  -0.220  -0.015  -0.087  -0.123  -0.168  -0.228  -0.231  -0.225  -0.170\n",
      "                         :    var1:  +0.279  +1.000  +0.343  +0.304  +0.232  +0.126  +0.052  +0.009  +0.336  +0.370  +0.367  +0.327  +0.229  +0.093  +0.008  -0.037  +0.303  +0.340  +0.325  +0.288  +0.158  +0.017  -0.080  -0.106  +0.258  +0.269  +0.238  +0.154  +0.015  -0.116  -0.166  -0.186  +0.154  +0.123  +0.066  -0.045  -0.189  -0.248  -0.273  -0.224  +0.070  +0.013  -0.066  -0.185  -0.281  -0.309  -0.340  -0.284  -0.013  -0.067  -0.145  -0.236  -0.307  -0.329  -0.322  -0.268  -0.053  -0.123  -0.166  -0.231  -0.295  -0.284  -0.262  -0.217\n",
      "                         :    var2:  +0.265  +0.343  +1.000  +0.390  +0.314  +0.252  +0.147  +0.069  +0.313  +0.387  +0.416  +0.401  +0.339  +0.211  +0.111  +0.042  +0.292  +0.330  +0.352  +0.323  +0.245  +0.115  +0.035  -0.028  +0.218  +0.213  +0.213  +0.136  +0.069  -0.053  -0.105  -0.112  +0.097  +0.075  +0.010  -0.082  -0.197  -0.258  -0.219  -0.189  -0.009  -0.067  -0.157  -0.258  -0.341  -0.343  -0.311  -0.269  -0.078  -0.164  -0.228  -0.327  -0.382  -0.360  -0.340  -0.267  -0.123  -0.200  -0.252  -0.330  -0.363  -0.333  -0.313  -0.257\n",
      "                         :    var3:  +0.252  +0.304  +0.390  +1.000  +0.360  +0.310  +0.225  +0.186  +0.229  +0.326  +0.383  +0.395  +0.382  +0.279  +0.216  +0.131  +0.198  +0.254  +0.313  +0.331  +0.300  +0.209  +0.120  +0.066  +0.123  +0.118  +0.144  +0.136  +0.106  +0.031  +0.001  -0.036  -0.016  -0.034  -0.075  -0.109  -0.146  -0.167  -0.148  -0.114  -0.095  -0.145  -0.243  -0.285  -0.341  -0.307  -0.268  -0.209  -0.157  -0.221  -0.309  -0.377  -0.388  -0.360  -0.310  -0.221  -0.179  -0.255  -0.317  -0.359  -0.378  -0.340  -0.298  -0.210\n",
      "                         :    var4:  +0.153  +0.232  +0.314  +0.360  +1.000  +0.360  +0.311  +0.235  +0.157  +0.216  +0.306  +0.362  +0.399  +0.363  +0.309  +0.250  +0.069  +0.128  +0.216  +0.287  +0.344  +0.302  +0.254  +0.184  -0.012  +0.016  +0.041  +0.099  +0.135  +0.141  +0.134  +0.096  -0.128  -0.156  -0.147  -0.153  -0.133  -0.097  -0.032  -0.007  -0.185  -0.233  -0.317  -0.320  -0.313  -0.223  -0.168  -0.111  -0.218  -0.289  -0.337  -0.386  -0.355  -0.306  -0.238  -0.165  -0.207  -0.281  -0.347  -0.357  -0.361  -0.318  -0.241  -0.177\n",
      "                         :    var5:  +0.067  +0.126  +0.252  +0.310  +0.360  +1.000  +0.344  +0.279  +0.042  +0.133  +0.203  +0.299  +0.385  +0.374  +0.356  +0.298  -0.024  +0.047  +0.120  +0.223  +0.323  +0.344  +0.300  +0.261  -0.098  -0.102  -0.047  +0.061  +0.171  +0.210  +0.207  +0.192  -0.202  -0.208  -0.222  -0.171  -0.090  -0.001  +0.055  +0.093  -0.249  -0.296  -0.328  -0.314  -0.253  -0.159  -0.090  -0.013  -0.263  -0.323  -0.360  -0.373  -0.299  -0.222  -0.158  -0.077  -0.226  -0.284  -0.349  -0.314  -0.320  -0.253  -0.173  -0.105\n",
      "                         :    var6:  +0.016  +0.052  +0.147  +0.225  +0.311  +0.344  +1.000  +0.292  -0.024  +0.031  +0.121  +0.221  +0.338  +0.375  +0.370  +0.338  -0.085  -0.051  +0.018  +0.173  +0.298  +0.344  +0.347  +0.309  -0.177  -0.165  -0.107  +0.001  +0.178  +0.236  +0.263  +0.244  -0.240  -0.260  -0.246  -0.166  -0.056  +0.063  +0.124  +0.152  -0.272  -0.313  -0.316  -0.295  -0.191  -0.081  +0.012  +0.045  -0.248  -0.308  -0.331  -0.306  -0.230  -0.147  -0.086  -0.012  -0.217  -0.270  -0.315  -0.292  -0.254  -0.190  -0.101  -0.061\n",
      "                         :    var7:  -0.014  +0.009  +0.069  +0.186  +0.235  +0.279  +0.292  +1.000  -0.060  -0.014  +0.049  +0.156  +0.264  +0.285  +0.313  +0.290  -0.098  -0.067  -0.004  +0.082  +0.224  +0.290  +0.315  +0.271  -0.165  -0.177  -0.107  +0.003  +0.131  +0.226  +0.254  +0.243  -0.225  -0.259  -0.233  -0.141  -0.046  +0.094  +0.142  +0.178  -0.240  -0.267  -0.277  -0.239  -0.128  -0.030  +0.076  +0.102  -0.228  -0.259  -0.282  -0.254  -0.169  -0.101  -0.038  +0.013  -0.192  -0.219  -0.257  -0.215  -0.182  -0.105  -0.062  -0.002\n",
      "                         :    var8:  +0.301  +0.336  +0.313  +0.229  +0.157  +0.042  -0.024  -0.060  +1.000  +0.387  +0.356  +0.271  +0.121  +0.019  -0.079  -0.130  +0.344  +0.363  +0.344  +0.230  +0.088  -0.073  -0.159  -0.181  +0.328  +0.336  +0.283  +0.162  -0.046  -0.180  -0.238  -0.247  +0.256  +0.207  +0.150  +0.001  -0.176  -0.294  -0.308  -0.285  +0.173  +0.128  +0.028  -0.104  -0.259  -0.330  -0.346  -0.309  +0.075  +0.006  -0.057  -0.177  -0.254  -0.320  -0.317  -0.259  +0.005  -0.036  -0.086  -0.187  -0.250  -0.271  -0.280  -0.227\n",
      "                         :    var9:  +0.315  +0.370  +0.387  +0.326  +0.216  +0.133  +0.031  -0.014  +0.387  +1.000  +0.433  +0.351  +0.217  +0.074  -0.014  -0.075  +0.365  +0.400  +0.399  +0.321  +0.142  -0.009  -0.117  -0.157  +0.331  +0.341  +0.303  +0.180  +0.006  -0.161  -0.218  -0.236  +0.207  +0.205  +0.118  -0.001  -0.236  -0.321  -0.333  -0.299  +0.114  +0.055  -0.024  -0.165  -0.315  -0.391  -0.385  -0.336  +0.033  -0.045  -0.122  -0.248  -0.336  -0.381  -0.399  -0.308  -0.032  -0.087  -0.159  -0.249  -0.319  -0.342  -0.334  -0.254\n",
      "                         :   var10:  +0.310  +0.367  +0.416  +0.383  +0.306  +0.203  +0.121  +0.049  +0.356  +0.433  +1.000  +0.417  +0.307  +0.177  +0.067  -0.010  +0.321  +0.378  +0.397  +0.367  +0.231  +0.075  -0.019  -0.072  +0.269  +0.295  +0.263  +0.178  +0.059  -0.088  -0.163  -0.167  +0.143  +0.115  +0.058  -0.084  -0.193  -0.286  -0.294  -0.263  +0.046  -0.012  -0.130  -0.233  -0.345  -0.392  -0.382  -0.317  -0.037  -0.124  -0.206  -0.324  -0.395  -0.398  -0.383  -0.308  -0.092  -0.183  -0.243  -0.315  -0.378  -0.379  -0.345  -0.261\n",
      "                         :   var11:  +0.259  +0.327  +0.401  +0.395  +0.362  +0.299  +0.221  +0.156  +0.271  +0.351  +0.417  +1.000  +0.374  +0.287  +0.191  +0.123  +0.214  +0.281  +0.334  +0.329  +0.293  +0.195  +0.122  +0.053  +0.152  +0.159  +0.179  +0.163  +0.098  +0.034  -0.002  -0.033  +0.005  -0.005  -0.057  -0.115  -0.162  -0.191  -0.177  -0.138  -0.087  -0.143  -0.230  -0.295  -0.362  -0.318  -0.295  -0.227  -0.137  -0.235  -0.292  -0.375  -0.403  -0.378  -0.335  -0.241  -0.171  -0.252  -0.319  -0.366  -0.387  -0.370  -0.323  -0.229\n",
      "                         :   var12:  +0.164  +0.229  +0.339  +0.382  +0.399  +0.385  +0.338  +0.264  +0.121  +0.217  +0.307  +0.374  +1.000  +0.378  +0.342  +0.262  +0.072  +0.126  +0.215  +0.294  +0.357  +0.339  +0.268  +0.204  -0.011  -0.007  +0.037  +0.091  +0.174  +0.171  +0.136  +0.112  -0.152  -0.170  -0.187  -0.168  -0.120  -0.076  -0.022  +0.034  -0.214  -0.273  -0.336  -0.336  -0.316  -0.219  -0.154  -0.116  -0.264  -0.329  -0.372  -0.414  -0.391  -0.315  -0.233  -0.163  -0.254  -0.323  -0.379  -0.378  -0.393  -0.323  -0.239  -0.167\n",
      "                         :   var13:  +0.044  +0.093  +0.211  +0.279  +0.363  +0.374  +0.375  +0.285  +0.019  +0.074  +0.177  +0.287  +0.378  +1.000  +0.411  +0.351  -0.073  -0.010  +0.078  +0.205  +0.356  +0.387  +0.395  +0.312  -0.154  -0.137  -0.092  +0.043  +0.183  +0.275  +0.279  +0.255  -0.261  -0.293  -0.285  -0.181  -0.066  +0.051  +0.127  +0.163  -0.319  -0.354  -0.378  -0.349  -0.254  -0.105  -0.011  +0.031  -0.304  -0.385  -0.404  -0.392  -0.299  -0.194  -0.126  -0.037  -0.290  -0.363  -0.367  -0.366  -0.319  -0.235  -0.139  -0.080\n",
      "                         :   var14:  -0.000  +0.008  +0.111  +0.216  +0.309  +0.356  +0.370  +0.313  -0.079  -0.014  +0.067  +0.191  +0.342  +0.411  +1.000  +0.367  -0.136  -0.107  -0.026  +0.131  +0.307  +0.382  +0.408  +0.373  -0.220  -0.214  -0.181  -0.011  +0.190  +0.289  +0.349  +0.308  -0.325  -0.331  -0.308  -0.200  -0.010  +0.134  +0.211  +0.222  -0.319  -0.366  -0.363  -0.301  -0.172  -0.017  +0.089  +0.130  -0.312  -0.354  -0.393  -0.332  -0.220  -0.109  -0.024  +0.039  -0.255  -0.306  -0.334  -0.298  -0.235  -0.151  -0.065  -0.009\n",
      "                         :   var15:  -0.080  -0.037  +0.042  +0.131  +0.250  +0.298  +0.338  +0.290  -0.130  -0.075  -0.010  +0.123  +0.262  +0.351  +0.367  +1.000  -0.179  -0.173  -0.090  +0.054  +0.225  +0.356  +0.394  +0.336  -0.249  -0.261  -0.188  -0.041  +0.160  +0.294  +0.324  +0.334  -0.296  -0.331  -0.291  -0.175  -0.003  +0.164  +0.218  +0.259  -0.304  -0.340  -0.329  -0.261  -0.105  +0.056  +0.139  +0.178  -0.258  -0.320  -0.320  -0.253  -0.161  -0.042  +0.032  +0.076  -0.192  -0.254  -0.277  -0.221  -0.166  -0.075  -0.014  +0.018\n",
      "                         :   var16:  +0.281  +0.303  +0.292  +0.198  +0.069  -0.024  -0.085  -0.098  +0.344  +0.365  +0.321  +0.214  +0.072  -0.073  -0.136  -0.179  +1.000  +0.398  +0.344  +0.212  +0.008  -0.139  -0.234  -0.253  +0.384  +0.370  +0.308  +0.133  -0.092  -0.244  -0.294  -0.307  +0.315  +0.319  +0.203  +0.038  -0.173  -0.326  -0.371  -0.338  +0.244  +0.211  +0.125  -0.053  -0.228  -0.345  -0.372  -0.339  +0.153  +0.095  +0.043  -0.115  -0.229  -0.310  -0.339  -0.288  +0.062  +0.041  -0.026  -0.114  -0.203  -0.253  -0.279  -0.235\n",
      "                         :   var17:  +0.302  +0.340  +0.330  +0.254  +0.128  +0.047  -0.051  -0.067  +0.363  +0.400  +0.378  +0.281  +0.126  -0.010  -0.107  -0.173  +0.398  +1.000  +0.386  +0.265  +0.077  -0.126  -0.233  -0.243  +0.374  +0.384  +0.336  +0.155  -0.048  -0.249  -0.290  -0.297  +0.288  +0.295  +0.197  +0.046  -0.188  -0.341  -0.375  -0.359  +0.201  +0.179  +0.067  -0.093  -0.266  -0.394  -0.398  -0.376  +0.121  +0.067  -0.015  -0.152  -0.280  -0.357  -0.370  -0.331  +0.052  -0.013  -0.071  -0.164  -0.275  -0.299  -0.334  -0.258\n",
      "                         :   var18:  +0.311  +0.325  +0.352  +0.313  +0.216  +0.120  +0.018  -0.004  +0.344  +0.399  +0.397  +0.334  +0.215  +0.078  -0.026  -0.090  +0.344  +0.386  +1.000  +0.314  +0.138  -0.033  -0.127  -0.151  +0.326  +0.334  +0.321  +0.161  -0.001  -0.160  -0.240  -0.242  +0.203  +0.205  +0.139  -0.006  -0.192  -0.306  -0.342  -0.312  +0.115  +0.092  -0.025  -0.147  -0.317  -0.379  -0.390  -0.337  +0.028  -0.021  -0.111  -0.229  -0.320  -0.370  -0.369  -0.311  -0.040  -0.085  -0.138  -0.246  -0.317  -0.344  -0.343  -0.277\n",
      "                         :   var19:  +0.223  +0.288  +0.323  +0.331  +0.287  +0.223  +0.173  +0.082  +0.230  +0.321  +0.367  +0.329  +0.294  +0.205  +0.131  +0.054  +0.212  +0.265  +0.314  +1.000  +0.248  +0.140  +0.046  +0.004  +0.134  +0.179  +0.176  +0.114  +0.087  -0.016  -0.048  -0.088  +0.038  +0.039  -0.011  -0.063  -0.149  -0.208  -0.185  -0.164  -0.028  -0.081  -0.171  -0.215  -0.292  -0.319  -0.282  -0.222  -0.096  -0.170  -0.220  -0.290  -0.348  -0.350  -0.318  -0.222  -0.118  -0.198  -0.258  -0.312  -0.348  -0.333  -0.298  -0.239\n",
      "                         :   var20:  +0.099  +0.158  +0.245  +0.300  +0.344  +0.323  +0.298  +0.224  +0.088  +0.142  +0.231  +0.293  +0.357  +0.356  +0.307  +0.225  +0.008  +0.077  +0.138  +0.248  +1.000  +0.303  +0.268  +0.215  -0.061  -0.057  +0.022  +0.090  +0.154  +0.172  +0.158  +0.150  -0.174  -0.176  -0.196  -0.145  -0.066  -0.014  +0.008  +0.051  -0.223  -0.265  -0.312  -0.292  -0.260  -0.162  -0.113  -0.048  -0.251  -0.317  -0.354  -0.351  -0.321  -0.237  -0.178  -0.094  -0.220  -0.298  -0.323  -0.335  -0.329  -0.266  -0.193  -0.143\n",
      "                         :   var21:  -0.038  +0.017  +0.115  +0.209  +0.302  +0.344  +0.344  +0.290  -0.073  -0.009  +0.075  +0.195  +0.339  +0.387  +0.382  +0.356  -0.139  -0.126  -0.033  +0.140  +0.303  +1.000  +0.399  +0.360  -0.238  -0.228  -0.168  -0.006  +0.154  +0.301  +0.321  +0.292  -0.305  -0.328  -0.316  -0.196  -0.020  +0.127  +0.192  +0.224  -0.321  -0.356  -0.367  -0.306  -0.156  +0.005  +0.075  +0.124  -0.317  -0.355  -0.369  -0.311  -0.224  -0.096  -0.028  +0.029  -0.268  -0.310  -0.340  -0.297  -0.236  -0.146  -0.057  -0.022\n",
      "                         :   var22:  -0.120  -0.080  +0.035  +0.120  +0.254  +0.300  +0.347  +0.315  -0.159  -0.117  -0.019  +0.122  +0.268  +0.395  +0.408  +0.394  -0.234  -0.233  -0.127  +0.046  +0.268  +0.399  +1.000  +0.396  -0.328  -0.305  -0.247  -0.037  +0.183  +0.340  +0.394  +0.389  -0.371  -0.392  -0.350  -0.198  +0.028  +0.225  +0.317  +0.311  -0.389  -0.397  -0.393  -0.280  -0.083  +0.093  +0.193  +0.231  -0.340  -0.367  -0.360  -0.272  -0.127  -0.015  +0.079  +0.124  -0.259  -0.309  -0.314  -0.239  -0.171  -0.080  +0.035  +0.060\n",
      "                         :   var23:  -0.112  -0.106  -0.028  +0.066  +0.184  +0.261  +0.309  +0.271  -0.181  -0.157  -0.072  +0.053  +0.204  +0.312  +0.373  +0.336  -0.253  -0.243  -0.151  +0.004  +0.215  +0.360  +0.396  +1.000  -0.325  -0.318  -0.277  -0.091  +0.163  +0.323  +0.375  +0.374  -0.377  -0.361  -0.322  -0.174  +0.046  +0.235  +0.301  +0.333  -0.352  -0.372  -0.335  -0.213  -0.042  +0.130  +0.239  +0.254  -0.298  -0.317  -0.302  -0.221  -0.077  +0.060  +0.125  +0.154  -0.224  -0.253  -0.264  -0.189  -0.081  -0.013  +0.072  +0.093\n",
      "                         :   var24:  +0.254  +0.258  +0.218  +0.123  -0.012  -0.098  -0.177  -0.165  +0.328  +0.331  +0.269  +0.152  -0.011  -0.154  -0.220  -0.249  +0.384  +0.374  +0.326  +0.134  -0.061  -0.238  -0.328  -0.325  +1.000  +0.417  +0.316  +0.143  -0.130  -0.308  -0.367  -0.355  +0.386  +0.365  +0.286  +0.091  -0.154  -0.319  -0.390  -0.374  +0.309  +0.302  +0.193  +0.031  -0.174  -0.317  -0.365  -0.358  +0.233  +0.214  +0.143  -0.013  -0.168  -0.265  -0.344  -0.274  +0.119  +0.126  +0.076  -0.035  -0.138  -0.208  -0.242  -0.209\n",
      "                         :   var25:  +0.256  +0.269  +0.213  +0.118  +0.016  -0.102  -0.165  -0.177  +0.336  +0.341  +0.295  +0.159  -0.007  -0.137  -0.214  -0.261  +0.370  +0.384  +0.334  +0.179  -0.057  -0.228  -0.305  -0.318  +0.417  +1.000  +0.350  +0.161  -0.103  -0.321  -0.396  -0.362  +0.378  +0.362  +0.309  +0.095  -0.171  -0.347  -0.403  -0.399  +0.331  +0.292  +0.196  +0.035  -0.180  -0.349  -0.401  -0.386  +0.231  +0.199  +0.134  -0.016  -0.175  -0.283  -0.342  -0.315  +0.123  +0.115  +0.063  -0.052  -0.163  -0.235  -0.280  -0.247\n",
      "                         :   var26:  +0.243  +0.238  +0.213  +0.144  +0.041  -0.047  -0.107  -0.107  +0.283  +0.303  +0.263  +0.179  +0.037  -0.092  -0.181  -0.188  +0.308  +0.336  +0.321  +0.176  +0.022  -0.168  -0.247  -0.277  +0.316  +0.350  +1.000  +0.140  -0.077  -0.241  -0.303  -0.301  +0.307  +0.294  +0.250  +0.085  -0.149  -0.307  -0.350  -0.359  +0.226  +0.222  +0.113  +0.018  -0.195  -0.304  -0.350  -0.344  +0.168  +0.117  +0.070  -0.047  -0.163  -0.288  -0.319  -0.302  +0.091  +0.068  -0.005  -0.078  -0.168  -0.224  -0.282  -0.212\n",
      "                         :   var27:  +0.126  +0.154  +0.136  +0.136  +0.099  +0.061  +0.001  +0.003  +0.162  +0.180  +0.178  +0.163  +0.091  +0.043  -0.011  -0.041  +0.133  +0.155  +0.161  +0.114  +0.090  -0.006  -0.037  -0.091  +0.143  +0.161  +0.140  +1.000  +0.026  -0.090  -0.098  -0.135  +0.081  +0.094  +0.045  -0.005  -0.088  -0.139  -0.148  -0.158  +0.035  +0.021  -0.003  -0.072  -0.154  -0.170  -0.192  -0.178  -0.014  -0.002  -0.061  -0.109  -0.175  -0.205  -0.220  -0.162  -0.024  -0.091  -0.082  -0.141  -0.173  -0.172  -0.186  -0.139\n",
      "                         :   var28:  -0.008  +0.015  +0.069  +0.106  +0.135  +0.171  +0.178  +0.131  -0.046  +0.006  +0.059  +0.098  +0.174  +0.183  +0.190  +0.160  -0.092  -0.048  -0.001  +0.087  +0.154  +0.154  +0.183  +0.163  -0.130  -0.103  -0.077  +0.026  +1.000  +0.150  +0.172  +0.134  -0.172  -0.177  -0.151  -0.084  +0.010  +0.055  +0.099  +0.102  -0.191  -0.198  -0.217  -0.136  -0.097  -0.010  +0.060  +0.062  -0.184  -0.197  -0.201  -0.159  -0.119  -0.064  -0.032  -0.008  -0.150  -0.195  -0.197  -0.172  -0.131  -0.089  -0.059  -0.034\n",
      "                         :   var29:  -0.129  -0.116  -0.053  +0.031  +0.141  +0.210  +0.236  +0.226  -0.180  -0.161  -0.088  +0.034  +0.171  +0.275  +0.289  +0.294  -0.244  -0.249  -0.160  -0.016  +0.172  +0.301  +0.340  +0.323  -0.308  -0.321  -0.241  -0.090  +0.150  +1.000  +0.335  +0.320  -0.339  -0.354  -0.316  -0.165  +0.074  +0.248  +0.287  +0.305  -0.338  -0.339  -0.306  -0.171  -0.029  +0.160  +0.205  +0.244  -0.285  -0.311  -0.286  -0.182  -0.034  +0.077  +0.144  +0.154  -0.223  -0.245  -0.233  -0.139  -0.070  +0.017  +0.087  +0.103\n",
      "                         :   var30:  -0.168  -0.166  -0.105  +0.001  +0.134  +0.207  +0.263  +0.254  -0.238  -0.218  -0.163  -0.002  +0.136  +0.279  +0.349  +0.324  -0.294  -0.290  -0.240  -0.048  +0.158  +0.321  +0.394  +0.375  -0.367  -0.396  -0.303  -0.098  +0.172  +0.335  +1.000  +0.419  -0.389  -0.407  -0.334  -0.156  +0.101  +0.296  +0.365  +0.358  -0.387  -0.372  -0.323  -0.184  +0.031  +0.218  +0.302  +0.317  -0.307  -0.306  -0.289  -0.183  -0.020  +0.123  +0.201  +0.212  -0.252  -0.262  -0.232  -0.140  -0.033  +0.054  +0.138  +0.131\n",
      "                         :   var31:  -0.184  -0.186  -0.112  -0.036  +0.096  +0.192  +0.244  +0.243  -0.247  -0.236  -0.167  -0.033  +0.112  +0.255  +0.308  +0.334  -0.307  -0.297  -0.242  -0.088  +0.150  +0.292  +0.389  +0.374  -0.355  -0.362  -0.301  -0.135  +0.134  +0.320  +0.419  +1.000  -0.399  -0.386  -0.344  -0.171  +0.087  +0.290  +0.367  +0.381  -0.352  -0.353  -0.304  -0.178  +0.025  +0.224  +0.322  +0.322  -0.299  -0.291  -0.272  -0.135  +0.004  +0.154  +0.235  +0.223  -0.202  -0.230  -0.207  -0.108  -0.009  +0.088  +0.151  +0.160\n",
      "                         :   var32:  +0.158  +0.154  +0.097  -0.016  -0.128  -0.202  -0.240  -0.225  +0.256  +0.207  +0.143  +0.005  -0.152  -0.261  -0.325  -0.296  +0.315  +0.288  +0.203  +0.038  -0.174  -0.305  -0.371  -0.377  +0.386  +0.378  +0.307  +0.081  -0.172  -0.339  -0.389  -0.399  +1.000  +0.410  +0.336  +0.152  -0.117  -0.315  -0.381  -0.373  +0.390  +0.384  +0.306  +0.133  -0.077  -0.251  -0.331  -0.324  +0.334  +0.321  +0.288  +0.134  -0.040  -0.176  -0.248  -0.257  +0.241  +0.261  +0.217  +0.100  +0.011  -0.105  -0.189  -0.182\n",
      "                         :   var33:  +0.138  +0.123  +0.075  -0.034  -0.156  -0.208  -0.260  -0.259  +0.207  +0.205  +0.115  -0.005  -0.170  -0.293  -0.331  -0.331  +0.319  +0.295  +0.205  +0.039  -0.176  -0.328  -0.392  -0.361  +0.365  +0.362  +0.294  +0.094  -0.177  -0.354  -0.407  -0.386  +0.410  +1.000  +0.345  +0.172  -0.100  -0.294  -0.362  -0.371  +0.385  +0.375  +0.312  +0.185  -0.059  -0.251  -0.326  -0.316  +0.321  +0.317  +0.283  +0.151  -0.023  -0.175  -0.233  -0.239  +0.229  +0.257  +0.209  +0.095  +0.001  -0.096  -0.192  -0.171\n",
      "                         :   var34:  +0.081  +0.066  +0.010  -0.075  -0.147  -0.222  -0.246  -0.233  +0.150  +0.118  +0.058  -0.057  -0.187  -0.285  -0.308  -0.291  +0.203  +0.197  +0.139  -0.011  -0.196  -0.316  -0.350  -0.322  +0.286  +0.309  +0.250  +0.045  -0.151  -0.316  -0.334  -0.344  +0.336  +0.345  +1.000  +0.170  -0.083  -0.242  -0.316  -0.304  +0.351  +0.343  +0.326  +0.187  -0.001  -0.175  -0.234  -0.257  +0.298  +0.305  +0.272  +0.175  +0.035  -0.107  -0.173  -0.200  +0.244  +0.242  +0.235  +0.134  +0.068  -0.052  -0.121  -0.114\n",
      "                         :   var35:  -0.024  -0.045  -0.082  -0.109  -0.153  -0.171  -0.166  -0.141  +0.001  -0.001  -0.084  -0.115  -0.168  -0.181  -0.200  -0.175  +0.038  +0.046  -0.006  -0.063  -0.145  -0.196  -0.198  -0.174  +0.091  +0.095  +0.085  -0.005  -0.084  -0.165  -0.156  -0.171  +0.152  +0.172  +0.170  +1.000  -0.008  -0.079  -0.111  -0.141  +0.156  +0.157  +0.187  +0.144  +0.086  -0.021  -0.045  -0.088  +0.147  +0.183  +0.175  +0.170  +0.093  +0.022  -0.007  -0.043  +0.116  +0.145  +0.145  +0.143  +0.077  +0.052  +0.020  -0.009\n",
      "                         :   var36:  -0.160  -0.189  -0.197  -0.146  -0.133  -0.090  -0.056  -0.046  -0.176  -0.236  -0.193  -0.162  -0.120  -0.066  -0.010  -0.003  -0.173  -0.188  -0.192  -0.149  -0.066  -0.020  +0.028  +0.046  -0.154  -0.171  -0.149  -0.088  +0.010  +0.074  +0.101  +0.087  -0.117  -0.100  -0.083  -0.008  +1.000  +0.162  +0.157  +0.140  -0.080  -0.058  +0.008  +0.093  +0.153  +0.186  +0.187  +0.155  -0.061  +0.011  +0.034  +0.106  +0.164  +0.177  +0.188  +0.140  -0.015  -0.001  +0.068  +0.109  +0.167  +0.161  +0.154  +0.125\n",
      "                         :   var37:  -0.222  -0.248  -0.258  -0.167  -0.097  -0.001  +0.063  +0.094  -0.294  -0.321  -0.286  -0.191  -0.076  +0.051  +0.134  +0.164  -0.326  -0.341  -0.306  -0.208  -0.014  +0.127  +0.225  +0.235  -0.319  -0.347  -0.307  -0.139  +0.055  +0.248  +0.296  +0.290  -0.315  -0.294  -0.242  -0.079  +0.162  +1.000  +0.330  +0.323  -0.236  -0.229  -0.148  +0.014  +0.181  +0.321  +0.356  +0.331  -0.193  -0.153  -0.081  +0.037  +0.163  +0.286  +0.303  +0.271  -0.122  -0.095  -0.047  +0.045  +0.155  +0.216  +0.251  +0.210\n",
      "                         :   var38:  -0.260  -0.273  -0.219  -0.148  -0.032  +0.055  +0.124  +0.142  -0.308  -0.333  -0.294  -0.177  -0.022  +0.127  +0.211  +0.218  -0.371  -0.375  -0.342  -0.185  +0.008  +0.192  +0.317  +0.301  -0.390  -0.403  -0.350  -0.148  +0.099  +0.287  +0.365  +0.367  -0.381  -0.362  -0.316  -0.111  +0.157  +0.330  +1.000  +0.409  -0.320  -0.305  -0.211  -0.046  +0.173  +0.353  +0.397  +0.389  -0.240  -0.206  -0.144  +0.007  +0.174  +0.280  +0.352  +0.326  -0.157  -0.148  -0.115  +0.017  +0.124  +0.229  +0.282  +0.238\n",
      "                         :   var39:  -0.223  -0.224  -0.189  -0.114  -0.007  +0.093  +0.152  +0.178  -0.285  -0.299  -0.263  -0.138  +0.034  +0.163  +0.222  +0.259  -0.338  -0.359  -0.312  -0.164  +0.051  +0.224  +0.311  +0.333  -0.374  -0.399  -0.359  -0.158  +0.102  +0.305  +0.358  +0.381  -0.373  -0.371  -0.304  -0.141  +0.140  +0.323  +0.409  +1.000  -0.313  -0.307  -0.256  -0.084  +0.138  +0.319  +0.378  +0.368  -0.244  -0.226  -0.186  -0.055  +0.120  +0.270  +0.313  +0.288  -0.159  -0.157  -0.128  -0.023  +0.106  +0.201  +0.249  +0.218\n",
      "                         :   var40:  +0.093  +0.070  -0.009  -0.095  -0.185  -0.249  -0.272  -0.240  +0.173  +0.114  +0.046  -0.087  -0.214  -0.319  -0.319  -0.304  +0.244  +0.201  +0.115  -0.028  -0.223  -0.321  -0.389  -0.352  +0.309  +0.331  +0.226  +0.035  -0.191  -0.338  -0.387  -0.352  +0.390  +0.385  +0.351  +0.156  -0.080  -0.236  -0.320  -0.313  +1.000  +0.387  +0.354  +0.204  +0.010  -0.157  -0.247  -0.263  +0.356  +0.349  +0.327  +0.208  +0.055  -0.081  -0.170  -0.182  +0.280  +0.325  +0.281  +0.173  +0.069  -0.022  -0.106  -0.116\n",
      "                         :   var41:  +0.040  +0.013  -0.067  -0.145  -0.233  -0.296  -0.313  -0.267  +0.128  +0.055  -0.012  -0.143  -0.273  -0.354  -0.366  -0.340  +0.211  +0.179  +0.092  -0.081  -0.265  -0.356  -0.397  -0.372  +0.302  +0.292  +0.222  +0.021  -0.198  -0.339  -0.372  -0.353  +0.384  +0.375  +0.343  +0.157  -0.058  -0.229  -0.305  -0.307  +0.387  +1.000  +0.384  +0.255  +0.061  -0.127  -0.228  -0.229  +0.368  +0.387  +0.384  +0.267  +0.107  -0.046  -0.113  -0.165  +0.305  +0.338  +0.323  +0.243  +0.131  +0.025  -0.075  -0.090\n",
      "                         :   var42:  -0.028  -0.066  -0.157  -0.243  -0.317  -0.328  -0.316  -0.277  +0.028  -0.024  -0.130  -0.230  -0.336  -0.378  -0.363  -0.329  +0.125  +0.067  -0.025  -0.171  -0.312  -0.367  -0.393  -0.335  +0.193  +0.196  +0.113  -0.003  -0.217  -0.306  -0.323  -0.304  +0.306  +0.312  +0.326  +0.187  +0.008  -0.148  -0.211  -0.256  +0.354  +0.384  +1.000  +0.300  +0.151  -0.037  -0.111  -0.173  +0.344  +0.370  +0.403  +0.334  +0.214  +0.069  -0.000  -0.069  +0.302  +0.351  +0.371  +0.305  +0.227  +0.132  +0.026  -0.013\n",
      "                         :   var43:  -0.120  -0.185  -0.258  -0.285  -0.320  -0.314  -0.295  -0.239  -0.104  -0.165  -0.233  -0.295  -0.336  -0.349  -0.301  -0.261  -0.053  -0.093  -0.147  -0.215  -0.292  -0.306  -0.280  -0.213  +0.031  +0.035  +0.018  -0.072  -0.136  -0.171  -0.184  -0.178  +0.133  +0.185  +0.187  +0.144  +0.093  +0.014  -0.046  -0.084  +0.204  +0.255  +0.300  +1.000  +0.242  +0.111  +0.054  +0.013  +0.221  +0.293  +0.336  +0.343  +0.275  +0.208  +0.130  +0.045  +0.235  +0.272  +0.335  +0.316  +0.279  +0.216  +0.157  +0.083\n",
      "                         :   var44:  -0.226  -0.281  -0.341  -0.341  -0.313  -0.253  -0.191  -0.128  -0.259  -0.315  -0.345  -0.362  -0.316  -0.254  -0.172  -0.105  -0.228  -0.266  -0.317  -0.292  -0.260  -0.156  -0.083  -0.042  -0.174  -0.180  -0.195  -0.154  -0.097  -0.029  +0.031  +0.025  -0.077  -0.059  -0.001  +0.086  +0.153  +0.181  +0.173  +0.138  +0.010  +0.061  +0.151  +0.242  +1.000  +0.317  +0.283  +0.220  +0.054  +0.134  +0.212  +0.302  +0.340  +0.356  +0.310  +0.234  +0.107  +0.148  +0.239  +0.298  +0.350  +0.338  +0.305  +0.209\n",
      "                         :   var45:  -0.277  -0.309  -0.343  -0.307  -0.223  -0.159  -0.081  -0.030  -0.330  -0.391  -0.392  -0.318  -0.219  -0.105  -0.017  +0.056  -0.345  -0.394  -0.379  -0.319  -0.162  +0.005  +0.093  +0.130  -0.317  -0.349  -0.304  -0.170  -0.010  +0.160  +0.218  +0.224  -0.251  -0.251  -0.175  -0.021  +0.186  +0.321  +0.353  +0.319  -0.157  -0.127  -0.037  +0.111  +0.317  +1.000  +0.413  +0.347  -0.093  -0.014  +0.070  +0.202  +0.335  +0.408  +0.403  +0.335  -0.036  +0.027  +0.102  +0.192  +0.312  +0.349  +0.358  +0.290\n",
      "                         :   var46:  -0.276  -0.340  -0.311  -0.268  -0.168  -0.090  +0.012  +0.076  -0.346  -0.385  -0.382  -0.295  -0.154  -0.011  +0.089  +0.139  -0.372  -0.398  -0.390  -0.282  -0.113  +0.075  +0.193  +0.239  -0.365  -0.401  -0.350  -0.192  +0.060  +0.205  +0.302  +0.322  -0.331  -0.326  -0.234  -0.045  +0.187  +0.356  +0.397  +0.378  -0.247  -0.228  -0.111  +0.054  +0.283  +0.413  +1.000  +0.421  -0.161  -0.114  -0.042  +0.131  +0.283  +0.383  +0.422  +0.375  -0.088  -0.058  +0.020  +0.140  +0.272  +0.336  +0.356  +0.290\n",
      "                         :   var47:  -0.231  -0.284  -0.269  -0.209  -0.111  -0.013  +0.045  +0.102  -0.309  -0.336  -0.317  -0.227  -0.116  +0.031  +0.130  +0.178  -0.339  -0.376  -0.337  -0.222  -0.048  +0.124  +0.231  +0.254  -0.358  -0.386  -0.344  -0.178  +0.062  +0.244  +0.317  +0.322  -0.324  -0.316  -0.257  -0.088  +0.155  +0.331  +0.389  +0.368  -0.263  -0.229  -0.173  +0.013  +0.220  +0.347  +0.421  +1.000  -0.185  -0.147  -0.098  +0.066  +0.224  +0.337  +0.373  +0.329  -0.110  -0.091  -0.036  +0.080  +0.190  +0.261  +0.326  +0.257\n",
      "                         :   var48:  +0.011  -0.013  -0.078  -0.157  -0.218  -0.263  -0.248  -0.228  +0.075  +0.033  -0.037  -0.137  -0.264  -0.304  -0.312  -0.258  +0.153  +0.121  +0.028  -0.096  -0.251  -0.317  -0.340  -0.298  +0.233  +0.231  +0.168  -0.014  -0.184  -0.285  -0.307  -0.299  +0.334  +0.321  +0.298  +0.147  -0.061  -0.193  -0.240  -0.244  +0.356  +0.368  +0.344  +0.221  +0.054  -0.093  -0.161  -0.185  +1.000  +0.340  +0.345  +0.252  +0.102  -0.005  -0.086  -0.133  +0.265  +0.317  +0.305  +0.219  +0.133  +0.041  -0.049  -0.066\n",
      "                         :   var49:  -0.016  -0.067  -0.164  -0.221  -0.289  -0.323  -0.308  -0.259  +0.006  -0.045  -0.124  -0.235  -0.329  -0.385  -0.354  -0.320  +0.095  +0.067  -0.021  -0.170  -0.317  -0.355  -0.367  -0.317  +0.214  +0.199  +0.117  -0.002  -0.197  -0.311  -0.306  -0.291  +0.321  +0.317  +0.305  +0.183  +0.011  -0.153  -0.206  -0.226  +0.349  +0.387  +0.370  +0.293  +0.134  -0.014  -0.114  -0.147  +0.340  +1.000  +0.404  +0.349  +0.211  +0.069  -0.011  -0.068  +0.293  +0.369  +0.370  +0.314  +0.234  +0.122  +0.022  -0.015\n",
      "                         :   var50:  -0.072  -0.145  -0.228  -0.309  -0.337  -0.360  -0.331  -0.282  -0.057  -0.122  -0.206  -0.292  -0.372  -0.404  -0.393  -0.320  +0.043  -0.015  -0.111  -0.220  -0.354  -0.369  -0.360  -0.302  +0.143  +0.134  +0.070  -0.061  -0.201  -0.286  -0.289  -0.272  +0.288  +0.283  +0.272  +0.175  +0.034  -0.081  -0.144  -0.186  +0.327  +0.384  +0.403  +0.336  +0.212  +0.070  -0.042  -0.098  +0.345  +0.404  +1.000  +0.379  +0.278  +0.144  +0.072  -0.007  +0.303  +0.374  +0.401  +0.367  +0.289  +0.203  +0.098  +0.035\n",
      "                         :   var51:  -0.181  -0.236  -0.327  -0.377  -0.386  -0.373  -0.306  -0.254  -0.177  -0.248  -0.324  -0.375  -0.414  -0.392  -0.332  -0.253  -0.115  -0.152  -0.229  -0.290  -0.351  -0.311  -0.272  -0.221  -0.013  -0.016  -0.047  -0.109  -0.159  -0.182  -0.183  -0.135  +0.134  +0.151  +0.175  +0.170  +0.106  +0.037  +0.007  -0.055  +0.208  +0.267  +0.334  +0.343  +0.302  +0.202  +0.131  +0.066  +0.252  +0.349  +0.379  +1.000  +0.371  +0.277  +0.228  +0.120  +0.251  +0.354  +0.402  +0.409  +0.371  +0.303  +0.217  +0.139\n",
      "                         :   var52:  -0.243  -0.307  -0.382  -0.388  -0.355  -0.299  -0.230  -0.169  -0.254  -0.336  -0.395  -0.403  -0.391  -0.299  -0.220  -0.161  -0.229  -0.280  -0.320  -0.348  -0.321  -0.224  -0.127  -0.077  -0.168  -0.175  -0.163  -0.175  -0.119  -0.034  -0.020  +0.004  -0.040  -0.023  +0.035  +0.093  +0.164  +0.163  +0.174  +0.120  +0.055  +0.107  +0.214  +0.275  +0.340  +0.335  +0.283  +0.224  +0.102  +0.211  +0.278  +0.371  +1.000  +0.397  +0.345  +0.242  +0.154  +0.225  +0.316  +0.357  +0.422  +0.385  +0.325  +0.270\n",
      "                         :   var53:  -0.265  -0.329  -0.360  -0.360  -0.306  -0.222  -0.147  -0.101  -0.320  -0.381  -0.398  -0.378  -0.315  -0.194  -0.109  -0.042  -0.310  -0.357  -0.370  -0.350  -0.237  -0.096  -0.015  +0.060  -0.265  -0.283  -0.288  -0.205  -0.064  +0.077  +0.123  +0.154  -0.176  -0.175  -0.107  +0.022  +0.177  +0.286  +0.280  +0.270  -0.081  -0.046  +0.069  +0.208  +0.356  +0.408  +0.383  +0.337  -0.005  +0.069  +0.144  +0.277  +0.397  +1.000  +0.413  +0.338  +0.033  +0.116  +0.203  +0.299  +0.393  +0.403  +0.389  +0.326\n",
      "                         :   var54:  -0.263  -0.322  -0.340  -0.310  -0.238  -0.158  -0.086  -0.038  -0.317  -0.399  -0.383  -0.335  -0.233  -0.126  -0.024  +0.032  -0.339  -0.370  -0.369  -0.318  -0.178  -0.028  +0.079  +0.125  -0.344  -0.342  -0.319  -0.220  -0.032  +0.144  +0.201  +0.235  -0.248  -0.233  -0.173  -0.007  +0.188  +0.303  +0.352  +0.313  -0.170  -0.113  -0.000  +0.130  +0.310  +0.403  +0.422  +0.373  -0.086  -0.011  +0.072  +0.228  +0.345  +0.413  +1.000  +0.363  -0.014  +0.039  +0.115  +0.225  +0.346  +0.377  +0.379  +0.324\n",
      "                         :   var55:  -0.220  -0.268  -0.267  -0.221  -0.165  -0.077  -0.012  +0.013  -0.259  -0.308  -0.308  -0.241  -0.163  -0.037  +0.039  +0.076  -0.288  -0.331  -0.311  -0.222  -0.094  +0.029  +0.124  +0.154  -0.274  -0.315  -0.302  -0.162  -0.008  +0.154  +0.212  +0.223  -0.257  -0.239  -0.200  -0.043  +0.140  +0.271  +0.326  +0.288  -0.182  -0.165  -0.069  +0.045  +0.234  +0.335  +0.375  +0.329  -0.133  -0.068  -0.007  +0.120  +0.242  +0.338  +0.363  +1.000  -0.065  -0.019  +0.045  +0.133  +0.244  +0.276  +0.330  +0.239\n",
      "                         :   var56:  -0.015  -0.053  -0.123  -0.179  -0.207  -0.226  -0.217  -0.192  +0.005  -0.032  -0.092  -0.171  -0.254  -0.290  -0.255  -0.192  +0.062  +0.052  -0.040  -0.118  -0.220  -0.268  -0.259  -0.224  +0.119  +0.123  +0.091  -0.024  -0.150  -0.223  -0.252  -0.202  +0.241  +0.229  +0.244  +0.116  -0.015  -0.122  -0.157  -0.159  +0.280  +0.305  +0.302  +0.235  +0.107  -0.036  -0.088  -0.110  +0.265  +0.293  +0.303  +0.251  +0.154  +0.033  -0.014  -0.065  +1.000  +0.287  +0.294  +0.232  +0.173  +0.104  -0.009  -0.010\n",
      "                         :   var57:  -0.087  -0.123  -0.200  -0.255  -0.281  -0.284  -0.270  -0.219  -0.036  -0.087  -0.183  -0.252  -0.323  -0.363  -0.306  -0.254  +0.041  -0.013  -0.085  -0.198  -0.298  -0.310  -0.309  -0.253  +0.126  +0.115  +0.068  -0.091  -0.195  -0.245  -0.262  -0.230  +0.261  +0.257  +0.242  +0.145  -0.001  -0.095  -0.148  -0.157  +0.325  +0.338  +0.351  +0.272  +0.148  +0.027  -0.058  -0.091  +0.317  +0.369  +0.374  +0.354  +0.225  +0.116  +0.039  -0.019  +0.287  +1.000  +0.362  +0.314  +0.262  +0.152  +0.069  +0.034\n",
      "                         :   var58:  -0.123  -0.166  -0.252  -0.317  -0.347  -0.349  -0.315  -0.257  -0.086  -0.159  -0.243  -0.319  -0.379  -0.367  -0.334  -0.277  -0.026  -0.071  -0.138  -0.258  -0.323  -0.340  -0.314  -0.264  +0.076  +0.063  -0.005  -0.082  -0.197  -0.233  -0.232  -0.207  +0.217  +0.209  +0.235  +0.145  +0.068  -0.047  -0.115  -0.128  +0.281  +0.323  +0.371  +0.335  +0.239  +0.102  +0.020  -0.036  +0.305  +0.370  +0.401  +0.402  +0.316  +0.203  +0.115  +0.045  +0.294  +0.362  +1.000  +0.383  +0.324  +0.232  +0.142  +0.084\n",
      "                         :   var59:  -0.168  -0.231  -0.330  -0.359  -0.357  -0.314  -0.292  -0.215  -0.187  -0.249  -0.315  -0.366  -0.378  -0.366  -0.298  -0.221  -0.114  -0.164  -0.246  -0.312  -0.335  -0.297  -0.239  -0.189  -0.035  -0.052  -0.078  -0.141  -0.172  -0.139  -0.140  -0.108  +0.100  +0.095  +0.134  +0.143  +0.109  +0.045  +0.017  -0.023  +0.173  +0.243  +0.305  +0.316  +0.298  +0.192  +0.140  +0.080  +0.219  +0.314  +0.367  +0.409  +0.357  +0.299  +0.225  +0.133  +0.232  +0.314  +0.383  +1.000  +0.365  +0.329  +0.227  +0.158\n",
      "                         :   var60:  -0.228  -0.295  -0.363  -0.378  -0.361  -0.320  -0.254  -0.182  -0.250  -0.319  -0.378  -0.387  -0.393  -0.319  -0.235  -0.166  -0.203  -0.275  -0.317  -0.348  -0.329  -0.236  -0.171  -0.081  -0.138  -0.163  -0.168  -0.173  -0.131  -0.070  -0.033  -0.009  +0.011  +0.001  +0.068  +0.077  +0.167  +0.155  +0.124  +0.106  +0.069  +0.131  +0.227  +0.279  +0.350  +0.312  +0.272  +0.190  +0.133  +0.234  +0.289  +0.371  +0.422  +0.393  +0.346  +0.244  +0.173  +0.262  +0.324  +0.365  +1.000  +0.393  +0.326  +0.243\n",
      "                         :   var61:  -0.231  -0.284  -0.333  -0.340  -0.318  -0.253  -0.190  -0.105  -0.271  -0.342  -0.379  -0.370  -0.323  -0.235  -0.151  -0.075  -0.253  -0.299  -0.344  -0.333  -0.266  -0.146  -0.080  -0.013  -0.208  -0.235  -0.224  -0.172  -0.089  +0.017  +0.054  +0.088  -0.105  -0.096  -0.052  +0.052  +0.161  +0.216  +0.229  +0.201  -0.022  +0.025  +0.132  +0.216  +0.338  +0.349  +0.336  +0.261  +0.041  +0.122  +0.203  +0.303  +0.385  +0.403  +0.377  +0.276  +0.104  +0.152  +0.232  +0.329  +0.393  +1.000  +0.361  +0.272\n",
      "                         :   var62:  -0.225  -0.262  -0.313  -0.298  -0.241  -0.173  -0.101  -0.062  -0.280  -0.334  -0.345  -0.323  -0.239  -0.139  -0.065  -0.014  -0.279  -0.334  -0.343  -0.298  -0.193  -0.057  +0.035  +0.072  -0.242  -0.280  -0.282  -0.186  -0.059  +0.087  +0.138  +0.151  -0.189  -0.192  -0.121  +0.020  +0.154  +0.251  +0.282  +0.249  -0.106  -0.075  +0.026  +0.157  +0.305  +0.358  +0.356  +0.326  -0.049  +0.022  +0.098  +0.217  +0.325  +0.389  +0.379  +0.330  -0.009  +0.069  +0.142  +0.227  +0.326  +0.361  +1.000  +0.289\n",
      "                         :   var63:  -0.170  -0.217  -0.257  -0.210  -0.177  -0.105  -0.061  -0.002  -0.227  -0.254  -0.261  -0.229  -0.167  -0.080  -0.009  +0.018  -0.235  -0.258  -0.277  -0.239  -0.143  -0.022  +0.060  +0.093  -0.209  -0.247  -0.212  -0.139  -0.034  +0.103  +0.131  +0.160  -0.182  -0.171  -0.114  -0.009  +0.125  +0.210  +0.238  +0.218  -0.116  -0.090  -0.013  +0.083  +0.209  +0.290  +0.290  +0.257  -0.066  -0.015  +0.035  +0.139  +0.270  +0.326  +0.324  +0.239  -0.010  +0.034  +0.084  +0.158  +0.243  +0.272  +0.289  +1.000\n",
      "                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "//Boosted Decision Trees\n",
    "factory.BookMethod(loader,TMVA::Types::kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=800:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. If using master version you can use the new DL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool useDNN = true; \n",
    "bool useCNN = true; \n",
    "bool useKeras = false; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_DENSE\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=Standard\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=Standard\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|64\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|128|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"STANDARD\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         : The STANDARD architecture has been deprecated. Please use Architecture=CPU or Architecture=CPU.See the TMVA Users' Guide for instructions if you encounter problems.\n",
      "                         : Will use the deprecated STANDARD architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useDNN) { \n",
    "    \n",
    "     TString inputLayoutString = \"InputLayout=1|1|64\"; \n",
    "     TString batchLayoutString= \"BatchLayout=1|128|64\";\n",
    "     TString layoutString (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "//                                                                                                                                                                                       \n",
    "      // Training strategies \n",
    "      // one can catenate several training strategies \n",
    "      TString training1(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                        \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                        \"MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,\"\n",
    "                        \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\");\n",
    "  \n",
    "      TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "      trainingStrategyString += training1; // + \"|\" + training2 + \"|\" + training3;\n",
    "\n",
    "      // General Options.                                                                                                                                                                \n",
    "      TString dnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                          \"WeightInitialization=XAVIERUNIFORM\");\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (inputLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (batchLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (layoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (trainingStrategyString);\n",
    "\n",
    "      dnnOptions += \":Architecture=Standard\";\n",
    "      factory.BookMethod(loader, TMVA::Types::kDL, \"DL_DENSE\", dnnOptions);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in TMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=128|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=128|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|8|8\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"128|1|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=20,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useCNN) { \n",
    "    TString inputLayoutString(\"InputLayout=1|8|8\");\n",
    "                                                                                                \n",
    "// Batch Layout                                                                                                                                     \n",
    "    TString batchLayoutString(\"BatchLayout=128|1|64\");\n",
    "                                                   \n",
    "\n",
    "TString layoutString(\"Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,\"\n",
    "                     \"RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "                                                                                                                                              \n",
    "\n",
    "\n",
    "   // Training strategies.                                                                                                                          \n",
    "   TString training0(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                     \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                     \"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"\n",
    "                     \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\");\n",
    " \n",
    "   TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "   trainingStrategyString += training0; // + \"|\" + training1 + \"|\" + training2;   }\n",
    "    \n",
    "// General Options.                                                                                                                              \n",
    "   TString cnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\");\n",
    "\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(inputLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(batchLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(layoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(trainingStrategyString);\n",
    "   cnnOptions.Append(\":Architecture=CPU\");\n",
    "\n",
    "   //// New DL (CNN)                                                                                                                                \n",
    "\n",
    "\n",
    "  factory.BookMethod(loader, TMVA::Types::kDL, \"DL_CNN\", cnnOptions);\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in Keras using a generated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (useKeras) { \n",
    "   factory.BookMethod(loader, TMVA::Types::kPyKeras, \n",
    "                       \"PyKeras\",\"H:!V:VarTransform=None:FilenameModel=model_cnn.h5:\"\n",
    "                       \"FilenameTrainedModel=trained_model_cnn.h5:NumEpochs=20:BatchSize=256\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var0' <---> Output : variable 'var0'\n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Input : variable 'var5' <---> Output : variable 'var5'\n",
      "                         : Input : variable 'var6' <---> Output : variable 'var6'\n",
      "                         : Input : variable 'var7' <---> Output : variable 'var7'\n",
      "                         : Input : variable 'var8' <---> Output : variable 'var8'\n",
      "                         : Input : variable 'var9' <---> Output : variable 'var9'\n",
      "                         : Input : variable 'var10' <---> Output : variable 'var10'\n",
      "                         : Input : variable 'var11' <---> Output : variable 'var11'\n",
      "                         : Input : variable 'var12' <---> Output : variable 'var12'\n",
      "                         : Input : variable 'var13' <---> Output : variable 'var13'\n",
      "                         : Input : variable 'var14' <---> Output : variable 'var14'\n",
      "                         : Input : variable 'var15' <---> Output : variable 'var15'\n",
      "                         : Input : variable 'var16' <---> Output : variable 'var16'\n",
      "                         : Input : variable 'var17' <---> Output : variable 'var17'\n",
      "                         : Input : variable 'var18' <---> Output : variable 'var18'\n",
      "                         : Input : variable 'var19' <---> Output : variable 'var19'\n",
      "                         : Input : variable 'var20' <---> Output : variable 'var20'\n",
      "                         : Input : variable 'var21' <---> Output : variable 'var21'\n",
      "                         : Input : variable 'var22' <---> Output : variable 'var22'\n",
      "                         : Input : variable 'var23' <---> Output : variable 'var23'\n",
      "                         : Input : variable 'var24' <---> Output : variable 'var24'\n",
      "                         : Input : variable 'var25' <---> Output : variable 'var25'\n",
      "                         : Input : variable 'var26' <---> Output : variable 'var26'\n",
      "                         : Input : variable 'var27' <---> Output : variable 'var27'\n",
      "                         : Input : variable 'var28' <---> Output : variable 'var28'\n",
      "                         : Input : variable 'var29' <---> Output : variable 'var29'\n",
      "                         : Input : variable 'var30' <---> Output : variable 'var30'\n",
      "                         : Input : variable 'var31' <---> Output : variable 'var31'\n",
      "                         : Input : variable 'var32' <---> Output : variable 'var32'\n",
      "                         : Input : variable 'var33' <---> Output : variable 'var33'\n",
      "                         : Input : variable 'var34' <---> Output : variable 'var34'\n",
      "                         : Input : variable 'var35' <---> Output : variable 'var35'\n",
      "                         : Input : variable 'var36' <---> Output : variable 'var36'\n",
      "                         : Input : variable 'var37' <---> Output : variable 'var37'\n",
      "                         : Input : variable 'var38' <---> Output : variable 'var38'\n",
      "                         : Input : variable 'var39' <---> Output : variable 'var39'\n",
      "                         : Input : variable 'var40' <---> Output : variable 'var40'\n",
      "                         : Input : variable 'var41' <---> Output : variable 'var41'\n",
      "                         : Input : variable 'var42' <---> Output : variable 'var42'\n",
      "                         : Input : variable 'var43' <---> Output : variable 'var43'\n",
      "                         : Input : variable 'var44' <---> Output : variable 'var44'\n",
      "                         : Input : variable 'var45' <---> Output : variable 'var45'\n",
      "                         : Input : variable 'var46' <---> Output : variable 'var46'\n",
      "                         : Input : variable 'var47' <---> Output : variable 'var47'\n",
      "                         : Input : variable 'var48' <---> Output : variable 'var48'\n",
      "                         : Input : variable 'var49' <---> Output : variable 'var49'\n",
      "                         : Input : variable 'var50' <---> Output : variable 'var50'\n",
      "                         : Input : variable 'var51' <---> Output : variable 'var51'\n",
      "                         : Input : variable 'var52' <---> Output : variable 'var52'\n",
      "                         : Input : variable 'var53' <---> Output : variable 'var53'\n",
      "                         : Input : variable 'var54' <---> Output : variable 'var54'\n",
      "                         : Input : variable 'var55' <---> Output : variable 'var55'\n",
      "                         : Input : variable 'var56' <---> Output : variable 'var56'\n",
      "                         : Input : variable 'var57' <---> Output : variable 'var57'\n",
      "                         : Input : variable 'var58' <---> Output : variable 'var58'\n",
      "                         : Input : variable 'var59' <---> Output : variable 'var59'\n",
      "                         : Input : variable 'var60' <---> Output : variable 'var60'\n",
      "                         : Input : variable 'var61' <---> Output : variable 'var61'\n",
      "                         : Input : variable 'var62' <---> Output : variable 'var62'\n",
      "                         : Input : variable 'var63' <---> Output : variable 'var63'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4991     3.8926   [    -10.257     22.057 ]\n",
      "                         :     var1:     3.9787     4.5075   [    -10.122     25.016 ]\n",
      "                         :     var2:     5.5671     4.8848   [    -9.4795     26.928 ]\n",
      "                         :     var3:     6.5379     5.0192   [    -9.7689     29.230 ]\n",
      "                         :     var4:     6.3871     4.9931   [    -11.476     28.503 ]\n",
      "                         :     var5:     5.4269     4.8235   [    -9.1293     30.122 ]\n",
      "                         :     var6:     3.9107     4.4655   [    -11.141     25.933 ]\n",
      "                         :     var7:     2.4388     3.8766   [    -9.8326     22.021 ]\n",
      "                         :     var8:     3.7375     4.4169   [    -9.0364     24.243 ]\n",
      "                         :     var9:     6.0120     5.1559   [    -9.2157     28.235 ]\n",
      "                         :    var10:     8.3558     5.4951   [    -7.3822     29.694 ]\n",
      "                         :    var11:     9.8310     5.5008   [    -7.2496     32.294 ]\n",
      "                         :    var12:     9.7061     5.5019   [    -9.2380     31.239 ]\n",
      "                         :    var13:     8.2453     5.5157   [    -8.3455     31.442 ]\n",
      "                         :    var14:     5.9694     5.0886   [    -9.2506     29.027 ]\n",
      "                         :    var15:     3.6435     4.3955   [    -10.587     23.653 ]\n",
      "                         :    var16:     4.8733     4.7778   [    -11.709     25.905 ]\n",
      "                         :    var17:     7.9688     5.5580   [    -7.5348     33.189 ]\n",
      "                         :    var18:     10.951     5.7539   [    -7.3453     34.627 ]\n",
      "                         :    var19:     12.853     5.4921   [    -4.1117     33.786 ]\n",
      "                         :    var20:     12.820     5.4867   [    -5.3808     32.315 ]\n",
      "                         :    var21:     10.889     5.7651   [    -6.3743     36.072 ]\n",
      "                         :    var22:     7.9053     5.5376   [    -7.9329     32.559 ]\n",
      "                         :    var23:     4.7962     4.7362   [    -10.919     23.587 ]\n",
      "                         :    var24:     5.6555     5.0342   [    -9.8326     29.659 ]\n",
      "                         :    var25:     9.1977     5.6658   [    -6.3310     34.142 ]\n",
      "                         :    var26:     12.554     5.6514   [    -5.9403     33.692 ]\n",
      "                         :    var27:     14.795     5.1093   [    -2.1615     37.430 ]\n",
      "                         :    var28:     14.660     5.2013   [    -2.8283     38.805 ]\n",
      "                         :    var29:     12.449     5.6721   [    -4.6051     37.288 ]\n",
      "                         :    var30:     9.0063     5.7010   [    -10.813     33.124 ]\n",
      "                         :    var31:     5.4970     4.9834   [    -10.336     30.010 ]\n",
      "                         :    var32:     5.6520     5.0125   [    -9.2211     27.428 ]\n",
      "                         :    var33:     9.1908     5.7259   [    -8.0987     33.206 ]\n",
      "                         :    var34:     12.684     5.6427   [    -5.9139     36.323 ]\n",
      "                         :    var35:     14.812     5.1435   [    -3.2133     34.607 ]\n",
      "                         :    var36:     14.707     5.1390   [    -2.8380     35.026 ]\n",
      "                         :    var37:     12.530     5.5950   [    -6.1929     33.746 ]\n",
      "                         :    var38:     9.0409     5.7810   [    -8.0031     32.626 ]\n",
      "                         :    var39:     5.5780     4.9512   [    -8.8630     29.784 ]\n",
      "                         :    var40:     4.9770     4.7758   [    -10.145     25.266 ]\n",
      "                         :    var41:     7.8714     5.5548   [    -8.5314     37.635 ]\n",
      "                         :    var42:     11.016     5.7577   [    -8.1448     36.124 ]\n",
      "                         :    var43:     12.821     5.4932   [    -6.6966     43.293 ]\n",
      "                         :    var44:     12.887     5.5346   [    -4.9059     34.631 ]\n",
      "                         :    var45:     10.988     5.8018   [    -6.8219     34.300 ]\n",
      "                         :    var46:     7.9529     5.5516   [    -10.776     32.909 ]\n",
      "                         :    var47:     4.8126     4.7994   [    -9.0429     27.598 ]\n",
      "                         :    var48:     3.8114     4.3913   [    -10.010     25.702 ]\n",
      "                         :    var49:     6.0972     5.0664   [    -8.8429     30.707 ]\n",
      "                         :    var50:     8.4053     5.4578   [    -8.4494     30.113 ]\n",
      "                         :    var51:     9.8185     5.5505   [    -8.6899     33.313 ]\n",
      "                         :    var52:     9.8044     5.5527   [    -6.3026     33.478 ]\n",
      "                         :    var53:     8.2980     5.4937   [    -8.6684     35.304 ]\n",
      "                         :    var54:     5.9857     5.0800   [    -8.5084     28.695 ]\n",
      "                         :    var55:     3.5967     4.2971   [    -8.7073     21.957 ]\n",
      "                         :    var56:     2.5031     3.9146   [    -11.497     20.361 ]\n",
      "                         :    var57:     3.9950     4.4431   [    -8.8077     25.394 ]\n",
      "                         :    var58:     5.6013     4.8508   [    -11.076     26.883 ]\n",
      "                         :    var59:     6.5296     5.0636   [    -9.0219     28.571 ]\n",
      "                         :    var60:     6.6129     5.0677   [    -9.9130     27.121 ]\n",
      "                         :    var61:     5.5612     4.9134   [    -9.6182     26.950 ]\n",
      "                         :    var62:     4.0187     4.5265   [    -11.569     26.781 ]\n",
      "                         :    var63:     2.4755     3.8720   [    -9.2495     22.465 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : ------------------------------\n",
      "                         :    1 : var31     : 1.987e-02\n",
      "                         :    2 : var60     : 1.452e-02\n",
      "                         :    3 : var39     : 1.448e-02\n",
      "                         :    4 : var38     : 1.352e-02\n",
      "                         :    5 : var11     : 1.318e-02\n",
      "                         :    6 : var4      : 1.276e-02\n",
      "                         :    7 : var24     : 1.248e-02\n",
      "                         :    8 : var23     : 1.231e-02\n",
      "                         :    9 : var59     : 1.229e-02\n",
      "                         :   10 : var30     : 1.203e-02\n",
      "                         :   11 : var51     : 1.037e-02\n",
      "                         :   12 : var3      : 9.927e-03\n",
      "                         :   13 : var32     : 9.479e-03\n",
      "                         :   14 : var47     : 8.533e-03\n",
      "                         :   15 : var40     : 8.417e-03\n",
      "                         :   16 : var58     : 8.149e-03\n",
      "                         :   17 : var25     : 8.039e-03\n",
      "                         :   18 : var2      : 8.016e-03\n",
      "                         :   19 : var12     : 7.996e-03\n",
      "                         :   20 : var46     : 7.747e-03\n",
      "                         :   21 : var33     : 7.741e-03\n",
      "                         :   22 : var16     : 7.662e-03\n",
      "                         :   23 : var5      : 7.407e-03\n",
      "                         :   24 : var41     : 6.987e-03\n",
      "                         :   25 : var55     : 6.755e-03\n",
      "                         :   26 : var43     : 6.707e-03\n",
      "                         :   27 : var26     : 6.565e-03\n",
      "                         :   28 : var13     : 6.508e-03\n",
      "                         :   29 : var52     : 6.318e-03\n",
      "                         :   30 : var15     : 6.001e-03\n",
      "                         :   31 : var61     : 5.907e-03\n",
      "                         :   32 : var22     : 5.683e-03\n",
      "                         :   33 : var29     : 5.676e-03\n",
      "                         :   34 : var54     : 5.618e-03\n",
      "                         :   35 : var20     : 5.605e-03\n",
      "                         :   36 : var37     : 5.505e-03\n",
      "                         :   37 : var19     : 5.274e-03\n",
      "                         :   38 : var17     : 4.922e-03\n",
      "                         :   39 : var49     : 4.797e-03\n",
      "                         :   40 : var8      : 4.496e-03\n",
      "                         :   41 : var7      : 4.491e-03\n",
      "                         :   42 : var34     : 4.484e-03\n",
      "                         :   43 : var48     : 4.478e-03\n",
      "                         :   44 : var9      : 4.435e-03\n",
      "                         :   45 : var50     : 4.398e-03\n",
      "                         :   46 : var18     : 4.369e-03\n",
      "                         :   47 : var53     : 4.348e-03\n",
      "                         :   48 : var27     : 4.313e-03\n",
      "                         :   49 : var57     : 4.163e-03\n",
      "                         :   50 : var10     : 4.135e-03\n",
      "                         :   51 : var45     : 4.055e-03\n",
      "                         :   52 : var35     : 3.998e-03\n",
      "                         :   53 : var1      : 3.670e-03\n",
      "                         :   54 : var44     : 3.477e-03\n",
      "                         :   55 : var14     : 3.376e-03\n",
      "                         :   56 : var56     : 3.157e-03\n",
      "                         :   57 : var6      : 3.078e-03\n",
      "                         :   58 : var62     : 2.999e-03\n",
      "                         :   59 : var21     : 2.938e-03\n",
      "                         :   60 : var36     : 2.937e-03\n",
      "                         :   61 : var42     : 2.906e-03\n",
      "                         :   62 : var28     : 2.700e-03\n",
      "                         :   63 : var63     : 2.451e-03\n",
      "                         :   64 : var0      : 2.151e-03\n",
      "                         : ------------------------------\n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 5000 bkg: 5000\n",
      "                         : #events: (unweighted) sig: 5000 bkg: 5000\n",
      "                         : Training 800 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 10000 events: 47.2 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.698 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_DENSE for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on the STANDARD architecture\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 64 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t  ( Input = 64 , Width = 1 ) \tOutput = ( 1 , 128 , 1 ) \t Activation Function = Identity\n",
      "                         : Training phase 1 of 1:    Learning rate = 0.001 regularization 2 minimum error = 0.765284\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Test Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.649769    0.664334     1.43999    0.644433     12549.7           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.596953    0.624044      1.3401     0.63887     14237.8           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.579217    0.614683     1.34139    0.635628     14146.4           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.565088     0.60927     1.39257    0.651525     13472.9           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.553454    0.603356     1.36725    0.660382     14124.3           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.547408    0.602606     1.33744     0.63439       14201           0\n",
      "                         :          7 |     0.542955     0.60278     1.56093    0.740213     12164.9           1\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.536383    0.601051     1.54121    0.635718     11026.1           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |      0.53226    0.599533      1.3434    0.637469     14143.1           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n",
      "                         :         10 |     0.526717    0.598436     1.34245    0.638422     14181.3           0\n",
      "                         :         11 Minimum Test error found - save the configuration \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         :         11 |      0.52106    0.597108      1.3358    0.635616       14259           0\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.518016    0.595838     1.33575    0.635936     14266.6           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |      0.51377    0.595534      1.3362    0.636816     14275.4           0\n",
      "                         :         14 |     0.509832    0.596852     1.33965    0.636578     14200.5           1\n",
      "                         :         15 Minimum Test error found - save the configuration \n",
      "                         :         15 |     0.507913    0.595373     1.33946    0.638922     14251.9           0\n",
      "                         :         16 |      0.50463     0.59622     1.33644    0.634317     14219.6           1\n",
      "                         :         17 |     0.501522    0.595428     1.34166    0.638196     14192.7           2\n",
      "                         :         18 |     0.499646    0.597845     1.34085    0.636605     14176.9           3\n",
      "                         :         19 |     0.496378    0.597409     1.33715    0.635831       14236           4\n",
      "                         :         20 |     0.495074    0.601348     1.33865    0.636086     14210.8           5\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 27.9 sec         \n",
      "                         : Evaluate deep neural network on the STANDARD architecture  using batches with size = 128\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.322 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_CNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU.\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 6  Input = ( 1, 8, 8 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 128 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 1\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 128 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 2\t POOL Layer: \t( W = 7 ,  H = 7 ,  D = 10 ) \t Filter ( W = 2 ,  H = 2 ) \tOutput = ( 128 , 10 , 49 ) \n",
      "\tLayer 3\t RESHAPE Layer \t Input = ( 10 , 7 , 7 ) \tOutput = ( 1 , 128 , 490 ) \n",
      "\tLayer 4\t DENSE Layer: \t  ( Input = 490 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 5\t DENSE Layer: \t  ( Input = 64 , Width = 1 ) \tOutput = ( 1 , 128 , 1 ) \t Activation Function = Identity\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n",
      "BLAS : Program is Terminated. Because you tried to allocate too many memory regions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n",
      "\n",
      " *** Break *** segmentation violation\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.TestAllMethods();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.EvaluateAllMethods();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = factory.GetROCCurve(loader);\n",
    "c1->Draw();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// close outputfile to save output file\n",
    "outputFile->Close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
