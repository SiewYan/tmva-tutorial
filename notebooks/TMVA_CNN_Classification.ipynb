{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tmva_logo.gif\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "# TMVA Classification Example Using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    " // for using Keras\n",
    "gSystem->Setenv(\"KERAS_BACKEND\",\"tensorflow\");\n",
    "// for setting openblas in single thread on SWAN\n",
    "gSystem->Setenv(\"OMP_NUM_THREADS\",\"1\"); \n",
    "TMVA::PyMethodBase::PyInitialize();\n",
    "\n",
    "\n",
    "\n",
    "auto outputFile = TFile::Open(\"CNN_ClassificationOutput.root\", \"RECREATE\");\n",
    "\n",
    "TMVA::Factory factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" ); \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables \n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "In this case the input data consists of an image of 16x16 pixels. Each single pixel is a branch in a ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::DataLoader * loader = new TMVA::DataLoader(\"dataset\");\n",
    "\n",
    "int imgSize = 8 * 8; \n",
    "for(auto i = 0; i < imgSize; i++)\n",
    " {\n",
    "     loader->AddVariable(Form(\"var%d\",i),'F');\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "TString inputFileName = \"images_data.root\";\n",
    "\n",
    "//TString inputFileName = \"tmva_class_example.root\";\n",
    "\n",
    "auto inputFile = TFile::Open( inputFileName );\n",
    "\n",
    "// --- Register the training and test trees\n",
    "\n",
    "TTree *signalTree     = (TTree*)inputFile->Get(\"sig_tree\");\n",
    "TTree *backgroundTree = (TTree*)inputFile->Get(\"bkg_tree\");\n",
    "\n",
    "// global event weights per tree (see below for setting event-wise weights)\n",
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "   \n",
    "// You can add an arbitrary number of signal or background trees\n",
    "loader->AddSignalTree    ( signalTree,     signalWeight     );\n",
    "loader->AddBackgroundTree( backgroundTree, backgroundWeight );\n",
    "\n",
    "\n",
    "// Set individual event weights (the variables must exist in the original TTree)\n",
    "//    for signal    : factory->SetSignalWeightExpression    (\"weight1*weight2\");\n",
    "//    for background: factory->SetBackgroundWeightExpression(\"weight1*weight2\");\n",
    "//loader->SetBackgroundWeightExpression( \"weight\" );\n",
    "\n",
    "// Apply additional cuts on the signal and background samples (can be different)\n",
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "// Tell the factory how to use the training and testing events\n",
    "//\n",
    "// If no numbers of events are given, half of the events in the tree are used \n",
    "// for training, and the other half for testing:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "// To also specify the number of testing events, use:\n",
    "\n",
    "loader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                    \"nTrain_Signal=0:nTrain_Background=0:SplitMode=Random:NormMode=NumEvents:!V:!CalcCorrelations\" );\n",
    "\n",
    "\n",
    "\n",
    "//loader->PrepareTrainingAndTestTree(mycuts, mycutb,\n",
    "//                                   \"nTrain_Signal=5000:nTrain_Background=5000:nTest_Signal=5000:nTest_Background=5000:SplitMode=Random:NormMode=NumEvents:!V\" ); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : signal_tree                                            *\n",
      "*Entries :    10000 : Total =         2601382 bytes  File  Size =    2572423 *\n",
      "*        :          : Tree compression factor =   1.00                       *\n",
      "******************************************************************************\n",
      "*Br    0 :var0      : var0/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    1 :var1      : var1/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    2 :var2      : var2/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    3 :var3      : var3/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    4 :var4      : var4/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :var5      : var5/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    6 :var6      : var6/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    7 :var7      : var7/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    8 :var8      : var8/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    9 :var9      : var9/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   10 :var10     : var10/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   11 :var11     : var11/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   12 :var12     : var12/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   13 :var13     : var13/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   14 :var14     : var14/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   15 :var15     : var15/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   16 :var16     : var16/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   17 :var17     : var17/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   18 :var18     : var18/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   19 :var19     : var19/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   20 :var20     : var20/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   21 :var21     : var21/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   22 :var22     : var22/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   23 :var23     : var23/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   24 :var24     : var24/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   25 :var25     : var25/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   26 :var26     : var26/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :var27     : var27/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   28 :var28     : var28/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   29 :var29     : var29/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   30 :var30     : var30/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   31 :var31     : var31/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   32 :var32     : var32/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   33 :var33     : var33/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   34 :var34     : var34/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   35 :var35     : var35/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   36 :var36     : var36/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   37 :var37     : var37/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   38 :var38     : var38/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   39 :var39     : var39/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   40 :var40     : var40/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   41 :var41     : var41/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   42 :var42     : var42/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   43 :var43     : var43/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   44 :var44     : var44/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   45 :var45     : var45/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   46 :var46     : var46/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   47 :var47     : var47/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   48 :var48     : var48/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   49 :var49     : var49/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   50 :var50     : var50/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   51 :var51     : var51/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   52 :var52     : var52/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   53 :var53     : var53/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   54 :var54     : var54/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   55 :var55     : var55/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   56 :var56     : var56/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   57 :var57     : var57/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   58 :var58     : var58/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   59 :var59     : var59/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   60 :var60     : var60/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   61 :var61     : var61/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   62 :var62     : var62/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   63 :var63     : var63/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "signalTree->Print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Likelihood based on KDE, a Fischer discriminant and a BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 5000\n",
      "                         : Signal     -- testing events             : 5000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 5000\n",
      "                         : Background -- testing events             : 5000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "//Boosted Decision Trees\n",
    "factory.BookMethod(loader,TMVA::Types::kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=800:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. If using master version you can use the new DL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool useDNN = true; \n",
    "bool useCNN = true; \n",
    "bool useKeras = false; // unfortunatly PyKeras does not work from C++ notebooks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_DENSE\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=Standard\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=Standard\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|64\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|128|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"STANDARD\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : The STANDARD architecture has been deprecated. Please use Architecture=CPU or Architecture=CPU.See the TMVA Users' Guide for instructions if you encounter problems.\n",
      "                         : Will use the deprecated STANDARD architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useDNN) { \n",
    "    \n",
    "     TString inputLayoutString = \"InputLayout=1|1|64\"; \n",
    "     TString batchLayoutString= \"BatchLayout=1|128|64\";\n",
    "     TString layoutString (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "//                                                                                                                                                                                       \n",
    "      // Training strategies \n",
    "      // one can catenate several training strategies \n",
    "      TString training1(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                        \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                        \"MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,\"\n",
    "                        \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\");\n",
    "  \n",
    "      TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "      trainingStrategyString += training1; // + \"|\" + training2 + \"|\" + training3;\n",
    "\n",
    "      // General Options.                                                                                                                                                                \n",
    "      TString dnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                          \"WeightInitialization=XAVIERUNIFORM\");\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (inputLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (batchLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (layoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (trainingStrategyString);\n",
    "\n",
    "      dnnOptions += \":Architecture=Standard\";\n",
    "      factory.BookMethod(loader, TMVA::Types::kDL, \"DL_DENSE\", dnnOptions);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in TMVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=32|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=32|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|8|8\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"32|1|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useCNN) { \n",
    "    TString inputLayoutString(\"InputLayout=1|8|8\");\n",
    "                                                                                                \n",
    "// Batch Layout                                                                                                                                     \n",
    "    TString batchLayoutString(\"BatchLayout=32|1|64\");\n",
    "                                                   \n",
    "\n",
    "TString layoutString(\"Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,\"\n",
    "                     \"RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "                                                                                                                                              \n",
    "\n",
    "\n",
    "   // Training strategies.                                                                                                                          \n",
    "   TString training0(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                     \"ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,\"\n",
    "                     \"MaxEpochs=30,WeightDecay=1e-4,Regularization=None,\"\n",
    "                     \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\");\n",
    " \n",
    "   TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "   trainingStrategyString += training0; // + \"|\" + training1 + \"|\" + training2;   }\n",
    "    \n",
    "// General Options.                                                                                                                              \n",
    "   TString cnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\");\n",
    "\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(inputLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(batchLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(layoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(trainingStrategyString);\n",
    "   cnnOptions.Append(\":Architecture=CPU\");\n",
    "\n",
    "   //// New DL (CNN)                                                                                                                                \n",
    "\n",
    "\n",
    "  factory.BookMethod(loader, TMVA::Types::kDL, \"DL_CNN\", cnnOptions);\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in Keras using a generated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (useKeras) { \n",
    "   factory.BookMethod(loader, TMVA::Types::kPyKeras, \n",
    "                       \"PyKeras\",\"H:!V:VarTransform=None:FilenameModel=model_cnn.h5:\"\n",
    "                       \"FilenameTrainedModel=trained_model_cnn.h5:NumEpochs=20:BatchSize=128\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var0' <---> Output : variable 'var0'\n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Input : variable 'var5' <---> Output : variable 'var5'\n",
      "                         : Input : variable 'var6' <---> Output : variable 'var6'\n",
      "                         : Input : variable 'var7' <---> Output : variable 'var7'\n",
      "                         : Input : variable 'var8' <---> Output : variable 'var8'\n",
      "                         : Input : variable 'var9' <---> Output : variable 'var9'\n",
      "                         : Input : variable 'var10' <---> Output : variable 'var10'\n",
      "                         : Input : variable 'var11' <---> Output : variable 'var11'\n",
      "                         : Input : variable 'var12' <---> Output : variable 'var12'\n",
      "                         : Input : variable 'var13' <---> Output : variable 'var13'\n",
      "                         : Input : variable 'var14' <---> Output : variable 'var14'\n",
      "                         : Input : variable 'var15' <---> Output : variable 'var15'\n",
      "                         : Input : variable 'var16' <---> Output : variable 'var16'\n",
      "                         : Input : variable 'var17' <---> Output : variable 'var17'\n",
      "                         : Input : variable 'var18' <---> Output : variable 'var18'\n",
      "                         : Input : variable 'var19' <---> Output : variable 'var19'\n",
      "                         : Input : variable 'var20' <---> Output : variable 'var20'\n",
      "                         : Input : variable 'var21' <---> Output : variable 'var21'\n",
      "                         : Input : variable 'var22' <---> Output : variable 'var22'\n",
      "                         : Input : variable 'var23' <---> Output : variable 'var23'\n",
      "                         : Input : variable 'var24' <---> Output : variable 'var24'\n",
      "                         : Input : variable 'var25' <---> Output : variable 'var25'\n",
      "                         : Input : variable 'var26' <---> Output : variable 'var26'\n",
      "                         : Input : variable 'var27' <---> Output : variable 'var27'\n",
      "                         : Input : variable 'var28' <---> Output : variable 'var28'\n",
      "                         : Input : variable 'var29' <---> Output : variable 'var29'\n",
      "                         : Input : variable 'var30' <---> Output : variable 'var30'\n",
      "                         : Input : variable 'var31' <---> Output : variable 'var31'\n",
      "                         : Input : variable 'var32' <---> Output : variable 'var32'\n",
      "                         : Input : variable 'var33' <---> Output : variable 'var33'\n",
      "                         : Input : variable 'var34' <---> Output : variable 'var34'\n",
      "                         : Input : variable 'var35' <---> Output : variable 'var35'\n",
      "                         : Input : variable 'var36' <---> Output : variable 'var36'\n",
      "                         : Input : variable 'var37' <---> Output : variable 'var37'\n",
      "                         : Input : variable 'var38' <---> Output : variable 'var38'\n",
      "                         : Input : variable 'var39' <---> Output : variable 'var39'\n",
      "                         : Input : variable 'var40' <---> Output : variable 'var40'\n",
      "                         : Input : variable 'var41' <---> Output : variable 'var41'\n",
      "                         : Input : variable 'var42' <---> Output : variable 'var42'\n",
      "                         : Input : variable 'var43' <---> Output : variable 'var43'\n",
      "                         : Input : variable 'var44' <---> Output : variable 'var44'\n",
      "                         : Input : variable 'var45' <---> Output : variable 'var45'\n",
      "                         : Input : variable 'var46' <---> Output : variable 'var46'\n",
      "                         : Input : variable 'var47' <---> Output : variable 'var47'\n",
      "                         : Input : variable 'var48' <---> Output : variable 'var48'\n",
      "                         : Input : variable 'var49' <---> Output : variable 'var49'\n",
      "                         : Input : variable 'var50' <---> Output : variable 'var50'\n",
      "                         : Input : variable 'var51' <---> Output : variable 'var51'\n",
      "                         : Input : variable 'var52' <---> Output : variable 'var52'\n",
      "                         : Input : variable 'var53' <---> Output : variable 'var53'\n",
      "                         : Input : variable 'var54' <---> Output : variable 'var54'\n",
      "                         : Input : variable 'var55' <---> Output : variable 'var55'\n",
      "                         : Input : variable 'var56' <---> Output : variable 'var56'\n",
      "                         : Input : variable 'var57' <---> Output : variable 'var57'\n",
      "                         : Input : variable 'var58' <---> Output : variable 'var58'\n",
      "                         : Input : variable 'var59' <---> Output : variable 'var59'\n",
      "                         : Input : variable 'var60' <---> Output : variable 'var60'\n",
      "                         : Input : variable 'var61' <---> Output : variable 'var61'\n",
      "                         : Input : variable 'var62' <---> Output : variable 'var62'\n",
      "                         : Input : variable 'var63' <---> Output : variable 'var63'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4323     3.8630   [    -10.257     22.057 ]\n",
      "                         :     var1:     3.9627     4.4650   [    -10.122     25.831 ]\n",
      "                         :     var2:     5.4794     4.8725   [    -8.1906     29.836 ]\n",
      "                         :     var3:     6.5490     5.0368   [    -9.7689     29.230 ]\n",
      "                         :     var4:     6.4897     5.0083   [    -11.476     27.242 ]\n",
      "                         :     var5:     5.5051     4.8667   [    -7.5238     30.122 ]\n",
      "                         :     var6:     3.9918     4.5749   [    -11.141     28.512 ]\n",
      "                         :     var7:     2.4703     3.8798   [    -9.8602     22.021 ]\n",
      "                         :     var8:     3.7059     4.4063   [    -9.7199     27.343 ]\n",
      "                         :     var9:     6.0613     5.1470   [    -9.2157     29.457 ]\n",
      "                         :    var10:     8.3576     5.4924   [    -8.2847     30.470 ]\n",
      "                         :    var11:     9.7592     5.4900   [    -6.4768     32.336 ]\n",
      "                         :    var12:     9.6933     5.4783   [    -8.2850     31.239 ]\n",
      "                         :    var13:     8.3248     5.5687   [    -7.3403     36.270 ]\n",
      "                         :    var14:     6.0560     5.1065   [    -9.2506     30.755 ]\n",
      "                         :    var15:     3.6508     4.4111   [    -12.546     22.584 ]\n",
      "                         :    var16:     4.8265     4.7593   [    -11.709     25.905 ]\n",
      "                         :    var17:     7.9222     5.5350   [    -8.2664     32.881 ]\n",
      "                         :    var18:     10.901     5.7474   [    -7.3453     35.900 ]\n",
      "                         :    var19:     12.854     5.4604   [    -5.4607     34.438 ]\n",
      "                         :    var20:     12.906     5.5766   [    -4.2162     34.453 ]\n",
      "                         :    var21:     10.965     5.8446   [    -6.3943     36.072 ]\n",
      "                         :    var22:     7.9054     5.5204   [    -7.9329     35.488 ]\n",
      "                         :    var23:     4.8375     4.7729   [    -10.919     23.259 ]\n",
      "                         :    var24:     5.6867     5.0012   [    -9.8326     27.530 ]\n",
      "                         :    var25:     9.0772     5.6819   [    -7.8932     32.554 ]\n",
      "                         :    var26:     12.562     5.6847   [    -4.3404     38.462 ]\n",
      "                         :    var27:     14.825     5.1680   [    -1.4311     37.430 ]\n",
      "                         :    var28:     14.731     5.1689   [    -2.8283     35.169 ]\n",
      "                         :    var29:     12.518     5.6598   [    -4.0975     36.999 ]\n",
      "                         :    var30:     9.0170     5.6967   [    -10.813     31.782 ]\n",
      "                         :    var31:     5.6330     5.0257   [    -9.6496     30.010 ]\n",
      "                         :    var32:     5.5739     4.9879   [    -11.560     26.953 ]\n",
      "                         :    var33:     9.1757     5.6492   [    -7.8908     33.206 ]\n",
      "                         :    var34:     12.627     5.6557   [    -5.9139     36.718 ]\n",
      "                         :    var35:     14.652     5.1028   [    -2.6615     34.607 ]\n",
      "                         :    var36:     14.779     5.1843   [    -2.8380     35.026 ]\n",
      "                         :    var37:     12.554     5.5964   [    -4.7197     33.836 ]\n",
      "                         :    var38:     9.0812     5.6938   [    -9.4451     32.626 ]\n",
      "                         :    var39:     5.6233     4.9971   [    -9.8782     27.415 ]\n",
      "                         :    var40:     4.9276     4.7854   [    -10.422     25.623 ]\n",
      "                         :    var41:     7.8189     5.5261   [    -8.4661     34.692 ]\n",
      "                         :    var42:     11.010     5.7812   [    -7.3053     36.124 ]\n",
      "                         :    var43:     12.902     5.4537   [    -6.0367     43.293 ]\n",
      "                         :    var44:     12.877     5.5252   [    -4.2441     34.631 ]\n",
      "                         :    var45:     11.014     5.7658   [    -5.3868     34.427 ]\n",
      "                         :    var46:     7.9269     5.5660   [    -8.9838     29.830 ]\n",
      "                         :    var47:     4.8651     4.7856   [    -9.0932     27.598 ]\n",
      "                         :    var48:     3.7239     4.3873   [    -10.844     25.228 ]\n",
      "                         :    var49:     6.0798     5.0591   [    -8.1885     29.845 ]\n",
      "                         :    var50:     8.2995     5.4137   [    -7.5161     32.722 ]\n",
      "                         :    var51:     9.8403     5.5363   [    -6.6423     32.436 ]\n",
      "                         :    var52:     9.8072     5.4962   [    -8.3466     33.869 ]\n",
      "                         :    var53:     8.3199     5.4493   [    -9.7019     35.304 ]\n",
      "                         :    var54:     6.0523     5.0862   [    -9.1295     32.443 ]\n",
      "                         :    var55:     3.6869     4.3417   [    -8.7073     27.256 ]\n",
      "                         :    var56:     2.4803     3.8967   [    -11.497     22.620 ]\n",
      "                         :    var57:     4.0231     4.5292   [    -8.6827     26.215 ]\n",
      "                         :    var58:     5.5256     4.8462   [    -10.942     30.791 ]\n",
      "                         :    var59:     6.5213     5.0135   [    -8.9191     29.350 ]\n",
      "                         :    var60:     6.5675     5.0285   [    -9.9130     28.476 ]\n",
      "                         :    var61:     5.5765     4.8790   [    -9.6182     29.674 ]\n",
      "                         :    var62:     4.0368     4.5263   [    -11.569     23.585 ]\n",
      "                         :    var63:     2.5323     3.8614   [    -10.527     22.465 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : ------------------------------\n",
      "                         :    1 : var31     : 1.549e-02\n",
      "                         :    2 : var4      : 1.510e-02\n",
      "                         :    3 : var39     : 1.348e-02\n",
      "                         :    4 : var59     : 1.257e-02\n",
      "                         :    5 : var11     : 1.254e-02\n",
      "                         :    6 : var24     : 1.143e-02\n",
      "                         :    7 : var32     : 1.110e-02\n",
      "                         :    8 : var60     : 1.097e-02\n",
      "                         :    9 : var38     : 1.033e-02\n",
      "                         :   10 : var3      : 1.018e-02\n",
      "                         :   11 : var23     : 1.018e-02\n",
      "                         :   12 : var16     : 9.936e-03\n",
      "                         :   13 : var40     : 9.754e-03\n",
      "                         :   14 : var47     : 9.667e-03\n",
      "                         :   15 : var61     : 8.764e-03\n",
      "                         :   16 : var30     : 8.681e-03\n",
      "                         :   17 : var33     : 8.675e-03\n",
      "                         :   18 : var2      : 8.608e-03\n",
      "                         :   19 : var12     : 8.266e-03\n",
      "                         :   20 : var51     : 8.209e-03\n",
      "                         :   21 : var52     : 7.558e-03\n",
      "                         :   22 : var25     : 7.553e-03\n",
      "                         :   23 : var41     : 7.429e-03\n",
      "                         :   24 : var58     : 7.218e-03\n",
      "                         :   25 : var46     : 6.884e-03\n",
      "                         :   26 : var20     : 6.747e-03\n",
      "                         :   27 : var37     : 6.639e-03\n",
      "                         :   28 : var53     : 6.322e-03\n",
      "                         :   29 : var15     : 6.032e-03\n",
      "                         :   30 : var43     : 5.932e-03\n",
      "                         :   31 : var5      : 5.777e-03\n",
      "                         :   32 : var26     : 5.675e-03\n",
      "                         :   33 : var50     : 5.519e-03\n",
      "                         :   34 : var48     : 5.465e-03\n",
      "                         :   35 : var13     : 5.391e-03\n",
      "                         :   36 : var34     : 5.260e-03\n",
      "                         :   37 : var10     : 5.192e-03\n",
      "                         :   38 : var8      : 5.087e-03\n",
      "                         :   39 : var55     : 5.085e-03\n",
      "                         :   40 : var22     : 5.001e-03\n",
      "                         :   41 : var19     : 4.940e-03\n",
      "                         :   42 : var27     : 4.856e-03\n",
      "                         :   43 : var45     : 4.439e-03\n",
      "                         :   44 : var57     : 4.390e-03\n",
      "                         :   45 : var54     : 4.208e-03\n",
      "                         :   46 : var62     : 4.115e-03\n",
      "                         :   47 : var44     : 3.945e-03\n",
      "                         :   48 : var9      : 3.896e-03\n",
      "                         :   49 : var21     : 3.869e-03\n",
      "                         :   50 : var17     : 3.854e-03\n",
      "                         :   51 : var7      : 3.849e-03\n",
      "                         :   52 : var1      : 3.797e-03\n",
      "                         :   53 : var29     : 3.788e-03\n",
      "                         :   54 : var35     : 3.780e-03\n",
      "                         :   55 : var36     : 3.574e-03\n",
      "                         :   56 : var42     : 3.494e-03\n",
      "                         :   57 : var14     : 3.100e-03\n",
      "                         :   58 : var49     : 3.016e-03\n",
      "                         :   59 : var0      : 2.904e-03\n",
      "                         :   60 : var56     : 2.888e-03\n",
      "                         :   61 : var63     : 2.808e-03\n",
      "                         :   62 : var18     : 2.719e-03\n",
      "                         :   63 : var6      : 2.643e-03\n",
      "                         :   64 : var28     : 2.389e-03\n",
      "                         : ------------------------------\n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 5000 bkg: 5000\n",
      "                         : #events: (unweighted) sig: 5000 bkg: 5000\n",
      "                         : Training 800 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 10000 events: 13.1 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.493 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.class.C\u001b[0m\n",
      "                         : CNN_ClassificationOutput.root:/dataset/Method_BDT/BDT\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_DENSE for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on the STANDARD architecture\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 64 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   128 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 2 minimum error = 0.732871\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.631291    0.655998      1.0395    0.347857     11474.1           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.595927    0.627229    0.871047    0.333108     14752.6           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.572666    0.622379    0.869454    0.342332     15055.3           0\n",
      "                         :          4 |     0.566406    0.631805    0.874414     0.33943     14834.1           1\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.549837    0.616984    0.870076    0.339507     14957.5           0\n",
      "                         :          6 |     0.543065    0.617345    0.872185    0.333304     14726.8           1\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |       0.5365    0.614675    0.880162    0.344518     14815.8           0\n",
      "                         :          8 |     0.530983    0.619706     0.86111    0.332764     15020.5           1\n",
      "                         :          9 |     0.527458    0.618264    0.876829    0.342036     14839.4           2\n",
      "                         :         10 |     0.522764    0.619132    0.875671    0.344063     14928.3           3\n",
      "                         :         11 |     0.517646    0.615747    0.877051    0.342011     14832.5           4\n",
      "                         :         12 |     0.513906    0.622438    0.879643    0.342985     14787.8           5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         :         13 |     0.507408    0.618535    0.891288    0.343492     14487.1           6\n",
      "                         :         14 |      0.51403    0.621716    0.887032    0.345483     14654.3           7\n",
      "                         :         15 |     0.500898    0.623097    0.870298    0.338465       14922           8\n",
      "                         :         16 |       0.4979    0.623156    0.890279    0.340164     14426.1           9\n",
      "                         :         17 |     0.497267    0.624341    0.882433    0.346385     14804.6          10\n",
      "                         :         18 |     0.491209    0.626106    0.885292     0.34461     14677.8          11\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 16.1 sec         \n",
      "                         : Evaluate deep neural network on the STANDARD architecture  using batches with size = 128\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.348 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_CNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 6  Input = ( 1, 8, 8 )  Batch size = 32  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 32 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 1\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 32 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 2\t POOL Layer: \t( W = 7 ,  H = 7 ,  D = 10 ) \t Filter ( W = 2 ,  H = 2 ) \tOutput = ( 32 , 10 , 49 ) \n",
      "\tLayer 3\t RESHAPE Layer \t Input = ( 10 , 7 , 7 ) \tOutput = ( 1 , 32 , 490 ) \n",
      "\tLayer 4\t DENSE Layer: \t ( Input =   490 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 5\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,    32 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 0 minimum error = 0.747829\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |      0.69404    0.694995     6.31552     2.10846     1901.57           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.693187    0.693477     6.21158     2.01164     1904.79           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.692748    0.692212     6.39633     2.12558     1873.21           0\n",
      "                         :          4 |     0.692929    0.692897     6.37988     2.10376     1870.86           1\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.687109    0.686673     6.42304     2.19012     1889.95           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.677862     0.67877     5.97154     2.18883     2114.88           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.670445    0.671671     6.52061     2.18587     1845.56           0\n",
      "                         :          8 |     0.675529    0.675694     6.19313     2.11525     1961.81           1\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.653944    0.658078     6.48288      2.1954      1865.9           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n",
      "                         :         10 |      0.64998    0.654825      6.5076     2.18392     1850.28           0\n",
      "                         :         11 Minimum Test error found - save the configuration \n",
      "                         :         11 |     0.641426    0.647437     6.30214     1.97627     1849.34           0\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.634904    0.642808     5.11011     2.18844     2738.16           0\n",
      "                         :         13 |     0.635967    0.646135     6.40011     2.19754      1903.6           1\n",
      "                         :         14 Minimum Test error found - save the configuration \n",
      "                         :         14 |     0.626419    0.637707     5.90804     1.89379      1992.9           0\n",
      "                         :         15 Minimum Test error found - save the configuration \n",
      "                         :         15 |     0.618102    0.631643     6.28684      2.1035     1912.35           0\n",
      "                         :         16 Minimum Test error found - save the configuration \n",
      "                         :         16 |     0.615687     0.63128     6.28742     2.08475     1903.55           0\n",
      "                         :         17 |     0.624884    0.638397     6.10325     2.17504     2036.55           1\n",
      "                         :         18 Minimum Test error found - save the configuration \n",
      "                         :         18 |     0.603817    0.622429     6.12368     2.01413     1946.68           0\n",
      "                         :         19 |     0.601982    0.622597     5.89367     2.01136     2060.63           1\n",
      "                         :         20 Minimum Test error found - save the configuration \n",
      "                         :         20 |     0.601145    0.622396     6.29636     2.19757     1951.79           0\n",
      "                         :         21 Minimum Test error found - save the configuration \n",
      "                         :         21 |      0.59237     0.61582      6.0019     2.01057     2004.34           0\n",
      "                         :         22 |      0.60513    0.626938     5.70139     2.12222     2235.15           1\n",
      "                         :         23 Minimum Test error found - save the configuration \n",
      "                         :         23 |     0.583857    0.613689     6.38902     2.10851     1868.94           0\n",
      "                         :         24 |     0.582257    0.615054     6.19833     1.97534     1894.39           1\n",
      "                         :         25 Minimum Test error found - save the configuration \n",
      "                         :         25 |     0.581635    0.613573     5.69472     2.07417      2209.6           0\n",
      "                         :         26 Minimum Test error found - save the configuration \n",
      "                         :         26 |     0.573958    0.609736      5.8973     1.96606     2034.98           0\n",
      "                         :         27 Minimum Test error found - save the configuration \n",
      "                         :         27 |     0.575349    0.606339     6.19936     2.10394      1953.4           0\n",
      "                         :         28 |     0.571417    0.610574     6.61417     2.10326     1773.48           1\n",
      "                         :         29 |     0.573237    0.612656     5.99124     1.86878     1940.59           2\n",
      "                         :         30 |     0.574538    0.615018     6.01862      2.1038     2043.52           3\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 185 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 32\n",
      "                         : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL_CNN                   : [dataset] : Evaluation of DL_CNN on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 1.91 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : ---------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ---------------------------------------\n",
      "                         :    1 : var11     : 2.124e-02\n",
      "                         :    2 : var60     : 2.011e-02\n",
      "                         :    3 : var23     : 1.973e-02\n",
      "                         :    4 : var31     : 1.925e-02\n",
      "                         :    5 : var4      : 1.875e-02\n",
      "                         :    6 : var32     : 1.873e-02\n",
      "                         :    7 : var39     : 1.872e-02\n",
      "                         :    8 : var16     : 1.866e-02\n",
      "                         :    9 : var3      : 1.861e-02\n",
      "                         :   10 : var24     : 1.853e-02\n",
      "                         :   11 : var59     : 1.833e-02\n",
      "                         :   12 : var51     : 1.804e-02\n",
      "                         :   13 : var38     : 1.772e-02\n",
      "                         :   14 : var10     : 1.752e-02\n",
      "                         :   15 : var33     : 1.749e-02\n",
      "                         :   16 : var40     : 1.732e-02\n",
      "                         :   17 : var12     : 1.729e-02\n",
      "                         :   18 : var30     : 1.725e-02\n",
      "                         :   19 : var25     : 1.702e-02\n",
      "                         :   20 : var52     : 1.692e-02\n",
      "                         :   21 : var2      : 1.689e-02\n",
      "                         :   22 : var22     : 1.677e-02\n",
      "                         :   23 : var47     : 1.668e-02\n",
      "                         :   24 : var46     : 1.659e-02\n",
      "                         :   25 : var13     : 1.655e-02\n",
      "                         :   26 : var54     : 1.652e-02\n",
      "                         :   27 : var8      : 1.648e-02\n",
      "                         :   28 : var61     : 1.646e-02\n",
      "                         :   29 : var29     : 1.637e-02\n",
      "                         :   30 : var50     : 1.626e-02\n",
      "                         :   31 : var58     : 1.615e-02\n",
      "                         :   32 : var37     : 1.606e-02\n",
      "                         :   33 : var42     : 1.581e-02\n",
      "                         :   34 : var41     : 1.570e-02\n",
      "                         :   35 : var5      : 1.549e-02\n",
      "                         :   36 : var21     : 1.518e-02\n",
      "                         :   37 : var57     : 1.513e-02\n",
      "                         :   38 : var43     : 1.467e-02\n",
      "                         :   39 : var45     : 1.460e-02\n",
      "                         :   40 : var9      : 1.452e-02\n",
      "                         :   41 : var1      : 1.443e-02\n",
      "                         :   42 : var27     : 1.415e-02\n",
      "                         :   43 : var49     : 1.411e-02\n",
      "                         :   44 : var15     : 1.406e-02\n",
      "                         :   45 : var48     : 1.403e-02\n",
      "                         :   46 : var62     : 1.401e-02\n",
      "                         :   47 : var17     : 1.388e-02\n",
      "                         :   48 : var35     : 1.387e-02\n",
      "                         :   49 : var55     : 1.371e-02\n",
      "                         :   50 : var14     : 1.366e-02\n",
      "                         :   51 : var18     : 1.364e-02\n",
      "                         :   52 : var20     : 1.356e-02\n",
      "                         :   53 : var36     : 1.333e-02\n",
      "                         :   54 : var53     : 1.327e-02\n",
      "                         :   55 : var44     : 1.311e-02\n",
      "                         :   56 : var6      : 1.286e-02\n",
      "                         :   57 : var19     : 1.283e-02\n",
      "                         :   58 : var26     : 1.276e-02\n",
      "                         :   59 : var0      : 1.255e-02\n",
      "                         :   60 : var63     : 1.223e-02\n",
      "                         :   61 : var56     : 1.161e-02\n",
      "                         :   62 : var34     : 1.159e-02\n",
      "                         :   63 : var28     : 1.084e-02\n",
      "                         :   64 : var7      : 9.782e-03\n",
      "                         : ---------------------------------------\n",
      "                         : No variable ranking supplied by classifier: DL_DENSE\n",
      "                         : No variable ranking supplied by classifier: DL_CNN\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.431 sec       \n",
      "Factory                  : Test method: DL_DENSE for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on the STANDARD architecture  using batches with size = 1000\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.413 sec       \n",
      "Factory                  : Test method: DL_CNN for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "DL_CNN                   : [dataset] : Evaluation of DL_CNN on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 1.78 sec       \n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.5043     3.8853   [    -10.238     19.977 ]\n",
      "                         :     var1:     3.9825     4.4839   [    -9.8908     25.867 ]\n",
      "                         :     var2:     5.5631     4.8820   [    -9.4795     26.928 ]\n",
      "                         :     var3:     6.4561     5.0113   [    -7.8018     27.360 ]\n",
      "                         :     var4:     6.4159     5.0152   [    -10.282     28.503 ]\n",
      "                         :     var5:     5.4073     4.8119   [    -9.1293     27.156 ]\n",
      "                         :     var6:     3.8795     4.3825   [    -9.8938     25.933 ]\n",
      "                         :     var7:     2.4073     3.9082   [    -9.9916     21.294 ]\n",
      "                         :     var8:     3.7170     4.3735   [    -9.6036     24.819 ]\n",
      "                         :     var9:     6.0300     5.1292   [    -8.6642     28.235 ]\n",
      "                         :    var10:     8.3166     5.5458   [    -8.5650     31.127 ]\n",
      "                         :    var11:     9.7069     5.5196   [    -7.6700     32.150 ]\n",
      "                         :    var12:     9.6440     5.5426   [    -9.2380     29.605 ]\n",
      "                         :    var13:     8.2332     5.4702   [    -8.3455     30.980 ]\n",
      "                         :    var14:     5.9550     5.0876   [    -9.4517     28.416 ]\n",
      "                         :    var15:     3.6311     4.3911   [    -9.0935     23.653 ]\n",
      "                         :    var16:     4.8869     4.7742   [    -9.3507     26.243 ]\n",
      "                         :    var17:     7.9904     5.5533   [    -9.1076     33.189 ]\n",
      "                         :    var18:     10.935     5.7570   [    -11.120     34.627 ]\n",
      "                         :    var19:     12.853     5.5322   [    -3.1498     33.495 ]\n",
      "                         :    var20:     12.790     5.4588   [    -5.3808     32.738 ]\n",
      "                         :    var21:     10.869     5.6835   [    -6.3743     38.104 ]\n",
      "                         :    var22:     7.8424     5.5156   [    -7.4259     31.091 ]\n",
      "                         :    var23:     4.7815     4.7468   [    -9.2727     25.210 ]\n",
      "                         :    var24:     5.6147     4.9482   [    -9.3157     29.659 ]\n",
      "                         :    var25:     9.1872     5.6305   [    -7.2154     34.142 ]\n",
      "                         :    var26:     12.544     5.7216   [    -7.4565     35.941 ]\n",
      "                         :    var27:     14.639     5.0645   [    -2.1615     34.354 ]\n",
      "                         :    var28:     14.616     5.2023   [    -2.4554     38.805 ]\n",
      "                         :    var29:     12.397     5.7231   [    -6.3975     37.288 ]\n",
      "                         :    var30:     8.9915     5.7052   [    -8.2118     33.124 ]\n",
      "                         :    var31:     5.4675     4.9613   [    -10.336     25.562 ]\n",
      "                         :    var32:     5.6604     5.0071   [    -9.2211     27.428 ]\n",
      "                         :    var33:     9.1786     5.7689   [    -8.0987     32.849 ]\n",
      "                         :    var34:     12.727     5.6793   [    -8.4293     39.896 ]\n",
      "                         :    var35:     14.872     5.1555   [    -3.2133     34.365 ]\n",
      "                         :    var36:     14.705     5.1060   [    -1.8485     33.879 ]\n",
      "                         :    var37:     12.503     5.6374   [    -7.0200     33.746 ]\n",
      "                         :    var38:     8.9986     5.7587   [    -8.0031     30.300 ]\n",
      "                         :    var39:     5.5104     4.8948   [    -9.0285     29.784 ]\n",
      "                         :    var40:     4.9943     4.7990   [    -9.8449     28.788 ]\n",
      "                         :    var41:     7.9949     5.5695   [    -8.5314     37.635 ]\n",
      "                         :    var42:     11.040     5.7246   [    -8.1448     32.315 ]\n",
      "                         :    var43:     12.765     5.4985   [    -6.6966     35.064 ]\n",
      "                         :    var44:     12.895     5.5564   [    -5.3399     36.017 ]\n",
      "                         :    var45:     10.991     5.7813   [    -8.1370     34.364 ]\n",
      "                         :    var46:     7.9592     5.5420   [    -10.776     32.909 ]\n",
      "                         :    var47:     4.8937     4.8298   [    -9.0429     26.537 ]\n",
      "                         :    var48:     3.8041     4.3757   [    -10.100     25.702 ]\n",
      "                         :    var49:     6.1313     5.1336   [    -8.8429     30.707 ]\n",
      "                         :    var50:     8.4447     5.5112   [    -8.4494     30.113 ]\n",
      "                         :    var51:     9.8454     5.5869   [    -8.6899     33.313 ]\n",
      "                         :    var52:     9.8467     5.5883   [    -6.0518     32.730 ]\n",
      "                         :    var53:     8.3965     5.5273   [    -9.6863     34.087 ]\n",
      "                         :    var54:     6.0207     5.1251   [    -8.5084     28.695 ]\n",
      "                         :    var55:     3.6099     4.3525   [    -10.585     22.529 ]\n",
      "                         :    var56:     2.4870     3.9654   [    -10.180     20.361 ]\n",
      "                         :    var57:     4.0141     4.4597   [    -8.8077     23.248 ]\n",
      "                         :    var58:     5.6445     4.8995   [    -11.076     29.580 ]\n",
      "                         :    var59:     6.5601     5.0991   [    -9.0219     29.232 ]\n",
      "                         :    var60:     6.5842     5.0875   [    -8.4592     27.121 ]\n",
      "                         :    var61:     5.6473     4.9430   [    -9.4368     29.659 ]\n",
      "                         :    var62:     4.0403     4.5144   [    -9.4320     26.781 ]\n",
      "                         :    var63:     2.4708     3.9139   [    -9.2495     21.548 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "Factory                  : Evaluate classifier: DL_DENSE\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on the STANDARD architecture  using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DL_DENSE       : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.5043     3.8853   [    -10.238     19.977 ]\n",
      "                         :     var1:     3.9825     4.4839   [    -9.8908     25.867 ]\n",
      "                         :     var2:     5.5631     4.8820   [    -9.4795     26.928 ]\n",
      "                         :     var3:     6.4561     5.0113   [    -7.8018     27.360 ]\n",
      "                         :     var4:     6.4159     5.0152   [    -10.282     28.503 ]\n",
      "                         :     var5:     5.4073     4.8119   [    -9.1293     27.156 ]\n",
      "                         :     var6:     3.8795     4.3825   [    -9.8938     25.933 ]\n",
      "                         :     var7:     2.4073     3.9082   [    -9.9916     21.294 ]\n",
      "                         :     var8:     3.7170     4.3735   [    -9.6036     24.819 ]\n",
      "                         :     var9:     6.0300     5.1292   [    -8.6642     28.235 ]\n",
      "                         :    var10:     8.3166     5.5458   [    -8.5650     31.127 ]\n",
      "                         :    var11:     9.7069     5.5196   [    -7.6700     32.150 ]\n",
      "                         :    var12:     9.6440     5.5426   [    -9.2380     29.605 ]\n",
      "                         :    var13:     8.2332     5.4702   [    -8.3455     30.980 ]\n",
      "                         :    var14:     5.9550     5.0876   [    -9.4517     28.416 ]\n",
      "                         :    var15:     3.6311     4.3911   [    -9.0935     23.653 ]\n",
      "                         :    var16:     4.8869     4.7742   [    -9.3507     26.243 ]\n",
      "                         :    var17:     7.9904     5.5533   [    -9.1076     33.189 ]\n",
      "                         :    var18:     10.935     5.7570   [    -11.120     34.627 ]\n",
      "                         :    var19:     12.853     5.5322   [    -3.1498     33.495 ]\n",
      "                         :    var20:     12.790     5.4588   [    -5.3808     32.738 ]\n",
      "                         :    var21:     10.869     5.6835   [    -6.3743     38.104 ]\n",
      "                         :    var22:     7.8424     5.5156   [    -7.4259     31.091 ]\n",
      "                         :    var23:     4.7815     4.7468   [    -9.2727     25.210 ]\n",
      "                         :    var24:     5.6147     4.9482   [    -9.3157     29.659 ]\n",
      "                         :    var25:     9.1872     5.6305   [    -7.2154     34.142 ]\n",
      "                         :    var26:     12.544     5.7216   [    -7.4565     35.941 ]\n",
      "                         :    var27:     14.639     5.0645   [    -2.1615     34.354 ]\n",
      "                         :    var28:     14.616     5.2023   [    -2.4554     38.805 ]\n",
      "                         :    var29:     12.397     5.7231   [    -6.3975     37.288 ]\n",
      "                         :    var30:     8.9915     5.7052   [    -8.2118     33.124 ]\n",
      "                         :    var31:     5.4675     4.9613   [    -10.336     25.562 ]\n",
      "                         :    var32:     5.6604     5.0071   [    -9.2211     27.428 ]\n",
      "                         :    var33:     9.1786     5.7689   [    -8.0987     32.849 ]\n",
      "                         :    var34:     12.727     5.6793   [    -8.4293     39.896 ]\n",
      "                         :    var35:     14.872     5.1555   [    -3.2133     34.365 ]\n",
      "                         :    var36:     14.705     5.1060   [    -1.8485     33.879 ]\n",
      "                         :    var37:     12.503     5.6374   [    -7.0200     33.746 ]\n",
      "                         :    var38:     8.9986     5.7587   [    -8.0031     30.300 ]\n",
      "                         :    var39:     5.5104     4.8948   [    -9.0285     29.784 ]\n",
      "                         :    var40:     4.9943     4.7990   [    -9.8449     28.788 ]\n",
      "                         :    var41:     7.9949     5.5695   [    -8.5314     37.635 ]\n",
      "                         :    var42:     11.040     5.7246   [    -8.1448     32.315 ]\n",
      "                         :    var43:     12.765     5.4985   [    -6.6966     35.064 ]\n",
      "                         :    var44:     12.895     5.5564   [    -5.3399     36.017 ]\n",
      "                         :    var45:     10.991     5.7813   [    -8.1370     34.364 ]\n",
      "                         :    var46:     7.9592     5.5420   [    -10.776     32.909 ]\n",
      "                         :    var47:     4.8937     4.8298   [    -9.0429     26.537 ]\n",
      "                         :    var48:     3.8041     4.3757   [    -10.100     25.702 ]\n",
      "                         :    var49:     6.1313     5.1336   [    -8.8429     30.707 ]\n",
      "                         :    var50:     8.4447     5.5112   [    -8.4494     30.113 ]\n",
      "                         :    var51:     9.8454     5.5869   [    -8.6899     33.313 ]\n",
      "                         :    var52:     9.8467     5.5883   [    -6.0518     32.730 ]\n",
      "                         :    var53:     8.3965     5.5273   [    -9.6863     34.087 ]\n",
      "                         :    var54:     6.0207     5.1251   [    -8.5084     28.695 ]\n",
      "                         :    var55:     3.6099     4.3525   [    -10.585     22.529 ]\n",
      "                         :    var56:     2.4870     3.9654   [    -10.180     20.361 ]\n",
      "                         :    var57:     4.0141     4.4597   [    -8.8077     23.248 ]\n",
      "                         :    var58:     5.6445     4.8995   [    -11.076     29.580 ]\n",
      "                         :    var59:     6.5601     5.0991   [    -9.0219     29.232 ]\n",
      "                         :    var60:     6.5842     5.0875   [    -8.4592     27.121 ]\n",
      "                         :    var61:     5.6473     4.9430   [    -9.4368     29.659 ]\n",
      "                         :    var62:     4.0403     4.5144   [    -9.4320     26.781 ]\n",
      "                         :    var63:     2.4708     3.9139   [    -9.2495     21.548 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "Factory                  : Evaluate classifier: DL_CNN\n",
      "                         : \n",
      "DL_CNN                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DL_CNN         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.5043     3.8853   [    -10.238     19.977 ]\n",
      "                         :     var1:     3.9825     4.4839   [    -9.8908     25.867 ]\n",
      "                         :     var2:     5.5631     4.8820   [    -9.4795     26.928 ]\n",
      "                         :     var3:     6.4561     5.0113   [    -7.8018     27.360 ]\n",
      "                         :     var4:     6.4159     5.0152   [    -10.282     28.503 ]\n",
      "                         :     var5:     5.4073     4.8119   [    -9.1293     27.156 ]\n",
      "                         :     var6:     3.8795     4.3825   [    -9.8938     25.933 ]\n",
      "                         :     var7:     2.4073     3.9082   [    -9.9916     21.294 ]\n",
      "                         :     var8:     3.7170     4.3735   [    -9.6036     24.819 ]\n",
      "                         :     var9:     6.0300     5.1292   [    -8.6642     28.235 ]\n",
      "                         :    var10:     8.3166     5.5458   [    -8.5650     31.127 ]\n",
      "                         :    var11:     9.7069     5.5196   [    -7.6700     32.150 ]\n",
      "                         :    var12:     9.6440     5.5426   [    -9.2380     29.605 ]\n",
      "                         :    var13:     8.2332     5.4702   [    -8.3455     30.980 ]\n",
      "                         :    var14:     5.9550     5.0876   [    -9.4517     28.416 ]\n",
      "                         :    var15:     3.6311     4.3911   [    -9.0935     23.653 ]\n",
      "                         :    var16:     4.8869     4.7742   [    -9.3507     26.243 ]\n",
      "                         :    var17:     7.9904     5.5533   [    -9.1076     33.189 ]\n",
      "                         :    var18:     10.935     5.7570   [    -11.120     34.627 ]\n",
      "                         :    var19:     12.853     5.5322   [    -3.1498     33.495 ]\n",
      "                         :    var20:     12.790     5.4588   [    -5.3808     32.738 ]\n",
      "                         :    var21:     10.869     5.6835   [    -6.3743     38.104 ]\n",
      "                         :    var22:     7.8424     5.5156   [    -7.4259     31.091 ]\n",
      "                         :    var23:     4.7815     4.7468   [    -9.2727     25.210 ]\n",
      "                         :    var24:     5.6147     4.9482   [    -9.3157     29.659 ]\n",
      "                         :    var25:     9.1872     5.6305   [    -7.2154     34.142 ]\n",
      "                         :    var26:     12.544     5.7216   [    -7.4565     35.941 ]\n",
      "                         :    var27:     14.639     5.0645   [    -2.1615     34.354 ]\n",
      "                         :    var28:     14.616     5.2023   [    -2.4554     38.805 ]\n",
      "                         :    var29:     12.397     5.7231   [    -6.3975     37.288 ]\n",
      "                         :    var30:     8.9915     5.7052   [    -8.2118     33.124 ]\n",
      "                         :    var31:     5.4675     4.9613   [    -10.336     25.562 ]\n",
      "                         :    var32:     5.6604     5.0071   [    -9.2211     27.428 ]\n",
      "                         :    var33:     9.1786     5.7689   [    -8.0987     32.849 ]\n",
      "                         :    var34:     12.727     5.6793   [    -8.4293     39.896 ]\n",
      "                         :    var35:     14.872     5.1555   [    -3.2133     34.365 ]\n",
      "                         :    var36:     14.705     5.1060   [    -1.8485     33.879 ]\n",
      "                         :    var37:     12.503     5.6374   [    -7.0200     33.746 ]\n",
      "                         :    var38:     8.9986     5.7587   [    -8.0031     30.300 ]\n",
      "                         :    var39:     5.5104     4.8948   [    -9.0285     29.784 ]\n",
      "                         :    var40:     4.9943     4.7990   [    -9.8449     28.788 ]\n",
      "                         :    var41:     7.9949     5.5695   [    -8.5314     37.635 ]\n",
      "                         :    var42:     11.040     5.7246   [    -8.1448     32.315 ]\n",
      "                         :    var43:     12.765     5.4985   [    -6.6966     35.064 ]\n",
      "                         :    var44:     12.895     5.5564   [    -5.3399     36.017 ]\n",
      "                         :    var45:     10.991     5.7813   [    -8.1370     34.364 ]\n",
      "                         :    var46:     7.9592     5.5420   [    -10.776     32.909 ]\n",
      "                         :    var47:     4.8937     4.8298   [    -9.0429     26.537 ]\n",
      "                         :    var48:     3.8041     4.3757   [    -10.100     25.702 ]\n",
      "                         :    var49:     6.1313     5.1336   [    -8.8429     30.707 ]\n",
      "                         :    var50:     8.4447     5.5112   [    -8.4494     30.113 ]\n",
      "                         :    var51:     9.8454     5.5869   [    -8.6899     33.313 ]\n",
      "                         :    var52:     9.8467     5.5883   [    -6.0518     32.730 ]\n",
      "                         :    var53:     8.3965     5.5273   [    -9.6863     34.087 ]\n",
      "                         :    var54:     6.0207     5.1251   [    -8.5084     28.695 ]\n",
      "                         :    var55:     3.6099     4.3525   [    -10.585     22.529 ]\n",
      "                         :    var56:     2.4870     3.9654   [    -10.180     20.361 ]\n",
      "                         :    var57:     4.0141     4.4597   [    -8.8077     23.248 ]\n",
      "                         :    var58:     5.6445     4.8995   [    -11.076     29.580 ]\n",
      "                         :    var59:     6.5601     5.0991   [    -9.0219     29.232 ]\n",
      "                         :    var60:     6.5842     5.0875   [    -8.4592     27.121 ]\n",
      "                         :    var61:     5.6473     4.9430   [    -9.4368     29.659 ]\n",
      "                         :    var62:     4.0403     4.5144   [    -9.4320     26.781 ]\n",
      "                         :    var63:     2.4708     3.9139   [    -9.2495     21.548 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       BDT            : 0.795\n",
      "                         : dataset       DL_DENSE       : 0.768\n",
      "                         : dataset       DL_CNN         : 0.775\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              BDT            : 0.128 (0.194)       0.449 (0.540)      0.733 (0.780)\n",
      "                         : dataset              DL_DENSE       : 0.094 (0.122)       0.402 (0.467)      0.699 (0.743)\n",
      "                         : dataset              DL_CNN         : 0.039 (0.038)       0.385 (0.381)      0.708 (0.740)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:dataset          : Created tree 'TestTree' with 10000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 10000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = factory.GetROCCurve(loader);\n",
    "c1->Draw();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// close outputfile to save output file\n",
    "outputFile->Close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
