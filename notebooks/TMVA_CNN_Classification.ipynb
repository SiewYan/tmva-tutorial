{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tmva_logo.gif\" height=\"20%\" width=\"20%\">\n",
    "\n",
    "# TMVA Classification Example Using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    " // for using Keras\n",
    "gSystem->Setenv(\"KERAS_BACKEND\",\"tensorflow\");\n",
    "// for setting openblas in single thread on SWAN\n",
    "gSystem->Setenv(\"OMP_NUM_THREADS\",\"1\"); \n",
    "TMVA::PyMethodBase::PyInitialize();\n",
    "\n",
    "\n",
    "\n",
    "auto outputFile = TFile::Open(\"CNN_ClassificationOutput.root\", \"RECREATE\");\n",
    "\n",
    "TMVA::Factory factory(\"TMVA_CNN_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" ); \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables \n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "In this case the input data consists of an image of 16x16 pixels. Each single pixel is a branch in a ROOT TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMVA::DataLoader * loader = new TMVA::DataLoader(\"dataset\");\n",
    "\n",
    "int imgSize = 8 * 8; \n",
    "for(auto i = 0; i < imgSize; i++)\n",
    " {\n",
    "     loader->AddVariable(Form(\"var%d\",i),'F');\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "TString inputFileName = \"images_data.root\";\n",
    "\n",
    "//TString inputFileName = \"tmva_class_example.root\";\n",
    "\n",
    "auto inputFile = TFile::Open( inputFileName );\n",
    "\n",
    "// --- Register the training and test trees\n",
    "\n",
    "TTree *signalTree     = (TTree*)inputFile->Get(\"sig_tree\");\n",
    "TTree *backgroundTree = (TTree*)inputFile->Get(\"bkg_tree\");\n",
    "\n",
    "// global event weights per tree (see below for setting event-wise weights)\n",
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "   \n",
    "// You can add an arbitrary number of signal or background trees\n",
    "loader->AddSignalTree    ( signalTree,     signalWeight     );\n",
    "loader->AddBackgroundTree( backgroundTree, backgroundWeight );\n",
    "\n",
    "\n",
    "// Set individual event weights (the variables must exist in the original TTree)\n",
    "//    for signal    : factory->SetSignalWeightExpression    (\"weight1*weight2\");\n",
    "//    for background: factory->SetBackgroundWeightExpression(\"weight1*weight2\");\n",
    "//loader->SetBackgroundWeightExpression( \"weight\" );\n",
    "\n",
    "// Apply additional cuts on the signal and background samples (can be different)\n",
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "// Tell the factory how to use the training and testing events\n",
    "//\n",
    "// If no numbers of events are given, half of the events in the tree are used \n",
    "// for training, and the other half for testing:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "// To also specify the number of testing events, use:\n",
    "\n",
    "loader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                    \"nTrain_Signal=0:nTrain_Background=0:SplitMode=Random:NormMode=NumEvents:!V:!CalcCorrelations\" );\n",
    "\n",
    "\n",
    "\n",
    "//loader->PrepareTrainingAndTestTree(mycuts, mycutb,\n",
    "//                                   \"nTrain_Signal=5000:nTrain_Background=5000:nTest_Signal=5000:nTest_Background=5000:SplitMode=Random:NormMode=NumEvents:!V\" ); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : signal_tree                                            *\n",
      "*Entries :    10000 : Total =         2601382 bytes  File  Size =    2572423 *\n",
      "*        :          : Tree compression factor =   1.00                       *\n",
      "******************************************************************************\n",
      "*Br    0 :var0      : var0/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    1 :var1      : var1/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    2 :var2      : var2/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    3 :var3      : var3/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    4 :var4      : var4/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :var5      : var5/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    6 :var6      : var6/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    7 :var7      : var7/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    8 :var8      : var8/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    9 :var9      : var9/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40631 bytes  File Size  =      40150 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   10 :var10     : var10/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   11 :var11     : var11/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   12 :var12     : var12/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   13 :var13     : var13/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   14 :var14     : var14/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   15 :var15     : var15/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   16 :var16     : var16/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   17 :var17     : var17/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   18 :var18     : var18/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   19 :var19     : var19/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   20 :var20     : var20/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   21 :var21     : var21/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   22 :var22     : var22/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   23 :var23     : var23/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   24 :var24     : var24/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   25 :var25     : var25/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   26 :var26     : var26/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :var27     : var27/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   28 :var28     : var28/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   29 :var29     : var29/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   30 :var30     : var30/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   31 :var31     : var31/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   32 :var32     : var32/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   33 :var33     : var33/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   34 :var34     : var34/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   35 :var35     : var35/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   36 :var36     : var36/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   37 :var37     : var37/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   38 :var38     : var38/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   39 :var39     : var39/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   40 :var40     : var40/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   41 :var41     : var41/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   42 :var42     : var42/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   43 :var43     : var43/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   44 :var44     : var44/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   45 :var45     : var45/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   46 :var46     : var46/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   47 :var47     : var47/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   48 :var48     : var48/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   49 :var49     : var49/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   50 :var50     : var50/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   51 :var51     : var51/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   52 :var52     : var52/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   53 :var53     : var53/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   54 :var54     : var54/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   55 :var55     : var55/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   56 :var56     : var56/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   57 :var57     : var57/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   58 :var58     : var58/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   59 :var59     : var59/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   60 :var60     : var60/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   61 :var61     : var61/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   62 :var62     : var62/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   63 :var63     : var63/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40637 bytes  File Size  =      40152 *\n",
      "*Baskets :        2 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "signalTree->Print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Likelihood based on KDE, a Fischer discriminant and a BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 5000\n",
      "                         : Signal     -- testing events             : 5000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 5000\n",
      "                         : Background -- testing events             : 5000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "//Boosted Decision Trees\n",
    "factory.BookMethod(loader,TMVA::Types::kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=800:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. If using master version you can use the new DL method\n",
    "See the example TMVA_Higgs_Classification for a detailed description of the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool useDNN = true; \n",
    "bool useCNN = true; \n",
    "bool useKeras = false; // unfortunatly PyKeras does not work from C++ notebooks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_DENSE\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|1|64:BatchLayout=1|128|64:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|64\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|128|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useDNN) { \n",
    "    \n",
    "     TString inputLayoutString = \"InputLayout=1|1|64\"; \n",
    "     TString batchLayoutString= \"BatchLayout=1|128|64\";\n",
    "     TString layoutString (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "//                                                                                                                                                                                       \n",
    "      // Training strategies \n",
    "      // one can catenate several training strategies \n",
    "      TString training1(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                        \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                        \"MaxEpochs=20,WeightDecay=1e-4,Regularization=L2,\"\n",
    "                        \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\");\n",
    "  \n",
    "      TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "      trainingStrategyString += training1; // + \"|\" + training2 + \"|\" + training3;\n",
    "\n",
    "      // General Options.                                                                                                                                                                \n",
    "      TString dnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                          \"WeightInitialization=XAVIERUNIFORM\");\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (inputLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (batchLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (layoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (trainingStrategyString);\n",
    "\n",
    "      dnnOptions += \":Architecture=CPU\";\n",
    "      factory.BookMethod(loader, TMVA::Types::kDL, \"DL_DENSE\", dnnOptions);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in TMVA\n",
    "\n",
    "   For building a CNN one needs to define \n",
    "\n",
    "   -  Input Layout :  number of channels (in this case = 1)  | image height | image width\n",
    "   -  Batch Layout :  batch size | number of channels | image size = (height*width)\n",
    "\n",
    "   Then one add Convolutional layers and MaxPool layers. \n",
    "\n",
    "   -  For Convolutional layer the option string has to be: \n",
    "      - CONV | number of units | filter height | filter width | stride height | stride width | padding height | paddig width | activation function \n",
    "\n",
    "      - note in this case we are using a filer 3x3 and padding=1 and stride=1 so we get the output dimension of the conv layer equal to the input\n",
    "\n",
    "    - For the MaxPool layer: \n",
    "       - MAXPOOL  | pool height | pool width | stride height | stride width\n",
    "\n",
    "   The RESHAPE layer is needed to flatten the output before the Dense layer\n",
    "\n",
    "\n",
    "   Note that to run the CNN is required to have CPU  or GPU support \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CNN\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=32|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=GPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:WeightInitialization=XAVIERUNIFORM:InputLayout=1|8|8:BatchLayout=32|1|64:Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0:Architecture=GPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"None\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|8|8\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"32|1|64\" [The Layout of the batch]\n",
      "                         :     Layout: \"CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIERUNIFORM\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"GPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "                         :     ValidationSize: \"20%\" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]\n",
      "\u001b[31m<ERROR>                         : CUDA backend not enabled. Please make sure you have CUDA installed and it was successfully detected by CMAKE by using -Dcuda=On \u001b[0m\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useCNN) { \n",
    "    TString inputLayoutString(\"InputLayout=1|8|8\");\n",
    "                                                                                                \n",
    "// Batch Layout                                                                                                                                     \n",
    "    TString batchLayoutString(\"BatchLayout=32|1|64\");\n",
    "                                                   \n",
    "\n",
    "TString layoutString(\"Layout=CONV|10|3|3|1|1|1|1|RELU,CONV|10|3|3|1|1|1|1|RELU,MAXPOOL|2|2|1|1,\"\n",
    "                     \"RESHAPE|FLAT,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "                                                                                                                                              \n",
    "\n",
    "\n",
    "   // Training strategies.                                                                                                                          \n",
    "   TString training0(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                     \"ConvergenceSteps=10,BatchSize=32,TestRepetitions=1,\"\n",
    "                     \"MaxEpochs=30,WeightDecay=1e-4,Regularization=None,\"\n",
    "                     \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.0\");\n",
    " \n",
    "   TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "   trainingStrategyString += training0; // + \"|\" + training1 + \"|\" + training2;   }\n",
    "    \n",
    "// General Options.                                                                                                                              \n",
    "   TString cnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=None:\"\n",
    "                       \"WeightInitialization=XAVIERUNIFORM\");\n",
    "\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(inputLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(batchLayoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(layoutString);\n",
    "   cnnOptions.Append(\":\"); cnnOptions.Append(trainingStrategyString);\n",
    "   cnnOptions.Append(\":Architecture=GPU\");\n",
    "\n",
    "   //// New DL (CNN)                                                                                                                                \n",
    "\n",
    "\n",
    "  factory.BookMethod(loader, TMVA::Types::kDL, \"DL_CNN\", cnnOptions);\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Book Convolutional Neural Network in Keras using a generated model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (useKeras) { \n",
    "   factory.BookMethod(loader, TMVA::Types::kPyKeras, \n",
    "                       \"PyKeras\",\"H:!V:VarTransform=None:FilenameModel=model_cnn.h5:\"\n",
    "                       \"FilenameTrainedModel=trained_model_cnn.h5:NumEpochs=20:BatchSize=128\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'var0' <---> Output : variable 'var0'\n",
      "                         : Input : variable 'var1' <---> Output : variable 'var1'\n",
      "                         : Input : variable 'var2' <---> Output : variable 'var2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "                         : Input : variable 'var5' <---> Output : variable 'var5'\n",
      "                         : Input : variable 'var6' <---> Output : variable 'var6'\n",
      "                         : Input : variable 'var7' <---> Output : variable 'var7'\n",
      "                         : Input : variable 'var8' <---> Output : variable 'var8'\n",
      "                         : Input : variable 'var9' <---> Output : variable 'var9'\n",
      "                         : Input : variable 'var10' <---> Output : variable 'var10'\n",
      "                         : Input : variable 'var11' <---> Output : variable 'var11'\n",
      "                         : Input : variable 'var12' <---> Output : variable 'var12'\n",
      "                         : Input : variable 'var13' <---> Output : variable 'var13'\n",
      "                         : Input : variable 'var14' <---> Output : variable 'var14'\n",
      "                         : Input : variable 'var15' <---> Output : variable 'var15'\n",
      "                         : Input : variable 'var16' <---> Output : variable 'var16'\n",
      "                         : Input : variable 'var17' <---> Output : variable 'var17'\n",
      "                         : Input : variable 'var18' <---> Output : variable 'var18'\n",
      "                         : Input : variable 'var19' <---> Output : variable 'var19'\n",
      "                         : Input : variable 'var20' <---> Output : variable 'var20'\n",
      "                         : Input : variable 'var21' <---> Output : variable 'var21'\n",
      "                         : Input : variable 'var22' <---> Output : variable 'var22'\n",
      "                         : Input : variable 'var23' <---> Output : variable 'var23'\n",
      "                         : Input : variable 'var24' <---> Output : variable 'var24'\n",
      "                         : Input : variable 'var25' <---> Output : variable 'var25'\n",
      "                         : Input : variable 'var26' <---> Output : variable 'var26'\n",
      "                         : Input : variable 'var27' <---> Output : variable 'var27'\n",
      "                         : Input : variable 'var28' <---> Output : variable 'var28'\n",
      "                         : Input : variable 'var29' <---> Output : variable 'var29'\n",
      "                         : Input : variable 'var30' <---> Output : variable 'var30'\n",
      "                         : Input : variable 'var31' <---> Output : variable 'var31'\n",
      "                         : Input : variable 'var32' <---> Output : variable 'var32'\n",
      "                         : Input : variable 'var33' <---> Output : variable 'var33'\n",
      "                         : Input : variable 'var34' <---> Output : variable 'var34'\n",
      "                         : Input : variable 'var35' <---> Output : variable 'var35'\n",
      "                         : Input : variable 'var36' <---> Output : variable 'var36'\n",
      "                         : Input : variable 'var37' <---> Output : variable 'var37'\n",
      "                         : Input : variable 'var38' <---> Output : variable 'var38'\n",
      "                         : Input : variable 'var39' <---> Output : variable 'var39'\n",
      "                         : Input : variable 'var40' <---> Output : variable 'var40'\n",
      "                         : Input : variable 'var41' <---> Output : variable 'var41'\n",
      "                         : Input : variable 'var42' <---> Output : variable 'var42'\n",
      "                         : Input : variable 'var43' <---> Output : variable 'var43'\n",
      "                         : Input : variable 'var44' <---> Output : variable 'var44'\n",
      "                         : Input : variable 'var45' <---> Output : variable 'var45'\n",
      "                         : Input : variable 'var46' <---> Output : variable 'var46'\n",
      "                         : Input : variable 'var47' <---> Output : variable 'var47'\n",
      "                         : Input : variable 'var48' <---> Output : variable 'var48'\n",
      "                         : Input : variable 'var49' <---> Output : variable 'var49'\n",
      "                         : Input : variable 'var50' <---> Output : variable 'var50'\n",
      "                         : Input : variable 'var51' <---> Output : variable 'var51'\n",
      "                         : Input : variable 'var52' <---> Output : variable 'var52'\n",
      "                         : Input : variable 'var53' <---> Output : variable 'var53'\n",
      "                         : Input : variable 'var54' <---> Output : variable 'var54'\n",
      "                         : Input : variable 'var55' <---> Output : variable 'var55'\n",
      "                         : Input : variable 'var56' <---> Output : variable 'var56'\n",
      "                         : Input : variable 'var57' <---> Output : variable 'var57'\n",
      "                         : Input : variable 'var58' <---> Output : variable 'var58'\n",
      "                         : Input : variable 'var59' <---> Output : variable 'var59'\n",
      "                         : Input : variable 'var60' <---> Output : variable 'var60'\n",
      "                         : Input : variable 'var61' <---> Output : variable 'var61'\n",
      "                         : Input : variable 'var62' <---> Output : variable 'var62'\n",
      "                         : Input : variable 'var63' <---> Output : variable 'var63'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4701     3.8623   [    -10.257     18.764 ]\n",
      "                         :     var1:     3.9681     4.4742   [    -9.3288     25.831 ]\n",
      "                         :     var2:     5.5276     4.8214   [    -9.4795     25.556 ]\n",
      "                         :     var3:     6.5247     5.0201   [    -7.6537     29.230 ]\n",
      "                         :     var4:     6.4129     5.0196   [    -10.282     27.355 ]\n",
      "                         :     var5:     5.4524     4.8577   [    -7.5877     27.156 ]\n",
      "                         :     var6:     3.9323     4.5203   [    -11.141     28.512 ]\n",
      "                         :     var7:     2.4199     3.9260   [    -9.8602     21.294 ]\n",
      "                         :     var8:     3.7393     4.3949   [    -9.6036     27.343 ]\n",
      "                         :     var9:     6.0779     5.1283   [    -9.2157     28.235 ]\n",
      "                         :    var10:     8.3410     5.4970   [    -7.7720     31.127 ]\n",
      "                         :    var11:     9.7506     5.4743   [    -6.0866     32.294 ]\n",
      "                         :    var12:     9.6127     5.5329   [    -9.2380     29.683 ]\n",
      "                         :    var13:     8.2307     5.5429   [    -7.1600     36.270 ]\n",
      "                         :    var14:     5.9661     5.0906   [    -9.2506     30.755 ]\n",
      "                         :    var15:     3.6163     4.4268   [    -9.8246     23.258 ]\n",
      "                         :    var16:     4.8768     4.7482   [    -11.709     26.243 ]\n",
      "                         :    var17:     7.9227     5.5269   [    -9.1076     30.527 ]\n",
      "                         :    var18:     10.915     5.7339   [    -6.2285     35.900 ]\n",
      "                         :    var19:     12.885     5.4738   [    -5.4607     34.438 ]\n",
      "                         :    var20:     12.837     5.4855   [    -4.9795     34.453 ]\n",
      "                         :    var21:     10.911     5.7875   [    -6.3943     38.104 ]\n",
      "                         :    var22:     7.8435     5.5336   [    -7.4259     35.488 ]\n",
      "                         :    var23:     4.7827     4.7420   [    -10.919     25.210 ]\n",
      "                         :    var24:     5.6673     4.9681   [    -9.3157     29.659 ]\n",
      "                         :    var25:     9.1214     5.6187   [    -7.8932     33.555 ]\n",
      "                         :    var26:     12.579     5.7177   [    -4.7632     38.462 ]\n",
      "                         :    var27:     14.711     5.0966   [    -2.1615     35.902 ]\n",
      "                         :    var28:     14.634     5.1859   [    -2.1573     33.831 ]\n",
      "                         :    var29:     12.373     5.6271   [    -4.6051     32.760 ]\n",
      "                         :    var30:     9.0234     5.6818   [    -10.813     32.022 ]\n",
      "                         :    var31:     5.5520     5.0224   [    -10.336     25.878 ]\n",
      "                         :    var32:     5.6652     5.0397   [    -11.560     27.428 ]\n",
      "                         :    var33:     9.2124     5.7022   [    -8.0987     32.849 ]\n",
      "                         :    var34:     12.650     5.6931   [    -8.4293     36.323 ]\n",
      "                         :    var35:     14.810     5.1596   [    -2.6615     34.607 ]\n",
      "                         :    var36:     14.725     5.1096   [    -2.8380     35.026 ]\n",
      "                         :    var37:     12.535     5.5816   [    -6.1929     33.836 ]\n",
      "                         :    var38:     8.9867     5.7043   [    -7.1232     32.626 ]\n",
      "                         :    var39:     5.5199     4.9405   [    -9.0285     29.784 ]\n",
      "                         :    var40:     5.0488     4.8433   [    -10.422     25.266 ]\n",
      "                         :    var41:     7.9399     5.6164   [    -7.8517     37.635 ]\n",
      "                         :    var42:     10.997     5.7916   [    -7.3053     36.124 ]\n",
      "                         :    var43:     12.806     5.4954   [    -6.6966     35.064 ]\n",
      "                         :    var44:     12.922     5.5352   [    -4.2441     36.017 ]\n",
      "                         :    var45:     10.977     5.7405   [    -8.1370     34.364 ]\n",
      "                         :    var46:     7.9028     5.5545   [    -10.776     32.909 ]\n",
      "                         :    var47:     4.8808     4.7925   [    -9.0932     26.816 ]\n",
      "                         :    var48:     3.7902     4.4039   [    -10.844     25.228 ]\n",
      "                         :    var49:     6.1485     5.1091   [    -8.8429     29.845 ]\n",
      "                         :    var50:     8.4125     5.4775   [    -8.2915     31.133 ]\n",
      "                         :    var51:     9.8682     5.5778   [    -6.8674     33.313 ]\n",
      "                         :    var52:     9.8212     5.5284   [    -6.0435     33.478 ]\n",
      "                         :    var53:     8.3884     5.5094   [    -9.7019     34.087 ]\n",
      "                         :    var54:     6.0209     5.1018   [    -8.5084     32.443 ]\n",
      "                         :    var55:     3.6421     4.3138   [    -10.585     26.869 ]\n",
      "                         :    var56:     2.5230     3.9446   [    -9.4698     21.372 ]\n",
      "                         :    var57:     4.0374     4.5043   [    -8.7161     26.215 ]\n",
      "                         :    var58:     5.6282     4.9041   [    -10.942     30.791 ]\n",
      "                         :    var59:     6.4932     5.0064   [    -9.0219     29.350 ]\n",
      "                         :    var60:     6.5388     5.0672   [    -8.4943     28.476 ]\n",
      "                         :    var61:     5.5954     4.8805   [    -9.6182     26.950 ]\n",
      "                         :    var62:     4.0401     4.4875   [    -11.569     26.781 ]\n",
      "                         :    var63:     2.5019     3.9016   [    -9.2495     22.465 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : ------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : ------------------------------\n",
      "                         :    1 : var4      : 1.556e-02\n",
      "                         :    2 : var31     : 1.403e-02\n",
      "                         :    3 : var24     : 1.348e-02\n",
      "                         :    4 : var33     : 1.328e-02\n",
      "                         :    5 : var39     : 1.317e-02\n",
      "                         :    6 : var32     : 1.210e-02\n",
      "                         :    7 : var59     : 1.206e-02\n",
      "                         :    8 : var60     : 1.191e-02\n",
      "                         :    9 : var3      : 1.166e-02\n",
      "                         :   10 : var38     : 1.153e-02\n",
      "                         :   11 : var11     : 1.145e-02\n",
      "                         :   12 : var47     : 9.808e-03\n",
      "                         :   13 : var12     : 9.701e-03\n",
      "                         :   14 : var16     : 9.031e-03\n",
      "                         :   15 : var41     : 8.867e-03\n",
      "                         :   16 : var30     : 8.663e-03\n",
      "                         :   17 : var23     : 8.343e-03\n",
      "                         :   18 : var40     : 8.225e-03\n",
      "                         :   19 : var48     : 7.877e-03\n",
      "                         :   20 : var25     : 7.484e-03\n",
      "                         :   21 : var51     : 7.456e-03\n",
      "                         :   22 : var26     : 7.162e-03\n",
      "                         :   23 : var2      : 7.159e-03\n",
      "                         :   24 : var46     : 6.982e-03\n",
      "                         :   25 : var52     : 6.800e-03\n",
      "                         :   26 : var5      : 6.738e-03\n",
      "                         :   27 : var61     : 6.040e-03\n",
      "                         :   28 : var20     : 6.007e-03\n",
      "                         :   29 : var8      : 5.495e-03\n",
      "                         :   30 : var58     : 5.292e-03\n",
      "                         :   31 : var45     : 5.198e-03\n",
      "                         :   32 : var53     : 5.178e-03\n",
      "                         :   33 : var13     : 5.108e-03\n",
      "                         :   34 : var7      : 5.072e-03\n",
      "                         :   35 : var22     : 5.061e-03\n",
      "                         :   36 : var43     : 5.031e-03\n",
      "                         :   37 : var37     : 4.977e-03\n",
      "                         :   38 : var6      : 4.920e-03\n",
      "                         :   39 : var17     : 4.849e-03\n",
      "                         :   40 : var15     : 4.728e-03\n",
      "                         :   41 : var35     : 4.702e-03\n",
      "                         :   42 : var10     : 4.668e-03\n",
      "                         :   43 : var28     : 4.503e-03\n",
      "                         :   44 : var55     : 4.495e-03\n",
      "                         :   45 : var54     : 4.427e-03\n",
      "                         :   46 : var18     : 4.333e-03\n",
      "                         :   47 : var50     : 4.264e-03\n",
      "                         :   48 : var36     : 4.240e-03\n",
      "                         :   49 : var34     : 4.202e-03\n",
      "                         :   50 : var19     : 4.151e-03\n",
      "                         :   51 : var9      : 4.144e-03\n",
      "                         :   52 : var57     : 4.121e-03\n",
      "                         :   53 : var21     : 4.060e-03\n",
      "                         :   54 : var1      : 3.936e-03\n",
      "                         :   55 : var29     : 3.921e-03\n",
      "                         :   56 : var63     : 3.558e-03\n",
      "                         :   57 : var0      : 3.485e-03\n",
      "                         :   58 : var56     : 3.481e-03\n",
      "                         :   59 : var49     : 2.914e-03\n",
      "                         :   60 : var14     : 2.902e-03\n",
      "                         :   61 : var27     : 2.892e-03\n",
      "                         :   62 : var44     : 2.748e-03\n",
      "                         :   63 : var62     : 2.556e-03\n",
      "                         :   64 : var42     : 2.538e-03\n",
      "                         : ------------------------------\n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 5000 bkg: 5000\n",
      "                         : #events: (unweighted) sig: 5000 bkg: 5000\n",
      "                         : Training 800 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 10000 events: 10.2 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.424 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.class.C\u001b[0m\n",
      "                         : CNN_ClassificationOutput.root:/dataset/Method_BDT/BDT\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_DENSE for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 64 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t ( Input =    64 , Width =    64 ) \tOutput = (  1 ,   128 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,   128 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 2 minimum error = 0.725341\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.617391    0.641516    0.044264    0.017724      299020           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.583435    0.624579    0.046092    0.017342      276035           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.565092    0.617742    0.044459    0.017203      291165           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.555039    0.614516    0.046266    0.017959      280355           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.543667     0.61043    0.044595    0.017402      291840           0\n",
      "                         :          6 |     0.539632    0.612068    0.044938    0.017584      290122           1\n",
      "                         :          7 |     0.536565    0.618669    0.043647    0.016828      295910           2\n",
      "                         :          8 |     0.526994    0.612202    0.044248    0.018145      304026           3\n",
      "                         :          9 |     0.521334    0.613837     0.04485    0.017182      286830           4\n",
      "                         :         10 |     0.515641    0.610852    0.045387    0.017476      284332           5\n",
      "                         :         11 |     0.511947    0.611254    0.049098     0.01836      258182           6\n",
      "                         :         12 |     0.507521    0.612898    0.044185    0.017116      293177           7\n",
      "                         :         13 |     0.513561    0.628147    0.045106    0.017414      286581           8\n",
      "                         :         14 |     0.501036    0.614607    0.045159    0.017396      285848           9\n",
      "                         :         15 |     0.501689    0.617901    0.045238    0.017635      287505          10\n",
      "                         :         16 |     0.493068    0.615865    0.044755    0.017223      288246          11\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 0.735 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 128\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.017 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_CNN for Classification\n",
      "                         : \n",
      "                         : Start of deep neural network training on CPU using (for ROOT-IMT) nthreads = 1\n",
      "                         : \n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 6  Input = ( 1, 8, 8 )  Batch size = 32  Loss function = C\n",
      "\tLayer 0\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 32 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 1\t CONV LAYER: \t( W = 8 ,  H = 8 ,  D = 10 ) \t Filter ( W = 3 ,  H = 3 ) \tOutput = ( 32 , 10 , 64 ) \t Activation Function = Relu\n",
      "\tLayer 2\t POOL Layer: \t( W = 7 ,  H = 7 ,  D = 10 ) \t Filter ( W = 2 ,  H = 2 ) \tOutput = ( 32 , 10 , 49 ) \n",
      "\tLayer 3\t RESHAPE Layer \t Input = ( 10 , 7 , 7 ) \tOutput = ( 1 , 32 , 490 ) \n",
      "\tLayer 4\t DENSE Layer: \t ( Input =   490 , Width =    64 ) \tOutput = (  1 ,    32 ,    64 ) \t Activation Function = Tanh\n",
      "\tLayer 5\t DENSE Layer: \t ( Input =    64 , Width =     1 ) \tOutput = (  1 ,    32 ,     1 ) \t Activation Function = Identity\n",
      "                         : Using 8000 events for training and 2000 for testing\n",
      "                         : Training phase 1 of 1:  Optimizer ADAM Learning rate = 0.001 regularization 0 minimum error = 0.753179\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Val. Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.628974    0.638921     0.85807    0.265543     13501.5           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.582525    0.597139    0.878707    0.287103     13522.6           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.556688    0.577771    0.882122    0.269344     13055.3           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.546541    0.569794     1.00751    0.321989       11670           0\n",
      "                         :          5 |     0.536457    0.572143    0.929963    0.280156     12311.3           1\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |      0.51988    0.568797    0.915309    0.269382     12385.3           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.514236     0.56631    0.923978    0.273821     12304.7           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.505966    0.564609    0.923661    0.274697     12327.3           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |      0.49675    0.563638    0.921623    0.272143     12317.5           0\n",
      "                         :         10 |     0.492777    0.566783     0.96351    0.282856     11753.4           1\n",
      "                         :         11 |     0.488541    0.567696     1.07262    0.335038     10846.2           2\n",
      "                         :         12 |     0.482917    0.564603     1.13517    0.344948     10123.8           3\n",
      "                         :         13 |     0.475516    0.567128     1.04274    0.282181     10518.6           4\n",
      "                         :         14 Minimum Test error found - save the configuration \n",
      "                         :         14 |      0.46832    0.562364    0.944156    0.282739     12095.2           0\n",
      "                         :         15 |      0.47058    0.565179     1.02246    0.277569     10739.9           1\n",
      "                         :         16 |     0.463581    0.564289    0.938109      0.2768     12097.2           2\n",
      "                         :         17 |     0.448337    0.565844    0.930056     0.27853     12278.9           3\n",
      "                         :         18 |     0.444535    0.566675    0.925062    0.274348     12294.2           4\n",
      "                         :         19 |     0.441648    0.569274    0.909058    0.263002     12382.8           5\n",
      "                         :         20 |     0.434082    0.567148    0.933393    0.280211     12247.7           6\n",
      "                         :         21 |     0.431023    0.568924    0.936935    0.276789     12118.5           7\n",
      "                         :         22 |     0.424703    0.571468     1.00848    0.285338     11062.8           8\n",
      "                         :         23 |     0.420392     0.57091    0.940174    0.271968     11972.4           9\n",
      "                         :         24 |     0.413546     0.57168    0.936936    0.271886     12029.2          10\n",
      "                         :         25 |     0.409333     0.57515    0.916463    0.262127     12226.1          11\n",
      "                         : \n",
      "                         : Elapsed time for training with 10000 events: 23.9 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 32\n",
      "                         : \n",
      "DL_CNN                   : [dataset] : Evaluation of DL_CNN on training sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.265 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : ---------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ---------------------------------------\n",
      "                         :    1 : var4      : 2.262e-02\n",
      "                         :    2 : var38     : 1.976e-02\n",
      "                         :    3 : var24     : 1.946e-02\n",
      "                         :    4 : var31     : 1.929e-02\n",
      "                         :    5 : var11     : 1.873e-02\n",
      "                         :    6 : var33     : 1.867e-02\n",
      "                         :    7 : var12     : 1.843e-02\n",
      "                         :    8 : var41     : 1.838e-02\n",
      "                         :    9 : var32     : 1.828e-02\n",
      "                         :   10 : var39     : 1.823e-02\n",
      "                         :   11 : var40     : 1.817e-02\n",
      "                         :   12 : var61     : 1.805e-02\n",
      "                         :   13 : var59     : 1.800e-02\n",
      "                         :   14 : var48     : 1.777e-02\n",
      "                         :   15 : var5      : 1.776e-02\n",
      "                         :   16 : var3      : 1.766e-02\n",
      "                         :   17 : var52     : 1.751e-02\n",
      "                         :   18 : var60     : 1.728e-02\n",
      "                         :   19 : var22     : 1.722e-02\n",
      "                         :   20 : var6      : 1.698e-02\n",
      "                         :   21 : var2      : 1.695e-02\n",
      "                         :   22 : var47     : 1.689e-02\n",
      "                         :   23 : var51     : 1.660e-02\n",
      "                         :   24 : var46     : 1.658e-02\n",
      "                         :   25 : var55     : 1.619e-02\n",
      "                         :   26 : var13     : 1.614e-02\n",
      "                         :   27 : var25     : 1.613e-02\n",
      "                         :   28 : var23     : 1.587e-02\n",
      "                         :   29 : var44     : 1.571e-02\n",
      "                         :   30 : var49     : 1.566e-02\n",
      "                         :   31 : var30     : 1.562e-02\n",
      "                         :   32 : var20     : 1.562e-02\n",
      "                         :   33 : var34     : 1.553e-02\n",
      "                         :   34 : var26     : 1.549e-02\n",
      "                         :   35 : var14     : 1.539e-02\n",
      "                         :   36 : var16     : 1.535e-02\n",
      "                         :   37 : var58     : 1.514e-02\n",
      "                         :   38 : var21     : 1.513e-02\n",
      "                         :   39 : var53     : 1.482e-02\n",
      "                         :   40 : var29     : 1.466e-02\n",
      "                         :   41 : var18     : 1.464e-02\n",
      "                         :   42 : var50     : 1.455e-02\n",
      "                         :   43 : var45     : 1.442e-02\n",
      "                         :   44 : var19     : 1.431e-02\n",
      "                         :   45 : var17     : 1.424e-02\n",
      "                         :   46 : var42     : 1.420e-02\n",
      "                         :   47 : var9      : 1.417e-02\n",
      "                         :   48 : var10     : 1.406e-02\n",
      "                         :   49 : var8      : 1.386e-02\n",
      "                         :   50 : var54     : 1.356e-02\n",
      "                         :   51 : var63     : 1.345e-02\n",
      "                         :   52 : var27     : 1.342e-02\n",
      "                         :   53 : var7      : 1.341e-02\n",
      "                         :   54 : var57     : 1.335e-02\n",
      "                         :   55 : var37     : 1.311e-02\n",
      "                         :   56 : var43     : 1.309e-02\n",
      "                         :   57 : var15     : 1.256e-02\n",
      "                         :   58 : var0      : 1.240e-02\n",
      "                         :   59 : var35     : 1.227e-02\n",
      "                         :   60 : var56     : 1.223e-02\n",
      "                         :   61 : var1      : 1.221e-02\n",
      "                         :   62 : var62     : 1.150e-02\n",
      "                         :   63 : var36     : 1.075e-02\n",
      "                         :   64 : var28     : 1.054e-02\n",
      "                         : ---------------------------------------\n",
      "                         : No variable ranking supplied by classifier: DL_DENSE\n",
      "                         : No variable ranking supplied by classifier: DL_CNN\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_DENSE.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_CNN_Classification_DL_CNN.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Evaluate Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.292 sec       \n",
      "Factory                  : Test method: DL_DENSE for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Evaluation of DL_DENSE on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.0137 sec       \n",
      "Factory                  : Test method: DL_CNN for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "DL_CNN                   : [dataset] : Evaluation of DL_CNN on testing sample (10000 events)\n",
      "                         : Elapsed time for evaluation of 10000 events: 0.355 sec       \n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4665     3.8863   [    -9.9918     22.057 ]\n",
      "                         :     var1:     3.9772     4.4747   [    -10.122     25.867 ]\n",
      "                         :     var2:     5.5148     4.9329   [    -8.5006     29.836 ]\n",
      "                         :     var3:     6.4803     5.0283   [    -9.7689     27.817 ]\n",
      "                         :     var4:     6.4927     5.0039   [    -11.476     28.503 ]\n",
      "                         :     var5:     5.4600     4.8215   [    -9.1293     30.122 ]\n",
      "                         :     var6:     3.9390     4.4395   [    -9.8938     25.836 ]\n",
      "                         :     var7:     2.4576     3.8619   [    -9.9916     22.021 ]\n",
      "                         :     var8:     3.6836     4.3847   [    -9.7199     23.915 ]\n",
      "                         :     var9:     6.0135     5.1477   [    -8.7538     29.457 ]\n",
      "                         :    var10:     8.3332     5.5413   [    -8.5650     29.694 ]\n",
      "                         :    var11:     9.7155     5.5353   [    -7.6700     32.336 ]\n",
      "                         :    var12:     9.7246     5.4877   [    -8.9977     31.239 ]\n",
      "                         :    var13:     8.3274     5.4963   [    -8.3455     35.521 ]\n",
      "                         :    var14:     6.0449     5.1036   [    -9.4517     29.027 ]\n",
      "                         :    var15:     3.6656     4.3752   [    -12.546     23.653 ]\n",
      "                         :    var16:     4.8365     4.7853   [    -9.9826     25.905 ]\n",
      "                         :    var17:     7.9899     5.5614   [    -8.4758     33.189 ]\n",
      "                         :    var18:     10.920     5.7705   [    -11.120     35.485 ]\n",
      "                         :    var19:     12.822     5.5187   [    -4.1117     33.549 ]\n",
      "                         :    var20:     12.859     5.5509   [    -5.3808     32.512 ]\n",
      "                         :    var21:     10.924     5.7420   [    -6.3743     33.543 ]\n",
      "                         :    var22:     7.9043     5.5024   [    -7.9329     32.559 ]\n",
      "                         :    var23:     4.8363     4.7776   [    -8.9670     23.259 ]\n",
      "                         :    var24:     5.6341     4.9816   [    -9.8326     25.064 ]\n",
      "                         :    var25:     9.1430     5.6941   [    -7.2154     34.142 ]\n",
      "                         :    var26:     12.527     5.6885   [    -7.4565     34.013 ]\n",
      "                         :    var27:     14.753     5.1380   [    -1.4311     37.430 ]\n",
      "                         :    var28:     14.713     5.1858   [    -2.8283     38.805 ]\n",
      "                         :    var29:     12.542     5.7547   [    -6.3975     37.288 ]\n",
      "                         :    var30:     8.9851     5.7200   [    -8.2118     33.124 ]\n",
      "                         :    var31:     5.5485     4.9660   [    -9.0119     30.010 ]\n",
      "                         :    var32:     5.5690     4.9548   [    -9.2211     25.742 ]\n",
      "                         :    var33:     9.1419     5.7164   [    -7.8908     33.206 ]\n",
      "                         :    var34:     12.704     5.6421   [    -5.3320     39.896 ]\n",
      "                         :    var35:     14.713     5.1005   [    -3.2133     34.365 ]\n",
      "                         :    var36:     14.759     5.1810   [    -2.6326     33.965 ]\n",
      "                         :    var37:     12.523     5.6522   [    -7.0200     33.746 ]\n",
      "                         :    var38:     9.0932     5.7481   [    -9.4451     32.219 ]\n",
      "                         :    var39:     5.6138     4.9522   [    -9.8782     27.415 ]\n",
      "                         :    var40:     4.8731     4.7393   [    -9.8653     28.788 ]\n",
      "                         :    var41:     7.8738     5.4797   [    -8.5314     34.890 ]\n",
      "                         :    var42:     11.053     5.7139   [    -8.1448     34.394 ]\n",
      "                         :    var43:     12.861     5.4574   [    -3.7585     43.293 ]\n",
      "                         :    var44:     12.851     5.5462   [    -5.3399     34.631 ]\n",
      "                         :    var45:     11.028     5.8064   [    -6.8219     34.427 ]\n",
      "                         :    var46:     7.9833     5.5533   [    -9.6217     31.459 ]\n",
      "                         :    var47:     4.8780     4.8230   [    -8.9724     27.598 ]\n",
      "                         :    var48:     3.7379     4.3593   [    -9.2094     25.702 ]\n",
      "                         :    var49:     6.0626     5.0836   [    -8.5402     30.707 ]\n",
      "                         :    var50:     8.3318     5.4485   [    -8.4494     32.722 ]\n",
      "                         :    var51:     9.8175     5.5454   [    -8.6899     33.142 ]\n",
      "                         :    var52:     9.8327     5.5565   [    -8.3466     33.869 ]\n",
      "                         :    var53:     8.3281     5.4676   [    -7.4441     35.304 ]\n",
      "                         :    var54:     6.0520     5.1096   [    -9.1295     30.308 ]\n",
      "                         :    var55:     3.6548     4.3804   [    -8.0707     27.256 ]\n",
      "                         :    var56:     2.4444     3.9174   [    -11.497     22.620 ]\n",
      "                         :    var57:     3.9997     4.4847   [    -8.8077     24.993 ]\n",
      "                         :    var58:     5.5419     4.8419   [    -11.076     28.099 ]\n",
      "                         :    var59:     6.5882     5.1057   [    -8.9191     27.372 ]\n",
      "                         :    var60:     6.6129     5.0486   [    -9.9130     27.121 ]\n",
      "                         :    var61:     5.6284     4.9417   [    -9.0860     29.674 ]\n",
      "                         :    var62:     4.0370     4.5530   [    -8.2972     24.892 ]\n",
      "                         :    var63:     2.5012     3.8740   [    -10.527     21.548 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "Factory                  : Evaluate classifier: DL_DENSE\n",
      "                         : \n",
      "DL_DENSE                 : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DL_DENSE       : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4665     3.8863   [    -9.9918     22.057 ]\n",
      "                         :     var1:     3.9772     4.4747   [    -10.122     25.867 ]\n",
      "                         :     var2:     5.5148     4.9329   [    -8.5006     29.836 ]\n",
      "                         :     var3:     6.4803     5.0283   [    -9.7689     27.817 ]\n",
      "                         :     var4:     6.4927     5.0039   [    -11.476     28.503 ]\n",
      "                         :     var5:     5.4600     4.8215   [    -9.1293     30.122 ]\n",
      "                         :     var6:     3.9390     4.4395   [    -9.8938     25.836 ]\n",
      "                         :     var7:     2.4576     3.8619   [    -9.9916     22.021 ]\n",
      "                         :     var8:     3.6836     4.3847   [    -9.7199     23.915 ]\n",
      "                         :     var9:     6.0135     5.1477   [    -8.7538     29.457 ]\n",
      "                         :    var10:     8.3332     5.5413   [    -8.5650     29.694 ]\n",
      "                         :    var11:     9.7155     5.5353   [    -7.6700     32.336 ]\n",
      "                         :    var12:     9.7246     5.4877   [    -8.9977     31.239 ]\n",
      "                         :    var13:     8.3274     5.4963   [    -8.3455     35.521 ]\n",
      "                         :    var14:     6.0449     5.1036   [    -9.4517     29.027 ]\n",
      "                         :    var15:     3.6656     4.3752   [    -12.546     23.653 ]\n",
      "                         :    var16:     4.8365     4.7853   [    -9.9826     25.905 ]\n",
      "                         :    var17:     7.9899     5.5614   [    -8.4758     33.189 ]\n",
      "                         :    var18:     10.920     5.7705   [    -11.120     35.485 ]\n",
      "                         :    var19:     12.822     5.5187   [    -4.1117     33.549 ]\n",
      "                         :    var20:     12.859     5.5509   [    -5.3808     32.512 ]\n",
      "                         :    var21:     10.924     5.7420   [    -6.3743     33.543 ]\n",
      "                         :    var22:     7.9043     5.5024   [    -7.9329     32.559 ]\n",
      "                         :    var23:     4.8363     4.7776   [    -8.9670     23.259 ]\n",
      "                         :    var24:     5.6341     4.9816   [    -9.8326     25.064 ]\n",
      "                         :    var25:     9.1430     5.6941   [    -7.2154     34.142 ]\n",
      "                         :    var26:     12.527     5.6885   [    -7.4565     34.013 ]\n",
      "                         :    var27:     14.753     5.1380   [    -1.4311     37.430 ]\n",
      "                         :    var28:     14.713     5.1858   [    -2.8283     38.805 ]\n",
      "                         :    var29:     12.542     5.7547   [    -6.3975     37.288 ]\n",
      "                         :    var30:     8.9851     5.7200   [    -8.2118     33.124 ]\n",
      "                         :    var31:     5.5485     4.9660   [    -9.0119     30.010 ]\n",
      "                         :    var32:     5.5690     4.9548   [    -9.2211     25.742 ]\n",
      "                         :    var33:     9.1419     5.7164   [    -7.8908     33.206 ]\n",
      "                         :    var34:     12.704     5.6421   [    -5.3320     39.896 ]\n",
      "                         :    var35:     14.713     5.1005   [    -3.2133     34.365 ]\n",
      "                         :    var36:     14.759     5.1810   [    -2.6326     33.965 ]\n",
      "                         :    var37:     12.523     5.6522   [    -7.0200     33.746 ]\n",
      "                         :    var38:     9.0932     5.7481   [    -9.4451     32.219 ]\n",
      "                         :    var39:     5.6138     4.9522   [    -9.8782     27.415 ]\n",
      "                         :    var40:     4.8731     4.7393   [    -9.8653     28.788 ]\n",
      "                         :    var41:     7.8738     5.4797   [    -8.5314     34.890 ]\n",
      "                         :    var42:     11.053     5.7139   [    -8.1448     34.394 ]\n",
      "                         :    var43:     12.861     5.4574   [    -3.7585     43.293 ]\n",
      "                         :    var44:     12.851     5.5462   [    -5.3399     34.631 ]\n",
      "                         :    var45:     11.028     5.8064   [    -6.8219     34.427 ]\n",
      "                         :    var46:     7.9833     5.5533   [    -9.6217     31.459 ]\n",
      "                         :    var47:     4.8780     4.8230   [    -8.9724     27.598 ]\n",
      "                         :    var48:     3.7379     4.3593   [    -9.2094     25.702 ]\n",
      "                         :    var49:     6.0626     5.0836   [    -8.5402     30.707 ]\n",
      "                         :    var50:     8.3318     5.4485   [    -8.4494     32.722 ]\n",
      "                         :    var51:     9.8175     5.5454   [    -8.6899     33.142 ]\n",
      "                         :    var52:     9.8327     5.5565   [    -8.3466     33.869 ]\n",
      "                         :    var53:     8.3281     5.4676   [    -7.4441     35.304 ]\n",
      "                         :    var54:     6.0520     5.1096   [    -9.1295     30.308 ]\n",
      "                         :    var55:     3.6548     4.3804   [    -8.0707     27.256 ]\n",
      "                         :    var56:     2.4444     3.9174   [    -11.497     22.620 ]\n",
      "                         :    var57:     3.9997     4.4847   [    -8.8077     24.993 ]\n",
      "                         :    var58:     5.5419     4.8419   [    -11.076     28.099 ]\n",
      "                         :    var59:     6.5882     5.1057   [    -8.9191     27.372 ]\n",
      "                         :    var60:     6.6129     5.0486   [    -9.9130     27.121 ]\n",
      "                         :    var61:     5.6284     4.9417   [    -9.0860     29.674 ]\n",
      "                         :    var62:     4.0370     4.5530   [    -8.2972     24.892 ]\n",
      "                         :    var63:     2.5012     3.8740   [    -10.527     21.548 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "Factory                  : Evaluate classifier: DL_CNN\n",
      "                         : \n",
      "DL_CNN                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DL_CNN         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     var0:     2.4665     3.8863   [    -9.9918     22.057 ]\n",
      "                         :     var1:     3.9772     4.4747   [    -10.122     25.867 ]\n",
      "                         :     var2:     5.5148     4.9329   [    -8.5006     29.836 ]\n",
      "                         :     var3:     6.4803     5.0283   [    -9.7689     27.817 ]\n",
      "                         :     var4:     6.4927     5.0039   [    -11.476     28.503 ]\n",
      "                         :     var5:     5.4600     4.8215   [    -9.1293     30.122 ]\n",
      "                         :     var6:     3.9390     4.4395   [    -9.8938     25.836 ]\n",
      "                         :     var7:     2.4576     3.8619   [    -9.9916     22.021 ]\n",
      "                         :     var8:     3.6836     4.3847   [    -9.7199     23.915 ]\n",
      "                         :     var9:     6.0135     5.1477   [    -8.7538     29.457 ]\n",
      "                         :    var10:     8.3332     5.5413   [    -8.5650     29.694 ]\n",
      "                         :    var11:     9.7155     5.5353   [    -7.6700     32.336 ]\n",
      "                         :    var12:     9.7246     5.4877   [    -8.9977     31.239 ]\n",
      "                         :    var13:     8.3274     5.4963   [    -8.3455     35.521 ]\n",
      "                         :    var14:     6.0449     5.1036   [    -9.4517     29.027 ]\n",
      "                         :    var15:     3.6656     4.3752   [    -12.546     23.653 ]\n",
      "                         :    var16:     4.8365     4.7853   [    -9.9826     25.905 ]\n",
      "                         :    var17:     7.9899     5.5614   [    -8.4758     33.189 ]\n",
      "                         :    var18:     10.920     5.7705   [    -11.120     35.485 ]\n",
      "                         :    var19:     12.822     5.5187   [    -4.1117     33.549 ]\n",
      "                         :    var20:     12.859     5.5509   [    -5.3808     32.512 ]\n",
      "                         :    var21:     10.924     5.7420   [    -6.3743     33.543 ]\n",
      "                         :    var22:     7.9043     5.5024   [    -7.9329     32.559 ]\n",
      "                         :    var23:     4.8363     4.7776   [    -8.9670     23.259 ]\n",
      "                         :    var24:     5.6341     4.9816   [    -9.8326     25.064 ]\n",
      "                         :    var25:     9.1430     5.6941   [    -7.2154     34.142 ]\n",
      "                         :    var26:     12.527     5.6885   [    -7.4565     34.013 ]\n",
      "                         :    var27:     14.753     5.1380   [    -1.4311     37.430 ]\n",
      "                         :    var28:     14.713     5.1858   [    -2.8283     38.805 ]\n",
      "                         :    var29:     12.542     5.7547   [    -6.3975     37.288 ]\n",
      "                         :    var30:     8.9851     5.7200   [    -8.2118     33.124 ]\n",
      "                         :    var31:     5.5485     4.9660   [    -9.0119     30.010 ]\n",
      "                         :    var32:     5.5690     4.9548   [    -9.2211     25.742 ]\n",
      "                         :    var33:     9.1419     5.7164   [    -7.8908     33.206 ]\n",
      "                         :    var34:     12.704     5.6421   [    -5.3320     39.896 ]\n",
      "                         :    var35:     14.713     5.1005   [    -3.2133     34.365 ]\n",
      "                         :    var36:     14.759     5.1810   [    -2.6326     33.965 ]\n",
      "                         :    var37:     12.523     5.6522   [    -7.0200     33.746 ]\n",
      "                         :    var38:     9.0932     5.7481   [    -9.4451     32.219 ]\n",
      "                         :    var39:     5.6138     4.9522   [    -9.8782     27.415 ]\n",
      "                         :    var40:     4.8731     4.7393   [    -9.8653     28.788 ]\n",
      "                         :    var41:     7.8738     5.4797   [    -8.5314     34.890 ]\n",
      "                         :    var42:     11.053     5.7139   [    -8.1448     34.394 ]\n",
      "                         :    var43:     12.861     5.4574   [    -3.7585     43.293 ]\n",
      "                         :    var44:     12.851     5.5462   [    -5.3399     34.631 ]\n",
      "                         :    var45:     11.028     5.8064   [    -6.8219     34.427 ]\n",
      "                         :    var46:     7.9833     5.5533   [    -9.6217     31.459 ]\n",
      "                         :    var47:     4.8780     4.8230   [    -8.9724     27.598 ]\n",
      "                         :    var48:     3.7379     4.3593   [    -9.2094     25.702 ]\n",
      "                         :    var49:     6.0626     5.0836   [    -8.5402     30.707 ]\n",
      "                         :    var50:     8.3318     5.4485   [    -8.4494     32.722 ]\n",
      "                         :    var51:     9.8175     5.5454   [    -8.6899     33.142 ]\n",
      "                         :    var52:     9.8327     5.5565   [    -8.3466     33.869 ]\n",
      "                         :    var53:     8.3281     5.4676   [    -7.4441     35.304 ]\n",
      "                         :    var54:     6.0520     5.1096   [    -9.1295     30.308 ]\n",
      "                         :    var55:     3.6548     4.3804   [    -8.0707     27.256 ]\n",
      "                         :    var56:     2.4444     3.9174   [    -11.497     22.620 ]\n",
      "                         :    var57:     3.9997     4.4847   [    -8.8077     24.993 ]\n",
      "                         :    var58:     5.5419     4.8419   [    -11.076     28.099 ]\n",
      "                         :    var59:     6.5882     5.1057   [    -8.9191     27.372 ]\n",
      "                         :    var60:     6.6129     5.0486   [    -9.9130     27.121 ]\n",
      "                         :    var61:     5.6284     4.9417   [    -9.0860     29.674 ]\n",
      "                         :    var62:     4.0370     4.5530   [    -8.2972     24.892 ]\n",
      "                         :    var63:     2.5012     3.8740   [    -10.527     21.548 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \u001b[32m\n",
      "                         : <PlotVariables> Will not produce scatter plots ==> \n",
      "                         : |  The number of 64 input variables and 0 target values would require 2016 two-dimensional\n",
      "                         : |  histograms, which would occupy the computer's memory. Note that this\n",
      "                         : |  suppression does not have any consequences for your analysis, other\n",
      "                         : |  than not disposing of these scatter plots. You can modify the maximum\n",
      "                         : |  number of input variables allowed to generate scatter plots in your\n",
      "                         : |  script via the command line:\n",
      "                         : |  \"(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;\"\u001b[0m\n",
      "                         : \n",
      "                         : Some more output\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       BDT            : 0.792\n",
      "                         : dataset       DL_CNN         : 0.780\n",
      "                         : dataset       DL_DENSE       : 0.768\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              BDT            : 0.132 (0.193)       0.447 (0.518)      0.742 (0.783)\n",
      "                         : dataset              DL_CNN         : 0.101 (0.170)       0.424 (0.522)      0.729 (0.771)\n",
      "                         : dataset              DL_DENSE       : 0.109 (0.125)       0.403 (0.463)      0.698 (0.729)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 10000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 10000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods();    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE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\nCgAAABAFQwEAAACi/D9GgmkCQXJC4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = factory.GetROCCurve(loader);\n",
    "c1->Draw();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// close outputfile to save output file\n",
    "outputFile->Close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
